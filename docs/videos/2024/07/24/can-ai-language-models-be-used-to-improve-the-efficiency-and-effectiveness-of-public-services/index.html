<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">Can AI language models be used to improve the efficiency and effectiveness of public services? [34:24]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=3L-JeNALLdU" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCBWjJVwRap6ocot6rs1Gg-g" target="_blank">Te Herenga Wakaâ€”Victoria University of Wellington</a></p><img src="https://i.ytimg.com/vi/3L-JeNALLdU/maxresdefault.jpg" alt="Thumbnail for video titled: Can AI language models be used to improve the efficiency and effectiveness of public services?" style="width: 100%;"><div class="tags"></div><h2>Description</h2><p>AI language models create many opportunities for improved efficiency and productivity. At the same time, they introduce many new risks, because it is very hard to guarantee their behaviour.<br>In this spotlight lecture, we will consider what use New Zealand government departments might make of them, and will look at some of the pros and cons in detail as they play out in the domain of public service. Presented by Dr Simon McCallum and Professor Ali Knott.</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>no my name is Margaret Highland and I'm<br>the deputy Vice Chancellor research and<br>um I'm here to to give you a very warm<br>welcome on this uh gray winter<br>Wellington day uh to our Spotlight<br>series and um I confess this was a bit<br>of an experiment to run an 8 AM lecture<br>um looks like it was a good<br>one uh so very uh welcome to this<br>lecture uh can AI language models be<br>used to improve the efficiency and effec<br>effess of the public service um this is<br>one of the first events being hosted by<br>the policy Hub which has being<br>established at the University as a way<br>of advancing our relationship and our<br>conversations with the government um and<br>one of the first sets of activities that<br>the Hub is leading is about the use of<br>AI in the public sector all around us<br>there are significant asks for<br>evidence-based policy and practice and<br>education social social welfare Justice<br>environmental goals health care whatever<br>the field uh this holds true in ALA in<br>altea New Zealand uh universities and<br>our research staff enjoy valuable<br>connections with government and policy<br>makers in areas like health and<br>environment but there are other areas<br>especially among the emerging ones where<br>there are critical gaps between research<br>expertise and formed<br>policym the key reason uh that I was<br>Keen to set have the policy Hub set up<br>was to help bridge this Gap to<br>facilitate the conversations and<br>interactions between our researchers uh<br>public sector agencies and policy<br>makers a key area of focus for the<br>policy Hub is making our research more<br>accessible to decision makers um and a<br>bit the other way around to help our<br>researchers understand how to do that<br>connection with policy<br>makers to ensure that academic evidence<br>underpins policy<br>decisions and uh the topic that we'll be<br>hearing about today is one of the four<br>areas that the policy Hub is currently<br>focusing on and in in addition to this<br>Workshop the policy Hub is also<br>supporting various government<br>departments as they consider the<br>appropriate Assurance approach that the<br>public sector should adopt to maximize<br>social benefit while effectively<br>managing risks from the use of<br>AI uh once again I'm delighted to<br>welcome all of you to this session I<br>look forward to hearing Ali and Simon's<br>thoughts on the opportunities and the<br>risks ahead and to the discussion that<br>I'm sure it will spark um and as you can<br>tell by our our pre- inro intro um Simon<br>and Ally are not shy and will introduce<br>themselves so I pass it over to that<br>thank<br>you um my name is s melum um I'm s the<br>the intro Act of the fun enthusiastic<br>puppy in this rooms where I'm kind of<br>yeah AI is amazing it can do amazing<br>things and then Ali tempers me with the<br>well but um and so we've actually been<br>doing this dog and pony show for about<br>20 years right because um I um we we<br>started um first working together back<br>in otago about 20 years ago so got my<br>PhD from atago in the functional purpose<br>of<br>REM I was looking at the way the brain<br>functions right so my PhD is more in<br>Neuroscience than just computer science<br>but a lot of what I was studying and I<br>was learning and the models I was<br>building back in the late 90s have<br>actually been sort of evolving to the<br>point where now they form some of the<br>core of what's in chat GPT the neural<br>networks that are buried deep in the<br>language model<br>uh now yes Ellie and I have both been<br>teaching AI for many years uh I moved<br>into teaching game development and you<br>thinking well what why why would game<br>development person want to talk about AI<br>it's the Innovation that happens in the<br>game industry and the constant change<br>that has meant that when I see AI I see<br>it as this change agent is constantly<br>changing things and so my experience in<br>the game industry is actually quite<br>useful here and you know I've taught in<br>Norway for a bunch of time and other and<br>and um I currently still working in<br>Norway so I do a lot of remote teaching<br>so yeah this is kind of pan spanning the<br>world uh at Victoria we've got a new um<br>bachelor in artificial intelligence so<br>we're graduating our first third years<br>um this year right so they're currently<br>oh no they're they're currently planning<br>our third year we'll graduate them next<br>year I'm graduating my first game<br>developers this year uh we also have a<br>masters and we have many PhD students<br>working in the field of AI right so<br>we've got a lot of research happening at<br>the University uh and as we said we're<br>working on government policy around this<br>because what was just an ivory Tower<br>thing is now washing over the rest of<br>the the society so um gener of AI That's<br>the big thing right chat GPT is the kind<br>of wow suddenly AI is able to make<br>things that make it feel like it's doing<br>stuff at a human level there's doing<br>things that we thought only people could<br>do um and so when you look at what it's<br>doing it is able to extract meaning from<br>language right that is a really kind of<br>deep concept that it's it's not actually<br>doing great reasoning it is just doing<br>this extraction of meaning and then it<br>uses that meaning to develop new con<br>content right so it's doing this kind of<br>understanding at a level<br>which our intuitions don't tell us a lot<br>about what's going on inside the machine<br>right because when we talk to other<br>people and they understand something we<br>say we can infer a whole bunch of things<br>about what's going on inside their head<br>that they're able to understand this<br>meaning but we can't do that with an AI<br>right the AI is extracting meaning from<br>language in a different way so we can<br>talk about how that works and we're<br>going to talk a little bit about what AI<br>is good at so how the AI works as<br>researchers as scientists as a<br>university part of our job is not just<br>to work out how to use something it's to<br>kind of you know rip it apart and find<br>out how it works on the inside so as<br>part of that when we look at the the<br>opening statement for today's session uh<br>we have artificial intelligence uh is<br>advancing and what chat GPT does is this<br>is actually the tokenizer for chat GPT<br>um it turns each of those words into a<br>token into a number now interestingly<br>the word artificial isn't in its<br>vocabulary right AI doesn't know the<br>word artificial that's two tokens for it<br>right because it didn't appear in the<br>first 80,000 words well actually about<br>990,000 Words which are its vocabulary<br>so those 90,000 words you can see each<br>of those tokens is number between 1 and<br>90,000 and those are how it extracts and<br>separates out<br>language it then takes that and turns it<br>into a massive representational vector<br>and so the idea here is that instead of<br>taking each word as a symbol as a thing<br>in itself it tries to separate it out<br>into the components that make up that<br>word right so a word like him right is<br>actually there's a depending on your<br>token size about a th to 4,000 Vector<br>space and what I mean by that is there<br>0.0147 and then next one is negative<br>0.2 there are 4,000 of those numbers and<br>they represent the word him and the word<br>her is a slightly different<br>representation but mostly they're going<br>to be the same number and mostly around<br>zero but there might be a number<br>somewhere in the Thousand which is a<br>kind of gender number and it will go oh<br>him is going to like positive two and<br>her is going to be like negative two<br>right they'll they'll spread out right<br>they'll separate on a particular part of<br>that representation but you also with<br>him and her you'd also have you know<br>both would have a high personhood number<br>and both would have a<br>relating to Society number and so they'd<br>have a collection of numbers now we can<br>then try and match some of that if we<br>just instead of having a thousand<br>dimensional space because you can't get<br>your head into that um if you look at it<br>in three dimensions you can start<br>thinking<br>well that Vector that represents man<br>right and a vector represents woman<br>would be similar to the vector that<br>represents him and the vector that<br>represents her but there's some sort of<br>personal pronoun thing that's been add<br>added what I can do is I can look at<br>those space that massive dimensional<br>space look at the difference between man<br>and woman and if I apply that difference<br>right I look at the okay this is how man<br>is different to woman I took that<br>difference and applied it to the word<br>him I would expect to find the word<br>her right because inside that<br>representation it's represented these<br>relationships between the meaning of<br>words right now and we can see that it<br>does work it does it for Capital Cities<br>the concept of Capital Cities there a<br>concept of timing these are all Concepts<br>that are baked into those 4,000<br>Dimensions that it's able to extract and<br>use to to move<br>around and what we do is we call these<br>edings now uh if you've been following<br>the news Microsoft has just released<br>co-pilot plus<br>PCS which use these in beddings to take<br>everything you do on your computer and<br>store it by meaning right because what<br>it's doing is it's turning a words and<br>sentences and paragraphs into these<br>conceptual meaning and so what they've<br>just recently done is they also add<br>screenshots to that so it constantly<br>watching you and it's storing all of<br>your screenshots in this meaning space<br>right and then you can access it by<br>saying well you know when was I talking<br>about cats and it'll find everything<br>that has a similar representation and<br>bring that back and show you what you<br>were doing so you can imagine You' have<br>this multi-dimensional space and you<br>have a point that was meaning and in the<br>things around<br>it so if we have that representation and<br>if I was to<br>say there was someone who was positive<br>on power positive on female positive on<br>UK positive posi politics positive on7<br>AG who would you guess that was Tracy<br>Chapman right so so Al's language models<br>Tracy Chapman<br>thater Margaret Thatcher and yeah in<br>fact you find that um Claude built the<br>Margaret Thatcher concept right uh and<br>it triggers not just on her name right<br>so you see here it that it's triggering<br>on her name and her name there but it<br>also Triggers on the word her in the<br>middle of a sentence about Margaret<br>Thatcher right because it's not<br>searching for the word Margaret Teter<br>it's searching for<br>what is the thing that most triggering<br>the concept Margaret thater right so<br>that's how these language models working<br>and in fact Claude what you can do with<br>it is you can also get it to drive the<br>Margaret thater concept so they could<br>get the llm to believe it was Margaret<br>Thatcher just by getting into its brain<br>and driving up all of the concept that<br>was Margaret Thatcher so it would answer<br>as Margaret Thatcher you ask it who it<br>was it would say it was marer so though<br>you can do interesting things in sort of<br>Neuroscience<br>now there are lots and lots of models um<br>and uh there are too many and they're<br>developing too fast to keep up with uh<br>if you're interested um although you<br>can't see that there uh if you go to<br>hugging face that's got a great list of<br>of models um hundreds of thousands of of<br>systems that are out there oh and there<br>uh so there's been recent announcements<br>I said co-pilot PCS open AI they're 4.0<br>is still reasonably recent that they're<br>they're hinting that five will be out in<br>the next couple of months so there'll be<br>another jump um Sonet from Claude from<br>anthropic is really good and I'll show<br>you some artifacts in just a sec uh and<br>Google and apple have both said that<br>this generat AI is coming to your cell<br>phones right so it will be part of every<br>operating system you use there will be<br>generative AI that is built into your<br>laptop so won't be a cloud service you<br>will be doing the encoding and the<br>embedding and generating of language on<br>your own machine right so um when we<br>talk about bring your own device you<br>will bring your own language model on<br>your laptop to work right so that's<br>going to be a massive change that it is<br>not just a an odd unusual thing<br>now with these AI systems we're no<br>longer just dealing with a language<br>model we're dealing with much more<br>complex systems so for example<br>in chat GPT there is this gpts system<br>which is where you can tune a particular<br>GPT uh and if I show you here uh last<br>night I created a and I'll just make<br>that larger so you can see it um NZ<br>budget<br>expert right and what I did is whoa okay<br>that's that got confused um I made it<br>too too large uh so a New Zealand budget<br>expert I did this using the C where I<br>just talked to the AI about what I was<br>trying to create in the configuration it<br>then wrote the instruction set about<br>what it expected to do uh and I then<br>added<br>the oh if I can get my mouse pointer to<br>actually grab the right part of the<br>screen ah there um I added the Buu for<br>24 and the b53 and the data tables as<br>Excel Str it so I just added those in<br>and now this particular language model<br>has access to all that information those<br>are budget updates yeah those are the<br>budget updates and the the financial<br>updates for the budget are both as the<br>expense tables and when I can now ask it<br>questions here and I asked it a question<br>and then it generates all of this<br>context but what it's doing here is if<br>we have a look um I asked<br>it um create a graph of the difference<br>in funding levels for Education versus<br>the military for example right if I and<br>and what it does is it doesn't just use<br>a language model it doesn't just kind of<br>try and ingest all the meaning and go<br>well can I extract meaning from here it<br>starts writing python code but what it<br>does so it writes in Python code it then<br>finds that it's got some errors in the<br>python code and so it analyze it and go<br>a I got errors let's write some more<br>python code and extract some additional<br>information about what the tables are<br>and then having extracted information<br>about tables it then tries again to<br>write python code to extract information<br>so this is showing what we call agentic<br>Behavior right I've given it a task it<br>then starts extracting information it<br>writes code to extract information when<br>there are a it fixes that code writes<br>new code because it it's learned right<br>so we we've taught it that it's not good<br>at numbers but coding is good at numbers<br>so instead of trying to extract numbers<br>directly by going oh three is a concept<br>of a small number two is the concept of<br>a small number therefore if I go to the<br>supermarket with three children and I<br>return home with two children that's<br>fine because it was the concept of small<br>children right small number of children<br>I still have a small number of children<br>what's your problem right so it's we've<br>learned that it's not good at<br>math right so what what it does now is<br>it writes computer code that extracts<br>numbers and processes them with code so<br>that it can get the numbers right right<br>so that's one of those big changes is<br>that we're no longer looking and I can<br>show you in real time when we ask<br>questions I can show you in real time<br>how that works but it will go through<br>this process of generating code and it<br>will generate graphs and it will<br>generate artifacts in fact Claude will<br>generate websites and I can generate<br>interfaces in real time so I have all<br>those demos we can show um this is part<br>of what I was saying agentic Behavior<br>Where It Starts building stepway<br>processes on top of just giving you a<br>chat response right so that's where this<br>is going now as when we start looking at<br>how we can make government more<br>efficient the idea that we have a tool<br>that can write code for us that can draw<br>grass for us that can step through<br>problems with us when we steer it is<br>makes us massively more efficient um and<br>so as I said it's coming to all devices<br>the windows co-pilot PC did pause their<br>recall function because people felt that<br>doing a spring shot every 3 seconds and<br>storing everything you were doing on<br>your laptop in plain text on your laptop<br>might be a security<br>problem and so they went oh we don't<br>know how to solve that so we'll just<br>turn it off so you can buy the PC but<br>it's currently turned off but they're<br>going to turn it on probably and we<br>don't know what that means when we have<br>perfect recall on everything you did by<br>accessing a language model that can<br>extract all that meaning can write code<br>to extract data and can generate<br>visualizations and content so with that<br>I was gonna hand over to Ellie this<br>feels like being in church do you think<br>it's like the Church of AI or something<br>about I'm going to tell you about your<br>new Masters or something like that early<br>in the morning and it's like you know<br>it's spread like here's the puled um so<br>I'm doing the kind of like the Hellfire<br>and brimstone part gen AI is the focus<br>we're not just talking about AI there's<br>all sorts of AI stuff that does rather<br>you know conventional normal things that<br>have been done for years in government<br>and Industry uh predicting outputs from<br>inputs and so on this is generative Ai<br>and this is this more creative thing and<br>that's the focus for today's seminar and<br>like Simon just showed it can do amazing<br>things and there's all sorts of<br>potential for this to make efficiencies<br>in any organization government or or<br>other um but it comes with special risks<br>and and I'm thinking about the risks<br>specifically of large language models<br>which is most of what Simon was talking<br>about Simon was also talking about AI<br>that can generate other modalities or<br>that can interact between other<br>modalities in language but I'll focus on<br>language<br>here because I think that like in the<br>public service most of what's going to<br>happen will involve language processing<br>in this generative<br>world so I I'll mention a few risks so<br>one of them is that the output of of of<br>a large language model it generates some<br>text let's say in response to a question<br>you have or it might even generate some<br>code but that can be unpredictable and<br>that makes this software completely<br>different from anything that you will<br>have seen before so I just want to put<br>some examples up uh you know when you<br>when you buy software it's been tested<br>inhouse and and then when you get it it<br>comes with certain guarantees uh so for<br>instance a spreadsheet is a good example<br>like if a government Department was<br>buying a spreadsheet they wouldn't have<br>to go away and test it because you know<br>they can rely on it working out of the<br>box<br>um and you know the same with the word<br>processor if you're you know personal<br>user or something like that or you don't<br>have to do that um and you might have to<br>check things like you know is is is the<br>Privacy uh settings right or um you know<br>is people's personal data being safe and<br>those kind of questions and those are<br>sort of the due diligence processes that<br>people are used to doing um but you<br>don't just do those things you have to<br>do more than that with generative AI um<br>and that's because uh these things<br>required through machine learning and uh<br>and what that means is that you know<br>they're trained on one set of data and<br>then they're deployed somewhere else I<br>suppose and and that's true with all<br>machine Learning Systems including the<br>kind of old fashion ones that we that we<br>understand quite well um they operate on<br>on inputs that they've never seen before<br>so all those examples that Simon was<br>showing you know he's typed of prompt to<br>to Claude or to chat gbt uh that it's<br>never seen before and so we're in a<br>slightly different situation from you<br>know a situation like a word processess<br>or a uh spreadsheet where you can kind<br>of prove that the code does what it's<br>supposed to do before you releasee it um<br>so the sort of the key Point here is<br>that language models are not normal<br>software and you need to treat them<br>differently with more<br>caution um and now I'm want to talk<br>about the particular sort of machine<br>learning which gives you a generative<br>model because it's different from the<br>normal ones you can trust some sort of<br>Machining learning devices more than<br>generative<br>Ai and this is because the traditional<br>machine learning systems are trained to<br>do one particular task and then deployed<br>in the field to do that same task so let<br>me give some examples let's say you have<br>something that takes an image of of a<br>mole or something on your skin and and<br>tells you yes or no whether that's<br>cancerous like that okay the system is<br>trained on exactly instances of that<br>task lots of skin cancers which are yes<br>no cancer lots of skin lesions which are<br>yes no cancerous or here's another one<br>system for predicting hospital bed occy<br>you train it on a bunch of data about<br>actual hospital bed and how long it was<br>how long they were there for so you're<br>training on one task and then deploying<br>it for exactly that same task but<br>language models aren't like that and<br>generative AI in general is not like<br>that a language model um Simon didn't<br>mention that but they're trying to do<br>something very different from what he<br>was uh using it for and that's a key<br>point right so a language model is<br>actually trained the way that it's<br>optimized is it's trained to predict the<br>next word in a sentence or the next word<br>in the text it's like if you have this<br>word if I say um llm are trained to<br>predict and I'll let you complete the<br>next word that's the task that language<br>models get good at so they're good at<br>continuing texts in coherent ways does<br>that make sense that makes sense that's<br>what they<br>do but that's not what they're used for<br>the tasks that they're used for are<br>defined much more abstractly answer this<br>question you know um uh write this piece<br>of code uh so the reason why they can<br>perform lots of those tasks very well is<br>they're trained on a huge amount of dat<br>data and they've got very clever ways of<br>generalizing away from that data so<br>they're good at doing these new tasks<br>you know these more abstractly defined<br>tasks which kind of boil down to this<br>kind of word prediction task you know if<br>you ask it to answer a question it<br>predicts the next word of your request<br>and then the word after that and the<br>word after that and that's how it ends<br>up producing a text but that doesn't<br>guarantee that the output is going to be<br>the right answer to the<br>question so uh it uh it allows them very<br>well in many cases because it's able to<br>generalize so well because it knows so<br>much and these days like Simon was<br>saying you can give it particular<br>documents and say refer specifically to<br>those documents um and that helps it you<br>know deliver sort of like meaningful<br>answers but underneath you know in<br>inside the guts of the thing it's still<br>just trying to produce coherent text its<br>output and that means it can mess up<br>spectacularly and people have come<br>across you know you will have seen in<br>the news this concept of hallucinations<br>I won't talk in detail but that's the<br>problem that arises because they're used<br>on tasks that they're not<br>PR here's another one being a little bit<br>controversial here um actually this is<br>the same risk it's not a different risk<br>so I'm I'm being very technical with<br>this use of the word volid um there's<br>this beautiful uh work by a philosopher<br>called Harry Frankford called on<br> I recommend you read it um so<br>he has this beautiful this is like a<br>needed definition for him is a<br>technical term it means speech intended<br>to persuade without regard for truth<br>it's like just flanneling on to indicate<br>that you know something so a few<br>examples that you know he comes up with<br>like a student who's writing an essay or<br>answering an exam question they don't<br>know what what you know anything and so<br>they just write something right you know<br>to try and persuade the marker that they<br>know something that's in technical sense<br>for Harry<br>hamburger a politician who says<br>something with the intent to please<br>voters without regard to the truth right<br>so he says that is even more<br>damaging than lying because um you're<br>not even trying to deceive uh you're not<br>trying to convey facts you just don't<br>care about the truth um what you're<br>trying to do is just present kind of<br>coherent looking words that seem to<br>follow the words that you've just been<br>given right does that even make sense<br>I'm being a bit<br>provocative so there's an interesting<br>paper in ethics and information<br>technology just a couple of months old<br>no month actually uh arguing that that<br>lm's proportion so worth worth a look<br>both at the original paper and at that<br>um so here's another risk this is sort<br>of like this is a bit of a different one<br>so now we're talking not just about the<br>fact that language models were optimized<br>very carefully optimized for producing<br>the next word but are used for some<br>other tasks this is a fact about their<br>inherent um operation which has got a<br>lot of rolling of dices in it so<br>language models produce their outputs<br>one word at a time or one word token<br>might produce half of the word uh you<br>know as in Sim<br>case um and each word they choose they<br>actually have a probability distribution<br>over all the words or all the tokens in<br>the language and then they pick randomly<br>from those with a preference towards the<br>ones which have got higher probability<br>but if you ask it you know the next time<br>around um you're probably going to get a<br>different answer and if you uh you know<br>you can you can turn down the<br>temperature in many of these systems and<br>so that it's more reliable actually it's<br>quite difficult to get it to be<br>completely reliable yeah there's some<br>there's still some non-determinism in<br>the way the graphic cards work and so<br>like floating Point numbers are always a<br>problem for Mass because when you<br>calculate them so it still does a little<br>bit variation but this is this makes it<br>wildly different from most of the<br>software that we know about and so again<br>this is I'm just being a kind of like<br>I'm being sort of like preaching caution<br>a little bit here um out of the box they<br>choose stastically from the from the<br>predictive distribution and you get a<br>different output each time and then<br>because you produce one word at a time<br>there's a Randomness which is<br>compounding by another Randomness and<br>another Randomness and so on it's like<br>are we okay with that okay so do we<br>really want to deploy our language<br>models or other generous tools that work<br>in that way and using those Public<br>Service I'm being provocative right I'm<br>being alarmist to make a point because I<br>think they do have a great use but we<br>have to be really careful my real point<br>is that we if you're going to use it for<br>some you know particular application you<br>need to evaluate the hell out of it uh<br>wherever you are looking at and you need<br>to be very pragmatic very empirical<br>about this evaluation evaluate it many<br>times quanti ly and then see how many<br>errors it makes see how many awful<br>errors it makes and so on so that that's<br>my real<br>point you can't just look at a few<br>examples because there's this kind of<br>tendency for the good usage or the you<br>know the clever outputs of a language<br>model to disseminate around because that<br>you know information spreads in in<br>situations where we're surprised or<br>amazed and stuff like that um and so we<br>see hey wow this looks good because I've<br>seen one example but that's just like an<br>availability horis that we should be<br>very care cautious<br>about so then you need very kind of<br>systematic due diligence processes and<br>exactly what those should look like is<br>still being you know developed basically<br>this is this is an active area of<br>research how can you um quantitatively<br>assess the performance of a generative<br>AI model for some particular task um so<br>yeah like I said it's actually you know<br>still basic research and so<br>again New Zealand government departments<br>should be looking into this because we<br>don't want to for behind but at the same<br>time we need to realize that what's<br>going on is still being worked out at<br>the level of research uh so we have to<br>be<br>cautious uh so I'll sketch a couple of<br>things which are sort of like being used<br>at the moment in in the field in in the<br>research area um one thing is to say<br>that we need separate evaluations for<br>each task okay um each time for each<br>task you design a prompt and Simon<br>showed you a few of those and then<br>there's a broader architecture these<br>days as well where you might have some<br>some uh particular particular document<br>that's that's to be focused on and and<br>uh there might be agentic kind of<br>processes that you have that might<br>iterate over some things and they might<br>be controls at the end to sort of check<br>outputs and so on for all of that you<br>need to design one of those and when you<br>have decent something decent then you<br>need to evaluate how well your custom<br>Works your custom language model works<br>for that particular T and what that<br>means is doing lots and lots of Trials<br>on lots of plausible inputs um and then<br>quantifying how well it performs you<br>know in how in what percentage of Trials<br>does it work well and and what<br>percentage of Trials does it work badly<br>or awfully and that sort of stuff so all<br>of evalu all of AI involves quantitive<br>evaluation that's how you do training in<br>the first place and so this is no<br>different from there except out in the<br>in the places where people are using AI<br>um that's not necessarily widely enough<br>known so that's my job<br>is if you change your prompt or change<br>your architecture all bets are off you<br>might have to start again and evaluate<br>again because you might have changed<br>something quite fundamental about how it<br>works<br>so how do you evaluate a language model<br>on some specific task let's say in the<br>New Zealand government or something like<br>that there's Benchmark methods which get<br>widely used in research and these are<br>used to compare clae and CH different<br>versions and so on and what you do is<br>you have a bunch of examples of good<br>task performance for this output here's<br>a good out here for this input here's a<br>good output this input here's a good<br>output those are created by human<br>experts and then uh and then you can run<br>your own system against those uh and see<br>how your systems outputs correspond you<br>know with the gold standard ones in<br>those cases if you want to do that<br>properly you need really quite large<br>sets of example queries and responses um<br>and um and then once you've got that<br>then you can uh evaluate automatically<br>which is quite nice and so if you change<br>your query or change your architecture<br>change your prompt um you can run it<br>again just by pressing but you know go<br>away and evaluate on that Benchmark<br>however benchmarks have to be big and<br>I'm not sure that New Zealand government<br>departments uh have the resources to<br>create benchmarks for all their tasks<br>and there might be a better way and also<br>the automated marking methods which are<br>basically ways of comparing two free<br>texts to see how similar they are those<br>are also a working<br>program so the second thing you can do<br>and this is where I'll finish so this<br>time for questions um is to use more<br>like a human evaluation method so here<br>what you do is you just you know you set<br>up your language model to do a task and<br>then you just ask a human how well the<br>system responds in this case in this<br>case in this case in this case for 1,000<br>or however many examples and so there's<br>some there's some painful labor there<br>for the human evaluator who seems to sit<br>there and sort of like grade the the<br>lm's responses um so there's no<br>automated scoring process because<br>there's just a human who's giving<br>intuition about how well things work and<br>giving a mark basically um so the human<br>can assess the language model by itself<br>just on an absolute scoring scale or<br>they can assess the language model um in<br>um<br>um uh so that's like a sort of uring<br>test so the human ver the language model<br>versus human tests are particularly<br>useful because you want to know is this<br>a task you know which is being better<br>done by the language model than by human<br>employee human employees make mistakes<br>as well and we need to evaluate those<br>too um so my my sort of finishing point<br>is just that that uh for New Zealand<br>government Department that might be the<br>way to do everything and I think I'll<br>finish there and and I hate to have to<br>to draw this uh really fascinating<br>session to a close I think it was a<br>really uh amazing and stimulating way to<br>start our day um poses lots of questions<br>shows the<br>possibilities shows us what our<br>responsibility is in um evaluating when<br>and how we use these tools uh but also I<br>think the other key point was that let's<br>do that collectively because I think the<br>shared effort uh will help us all move<br>forward um I know you'll have a million<br>further questions um Ali and Simon are<br>available but also contact us through<br>the policy Hub um to see if we can<br>facilitate some of those shared<br>conversations so finally um just join me<br>in thanking Simon and Ellie for an</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>