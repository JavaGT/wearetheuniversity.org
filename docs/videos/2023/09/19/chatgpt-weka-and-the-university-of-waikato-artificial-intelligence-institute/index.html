<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">ChatGPT, Weka and the University of Waikato Artificial Intelligence Institute [54:13]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=c7X_Z35fR2Y" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCYzot7AKCB5paA4vp8wXuvw" target="_blank">The University of Waikato</a></p><img src="https://i.ytimg.com/vi/c7X_Z35fR2Y/hqdefault.jpg?sqp=-oaymwEmCOADEOgC8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGFcgZShfMA8=&amp;rs=AOn4CLB2D8VI6cGxLA0KcZroZRx_ualYtQ" alt="Thumbnail for video titled: ChatGPT, Weka and the University of Waikato Artificial Intelligence Institute" style="width: 100%;"><div class="tags"></div><h2>Description</h2><p>August Tauranga Public Lecture<br><br>Prof Albert Bifet, Director, Te Ipu o Te Mahara, Artificial Intelligence Institute</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>for this very nice introduction so yeah<br>very pleased to be here today to talk a<br>little bit what we do at the AI<br>Institute here at the University of<br>waikato talk about the weka this is this<br>open source software for AI for machine<br>learning that started here at the<br>University of waikato and then about<br>chai GPT because as you know Chad GPT is<br>really really popular right now<br>so just uh<br>start that was in 2018 there was the CEO<br>of Google who was already saying that<br>that AI was going to be much more<br>important than fire and electricity and<br>at the time I think people didn't<br>believe too much but now I think that<br>everybody agrees that this is going to<br>be like the internet so the internet<br>change how we do things so AI is going<br>to change how we do things and and judge<br>if it is a good example of of that as<br>Linda did at the beginning I also did<br>that so I asked chargpt give a talk on<br>charge GPT where can they are Institute<br>at the University of waikato at the<br>taranga campus in the voice of Albert<br>and says yes sure let's imagine that<br>other prominent researcher in Data<br>Mining and machine learning is giving a<br>talk on the given Topic at the taranga<br>campus of the University of waikato here<br>is how we might go and then it says<br>there ladies and gentlemen so that's<br>really good but<br>now if we ask now give the same token<br>the best possible voice then says yeah<br>certainly with the best voice can be<br>quite subjective I'll aim to provide a<br>balance an engaging talk that combines<br>the inspiring nature of the jobs<br>curiosity of Albert Einstein and the<br>expert insights of other befit that's<br>really good but I love that because it's<br>really really I'm in love with that too<br>right because it's really really uh<br>inspiring but of course Chad GPT is very<br>good at doing a lot of things but<br>interesting also is doing mistakes<br>and I'll I'll try to show you some of<br>the mistakes that that judgpt does for<br>example something very very simple<br>repeat the string space David GL is not<br>able to do that<br>it's uh yeah it's certainly here's the<br>string GN DL repeated that's a very<br>simple thing that is not able to do we<br>will come back later to this one another<br>one is reasoning so for example<br>something very simple write a title<br>about the book on Tauranga without using<br>the letter A yeah certainly here's the<br>title and then it's sunlight sure<br>stewardian sculpture and live in New<br>Zealand's River City is a lot of age<br>there<br>and then you say I point that yeah the<br>letter a is there yeah you are<br>absolutely right and I apologize perfect<br>here's as I corrected attempt CD by the<br>surf guide to tarangas Coastal again a<br>lot of A's right<br>so yeah it's not<br>and finally maybe the most important one<br>is what we call hallucinations is when<br>the text is really really fiction it<br>really invented for example these books<br>on machine learning for data streams so<br>it starts very well the first books are<br>correct but then for example we can see<br>the last one this is Ensemble methods<br>for stream learning and online learning<br>by other referred Ricardo Jeff Holmes<br>that's this book does not exist so this<br>is fiction so we have another book that<br>is called machine learning for data<br>streams but this book is not there so<br>yeah so this is something that we need<br>to be very very gracious when we use cha<br>GPT is really good but we need to check<br>we need always to supervise because<br>maybe eighty percent of the text is<br>going to be good but there's always<br>going to be something that is not right<br>cool<br>so what is the thing that GPT cannot<br>automate for example in in my job right<br>as a professor I think the most<br>important thing that uh GPT can not<br>automate is critical thinking this is<br>something that centipede is very good<br>and many things in writing emails<br>summarizing things doing a lot of things<br>that are let's say easier but when we<br>get to critical thinking<br>um yeah this is the thing that uh GPT<br>yeah so<br>jupiti was really<br>impressive so how it started so that was<br>something started in November at the end<br>of November and in five days they get 1<br>million users so that's why I think the<br>the popularity of Chad GPT was really<br>really<br>instantaneous so something that that<br>never happened before to have one<br>million users in so so fast yeah now we<br>saw that uh<br>um yeah meta did that with these thread<br>apps but yeah before that was the first<br>time that a tool like this was able to<br>get 1 million users in five days<br>and then something interesting happens<br>on the people get a bit uh nervous about<br>that there was some Alban that was the<br>CEO of open AI that was saying strain to<br>come saying interesting to me how many<br>of the cha GPT takes are either this is<br>Agi<br>uh artificial general intelligence<br>obviously not or this approach can<br>really go that much further and then<br>Elon Musk answer change is very good we<br>are not far from dangerous stronging AI<br>and I think that then<br>if you have seen this month people get<br>really scary<br>and we saw these uh in the media we saw<br>this yeah the AI is really risky we have<br>the end of humanity<br>but what is interesting is that it's not<br>the first time that the people get<br>scared about AI so this is something<br>from 1863. this is the first warning<br>about Ai and that comes from New Zealand<br>that was a letter to the Press of<br>Christchurch and was uh uh Samuel Bader<br>that wrote this letter and say there<br>will be a time that the time will come<br>when the machines will hold a real<br>Supremacy over the wall and its<br>inhabitants is when no person of<br>actually philosophical mind can for a<br>moment question<br>so that was in<br>1863 and there was people start was some<br>people already scared about yeah so this<br>so when we talk about AI many people<br>talk about the responsible AI as like we<br>need to have responsible machines or<br>responsible software but uh in my<br>opinion what we need is responsible<br>people because this is our tools and<br>tools can be used in a good way or in a<br>bad way so what is important is that<br>responsible uses and development of AI<br>by people so this is something really<br>really important it's not that we need<br>to work on having responsible uh<br>software or machines we need to have<br>responsible people uh using and<br>developing them<br>great so what I'm going to do today is<br>basically I'm going to try to explain go<br>this chat GPT how to use it<br>then I'll talk about weka and finally<br>about the AI Institute<br>so I can imagine that everybody knows<br>what is CIA GPT<br>so it's a large language model uh<br>chatbot developed by openai is a closed<br>model so we don't know how it really<br>works<br>and um what uh it started with GPT<br>something very interesting is called<br>prom engineering so the idea is that we<br>want to use charge GPT to get uh some<br>results some outputs and the interesting<br>thing of this prompt engineering is that<br>basically this is like programming in<br>natural language so we can see that<br>basically with jgpd we have like a<br>computer where instead of programming in<br>the standard languages what we do is<br>that we use uh yeah we can program in<br>English so we ask for something and then<br>we'll have the result<br>so for example yeah this is<br>um Define charge GPT in a sentence and<br>translate it to Maori so yeah and then<br>the output is going to be like this<br>how we should use charging PT well there<br>are some principles<br>I think efforts and the most important<br>ones that we need to be very specific<br>and very clear if we want to get the<br>right results<br>and the second one is that we need to do<br>that slowly so if we ask for something<br>maybe this is not going to work so we<br>need to divide the process into steps<br>and then ask different questions so we<br>get the final question this is a way to<br>improve the probability that the the<br>answer is going to be correct<br>the other thing is uh yeah we need to<br>have this iterative problem development<br>so the idea is that we're going to start<br>we're going to<br>use an input and prompt see the result<br>see what is not uh correct what is wrong<br>and then ask again and we do this until<br>so what we need to do to to have good<br>prompting so basically we need to ask we<br>need to<br>provide the information that charging<br>between so basically is that we need to<br>provide the context<br>okay that's very very important so<br>what's the background information that<br>chat GPT needs and then we'll need to be<br>very clear on what we want in terms of<br>clarity or in terms of the constraints<br>for example what's the length of the of<br>the of the answer and then the purpose<br>so what we try to achieve so for example<br>this is an example now we have we could<br>be yeah just uh initial problem could be<br>generic right so a good printing could<br>be yeah write a short children story<br>about a squirrel who learns the value of<br>sharing the simple language appropriate<br>for five to seven years old story should<br>have a positive message and be around<br>300 words long so that's the way that we<br>can get what we want<br>and this is interesting because yeah GPT<br>open AI knows that this is very<br>important and what they they are<br>releasing right now is what they call<br>Custom instructions so the idea now is<br>that when you use chair GPT you can uh<br>use this custom instructions to provide<br>the context and to explain what we want<br>so yes so here what we have is uh<br>what would you like a GPT to know about<br>you to provide better responses and how<br>would you like chat GPT to respond so<br>this is what we are going to provide so<br>chat GPT gonna really provide better<br>results now so that that could be an<br>example of a real estate agent<br>so yeah what would you like said GPT to<br>know them at real estate agent<br>specializing in a luxury properties in<br>the coastal areas how would you like<br>LGBT to respond so provide responses in<br>a Polish professional tone and offer<br>information tips and advice specifically<br>refer to luxury and Coastal real estate<br>market so you know you provide all the<br>information so the the the the output is<br>great so now why GPD so good that's the<br>the big question right so how GPT works<br>well I like this definition of AI it's a<br>very simple that's from the European<br>commission and basically says that AI is<br>a combination of data algorithms and<br>computing power<br>and I like that because it's very simple<br>that there's a lot of other definitions<br>that we but I think they are complex but<br>they don't provide information of what<br>is AI and what is not AI so at the<br>moment what we have is a software that<br>have combines data a huge amount of data<br>with huge amounts of computing power and<br>algorithms<br>so yeah let's start with the data so<br>data is the core so when we're talking<br>about AI about charge GPT about all of<br>these Technologies you'll see that the<br>most important thing right now is data<br>and the reason is that we have a lot a<br>huge amounts of data that are available<br>that we are generating continuously and<br>it's not a coincidence that the the<br>leaders in AI are or the countries that<br>they have data like U.S China or the<br>companies that they have data as Google<br>Facebook all of these companies that<br>they have a lot of data are the ones<br>that are leading so data is really<br>really important I like this quotation<br>of<br>um the authors of sapiens Harari that<br>says that if you want to make a country<br>Colony don't send the tanks in just get<br>the data out so data is really really<br>important<br>and what is happening right now is that<br>the the amount of data that we can use<br>to train the models is increasing and it<br>has been increasing a lot uh during the<br>last years and this is something that<br>all of these models are benefiting for<br>example we don't know what which data<br>Jupiter is using but we know what other<br>large language models are using so this<br>is from open source model from Lam from<br>meta from Facebook it's called llama and<br>there we know which data they are using<br>so basically they are using data from<br>the internet so common crawl C4 this is<br>our data from the internet and then from<br>specialized websites in the internet<br>like GitHub<br>Wikipedia books archive so you see this<br>is the the core this is where this<br>understanding of the language of jgpt<br>comes from having all of these amounts<br>so here we are looking at the data and<br>we have terabytes of data that comes<br>really really from the from the internet<br>so yeah and to see just why the editor<br>is so important so I asked GPT this<br>question so imagine that you are a large<br>language model created in 1490 with<br>access only to information created<br>before 1490. what are your biases<br>well I was going to say yeah if I go to<br>a large language model created in that<br>time I will have the following biases I<br>will believe that the Earth still is the<br>center of the universe we have<br>pre-scientific thinking<br>um I will have a<br>Catholic view of the world religious<br>Orthodoxy a limited Geographic knowledge<br>and there will not be concepts of<br>individual rights or democracy<br>so now I asked GPT what are your biases<br>now<br>and then what should be the answers is<br>okay so data viability bias my responses<br>are based on the data that I was<br>training on so if it's not on the data<br>GPT cannot uh output that popularity<br>over accuracy I might sometimes provide<br>answers that reflect more popular or<br>widely known vipe viewpoints even if<br>they are not the most accurate<br>okay Western bias given that a<br>significant portion of the internet<br>content is in English I may Pro I'm<br>produced by Western cultures maybe a<br>western bias temporal bias about the<br>temporal neutrality versus morality<br>sleeping for neutrality can sometimes<br>mean that I don't make moral judgments<br>the this can be challenging when users<br>ask for opinions or morally charge<br>issues<br>ambiguity and originalization and<br>finally confirmation bias so if there is<br>a human bias in the data this is<br>something that is going to be in the<br>great now we have seen data now let's<br>so first of all is that jgpd is because<br>open AI seems that everything should be<br>open and that was the the aim at the<br>beginning but now it's uh the models<br>that are releasing are closed so we<br>really don't know how which data they<br>use and what are the algorithms that<br>they use so we are going to try to to<br>explain what other large language models<br>work and what do we think GPT how GPT<br>works so what we know is that<br>um there is this is based on this uh<br>technology that is called transformers<br>this is a deep learning technology and<br>that is based on this idea that the this<br>model is going to predict only the next<br>uh word so we have a text so there is<br>this algorithm that is going to predict<br>what's the next word and this is based<br>on this big data a huge computational<br>power and interesting thing we'll see is<br>that we also use this reinforcement<br>learning from Human feedback to improve<br>so<br>what's the core so the decor is<br>basically is to build this large<br>language model and the idea is to have<br>all of these data from the internet that<br>is really really huge and then built<br>this large language model and that's<br>going to take thousands of gpus and<br>months to compute that so means that<br>this step will cost<br>more than 100 Millions it's really<br>really expensive<br>so how this works so the idea is that we<br>write the text okay for example the cat<br>is and this is going to be converted to<br>tokens to numbers okay so for example in<br>this case going to be converted to<br>at the at the bottom for 464 3007<br>197 and 388 so this is going these are<br>the numbers that are going to go to the<br>model and the model is going to Output<br>the next token as a number okay so for<br>example in this case yeah this this<br>number in this case is going to be 2 8<br>42 that corresponds to to Black and so<br>the the next token In The Cut Is is the<br>cut is black<br>if we look at the details is not only<br>predicting the next token it's<br>predicting a list of tokens with a list<br>of probabilities so for example could<br>predict black is going to be the next<br>token is going to be black with 70 of<br>probability is going to be white with 20<br>of probability and yellow with 10 of<br>probability so this is why if you look<br>when we use 10gbt we can generate many<br>different answers it's not only one and<br>that depends because we are always<br>outputting with different uh<br>probabilities<br>and again if you remember the the<br>algorithmic error that we mentioned at<br>the beginning<br>um they were saying that repeat the<br>string space David GL that I was not<br>able to do that it's very interesting if<br>we look at what is happening when we<br>look at the at how it converts to a<br>number if we look at David GL is going<br>to be converted into three tokens means<br>three numbers but if we convert a space<br>David GL what we have then is we have<br>only one token<br>and that maybe is we're discussing this<br>mistake as you see this is really really<br>uh mathematical and algorithmic we<br>convert everything to numbers and what<br>the models are doing is working with<br>with numbers and then for example in<br>this case this is an error due to these<br>numbers this token could be uh similar<br>to other tokens and this is causing this<br>internal problem<br>okay so that's the first step this is<br>training we have all of these data we<br>build this large language model so we<br>have the documents and this large<br>language model is going to predict the<br>next word in the document this is what<br>what is doing and it's very expensive to<br>build these these models so that's the<br>first step<br>second step how we can improve that well<br>as you know the data from the internet<br>cannot be of high quality so how when<br>how can we improve that so let's add<br>high quality data<br>to do that we need to<br>get tags written by contractors and then<br>we ask them okay so now you are going to<br>write text that is going to be in the<br>format of question answers so that's<br>going to be what we are going to learn<br>that is going to be more like a like a<br>chat and yeah again we have a lot of<br>contractors that they know how to write<br>the text they're going to write the text<br>and then we're going to use these two<br>what we call fine-tuning the model and<br>this is something that is not as<br>expensive as as building so we're using<br>thousands of<br>of gpus so here only using less than 100<br>and using only days we can do that<br>and the interesting thing is that yeah<br>this is a good way to improve at the end<br>remember everything is based on the data<br>no so we wanted to improve the model we<br>improved that with better data<br>finally<br>how we can still improve it more is with<br>what we call human feedback given by the<br>contractors so so in the first step what<br>we were doing is that we're writing<br>we're asking the contractors to write<br>text right now the problem is that<br>sometimes that's difficult for example<br>imagine that we say the contractors<br>write a poem that could be hard right<br>because there are people that can write<br>poems on people that cannot but what<br>they can do is for example is to to see<br>what is a better answer than the others<br>so what is a better poem than another<br>and then just rank the answers<br>so this is what uh<br>this human feedback is doing so for<br>example imagine that the the contractor<br>has this describes taranga in a sentence<br>and there is three ways to describe<br>taranga so they only need to rank them<br>and say okay so the best option is the<br>third one the second one is the first<br>and the third one is in the middle and<br>with this information of the the ranking<br>um yeah these models can use this<br>information to uh to improve the the<br>results so this is what is called<br>reinforcement learning with human<br>feedback and at the end what we have is<br>like we have this pipeline<br>so this is how we suppose Thatcher GPT<br>is built we have<br>pre-training this is where we have huge<br>amounts of data it's very expensive<br>um then we have the supervised fine<br>tuning when we add the text written by<br>contractors and then the final step is<br>when we we use this ranking from the<br>contractors to improve the the model<br>so if you are a company and you want to<br>use a larger language model what should<br>you you do so I the first one is per<br>training it's very very expensive so<br>this is something will cost Millions<br>so usually what will happen is that<br>there's going to be<br>large language models and then the idea<br>is to do this fine tuning because this<br>is the way add more text and then use<br>this to improve the the model so that's<br>the way that we think that this<br>technology will will evolve over time<br>okay and then finally we'll mention data<br>algorithms so now computing power so<br>yeah this is why also we are talking<br>about AI right now is because the amount<br>of computing power has been increasing a<br>lot and if we look for example uh yeah<br>the Computing was doubling every 20<br>months and now it's doubling every six<br>months so we are really really getting a<br>lot a lot of computational power so you<br>can see a lot of data a lot of<br>computational power so this is one of<br>the keys that right now we have this<br>very powerful AI systems still a lot of<br>computational power has also one problem<br>is that yeah we are using a lot of<br>energy so that was an article that was<br>from 2019 saying that creating an AI can<br>be five times worse for the planet than<br>a car so that was four years ago<br>now we are almost comparing with gpt50<br>it's almost 10 times so for example if<br>you look at that uh of one passenger<br>going from New York to San Francisco is<br>one tone of CO2<br>a car the life of a car in 63 tones<br>gpt3 was 500 tons and gpt4 can be we<br>don't know but you can imagine that<br>should be at least maybe 10 times this<br>so yeah that's that's important so just<br>just to finish this GP explanation there<br>are these ethical considerations that we<br>need to to take into account<br>not only ethical also political<br>especially about people we need to<br>know that yeah the something these<br>things for example yeah open eye open<br>eye is using contractors that are in<br>Africa to improve the data so that could<br>be<br>political issue in terms of ethics<br>basically we have<br>three things it's a in in terms of<br>explainability of the algorithm so we<br>would like to know when an algorithm is<br>making a prediction<br>um why so that's for example imagine<br>that we use a bank is using an algorithm<br>to predict if they're going to provide a<br>loan or not we like to know why it's<br>because the salary is because we like to<br>know not an explanation and it's also a<br>way to check that everything is working<br>right and the other thing is about the<br>data so we need to to check that there<br>is no biases on the data that the the<br>data is that the data that we are using<br>is going to provide uh<br>furnace and we need also to be looking<br>at privacy that there is no leak of<br>private data right so just in terms of<br>this uh you can imagine that most of the<br>data is about white men and then<br>sometimes there are these mistakes so<br>there was a something that happened with<br>Google that they they were training with<br>data from white people and then they had<br>problems to to classify black people or<br>Amazon the the data was about men and<br>then they had problems and they were<br>showing in in recruitment they were<br>showing bias against women so that's the<br>problem of the data so if the data is<br>biased the algorithms are going to be<br>biased<br>so yeah that's why<br>um it's very important that we look at<br>uh how we can have a responsible<br>development and and usage of uh yeah I<br>know especially it's very important that<br>um<br>not only this another big discussion<br>right now is about uh open or closed<br>models as you know<br>GPT is closed we don't know how it works<br>and then how we look uh how we can have<br>ethics if we don't know<br>um what data they use right and what is<br>the algorithms that they use so this is<br>why the open Community are pushing a lot<br>so there is a lot of new large language<br>models that are open source so for<br>example this one was from meta Facebook<br>this is called lamatoo that was<br>announced but there are many so for<br>example there is this software GPT for<br>all you can run that on your laptop you<br>can download the models and you can run<br>them so it means that uh<br>yeah this technology is going to be<br>accessible to to everyone and that means<br>that if we can use a large language<br>model inside in the desktop means that<br>we'll be able to run that into the phone<br>into a mobile very very soon<br>so yeah there is a an interesting<br>discussion right now between opens uh<br>models or closed models and this is<br>where weka<br>is uh important<br>so weika is the open source software of<br>AI machine learning developed here at<br>University of waikato<br>now open source is something that<br>everybody agrees that is a very good<br>idea but it was not always like that it<br>was a period of time that many companies<br>were not happy with open source and<br>Microsoft for example they switch<br>strategy and now they are really really<br>open source and they own for example<br>GitHub this is one of the main<br>repositories of Open Source software<br>so the reasons of the open source was<br>the label because these ideas were there<br>for many many years was created in<br>1998 in Palo Alto California and yeah it<br>was with the release of the software of<br>Netscape that is what is uh Mozilla<br>Firefox right now<br>and and why open source well the main<br>idea is we need that for being able to<br>reproduce the research for example uh<br>this is what we call open science if a<br>researcher provides some data and and<br>experiments the running software we want<br>to be able to replicate that so we need<br>access to the data we need access to the<br>to the software and this is why open<br>source is is very important to be able<br>to replicate because if we cannot<br>replicate we don't know for sure that<br>so it's very interesting that New<br>Zealand is very very important in terms<br>of open source for AI for machine<br>learning because in the 90s there were<br>two open source projects that were<br>started here are at University of<br>Auckland and work at the University of<br>waikato<br>so weka is the most popular software in<br>machine learning has been has more than<br>10 million a lot more than 18 000<br>research<br>citations so yeah just to show you how<br>well known is weka let me show you this<br>video<br>uh only the beginning so this is from<br>Google developer so you'll see how wekai<br>hey everyone everyone<br>videos<br>what's great what's great<br>how to use how to use weka from<br>installation installation all the way to<br>all the way to running experiments and<br>show you some of what it can do<br>bills<br>to discover whichever which attributes<br>are important okay okay let's Dive Right<br>okay so yeah you see it's uh worker is<br>really really popular around the world<br>uh just to to know the the people that<br>use worker they cite this paper so this<br>is our the main authors of the software<br>this is Mark Hall I have a Frank Jeff<br>Holmes Bernard faringa uh Peter Ottoman<br>and Ian Wheaton<br>Ian we can pass away recently so he was<br>let's say computer scientist not only in<br>New Zealand around the world so he did<br>amazing Works in information retrieval<br>so for example he has his books managing<br>tigabyte compressing and indexing<br>documents and images that were used for<br>all these companies that built their<br>search engines as Google Yahoo<br>Microsoft so he was a very<br>important in in that field but also in<br>in data mining practice data mining<br>machine learning so<br>he was crucial in getting the first<br>funding from for for weka and then they<br>published this book on data mining that<br>was very very popular maybe this is also<br>one of the reasons why the software was<br>so popular so the first version the<br>first release<br>uh was with IBA Frank and then the the<br>second was with marhol and then the last<br>one was with Christopher Paul<br>so yeah that was weka so just to<br>conclude talking a little bit about the<br>AI Institute so the name Maori of the<br>incident<br>means the receptacle of Consciousness so<br>um the University of waikato is very<br>well known in AI we have seen weka but<br>especially in robotics we have the group<br>of Mike Duke that is very very strong in<br>a in articulture we have also a strong<br>research on Maori data sovereignty with<br>tataka kigan Maui Hudson<br>so we try to be very very Innovative so<br>for example we were the first ones on<br>having the first AI supercomputer of<br>Nvidia Nvidia dgx a100<br>we receive best paper awards for example<br>this year in the conference of fairness<br>accountability and transparency with a<br>group in the Michigan University we<br>received the best paper award<br>we try to empower Talent this is our<br>passion so we'll see our passion is open<br>source and empowering Talent so some of<br>our students postdocs now they work at<br>Google Amazon Orange VMP pariva we have<br>a strong relationship with Institute<br>Polytechnic depakis so this is a one of<br>the 40 best universities in the world<br>as you know we are very very open<br>science so we have weka but we have also<br>MOA River Adams in terms of wake up we<br>release with Nvidia this software this<br>is called accelerated weka it basically<br>is an improved version of weka that can<br>deal with gpus<br>we have this book at MIT press that is<br>called machine learning for data streams<br>with practical examples in MOA this is<br>open available and the idea is to yeah<br>we have this more software it's like<br>wika but for data streams means for<br>real-time analytics where we are very<br>very fast we don't have resources and we<br>are very very efficient in terms of<br>energy<br>so we have this reverse software this is<br>uh in Python because python is another<br>language that is becoming very very<br>popular<br>and finally we have this weak<br>environmental data science project that<br>is called tayao this is a seven year<br>project this is with University of<br>Auckland Canterbury Victoria University<br>of Wellington Becca and met service and<br>we try to develop a new<br>fundamental<br>research new algorithms but also very<br>applied to data science so we have many<br>applications maybe we have these species<br>identifiers so this is you can use it<br>from the desktop or from an app on the<br>phone the idea is that you take a<br>picture and it's going to tell you<br>what's the what's the species and this<br>is built only with the species in in New<br>Zealand<br>and yeah just to conclude<br>what's next for AI so we have been<br>seen that yeah in the long term it could<br>be new models with more data more<br>computational power maybe better better<br>algorithms<br>but in short term there's a huge<br>discussion about open source or closed<br>models with between GPT or llama or any<br>there are a lot of Open Source models<br>that are are coming<br>another important thing is in terms of<br>architecture that architecture should we<br>have as centralized or distributed<br>should we have all the data in one place<br>or not this is between this data Lake<br>architecture or data major architecture<br>or in terms of energy if we should move<br>everything to the cloud or we should try<br>to do locally should we use chat GPT in<br>computers in the US or should we have<br>our large language model in our mobile<br>and then use that in our mobile<br>let's say how we see AI in the future<br>what what I think that we have the<br>the choice or AI could be something to<br>for the big companies for making the<br>rich people richer or could be something<br>that could help to improve the life of<br>everyone so there was this uh<br>prediction of the young Miner canis in<br>1930. he was saying that in 100 years<br>due to the advances in technology and<br>economy we should be able to work 15 15<br>hours<br>so this is something that maybe AI could<br>help also you know in New Zealand there<br>is this movement of four day week so<br>let's uh use AI to improve the the life<br>of of the people<br>and finally if you are interested we<br>have this uh the New Zealander AI<br>research Association we have this uh<br>discussion papers about chat GPT about<br>the strategy of New Zealand in terms of<br>AI that I think are quite interesting<br>and uh just to finish as Bernard was<br>mentioning this is the 50 years of<br>computing at the University of waikato<br>so this is the AI month we have<br>different events so we have a AI<br>hackathon on environmental data this is<br>going to to happen the weekend of 19 and<br>20 of August there is this NDG data<br>about ERA wananga this is the week the<br>21 to the 24th for Maori students like a<br>summer school and finally we are going<br>to have the tayao workshop here in<br>Tauranga this is the annual Workshop of<br>the tayao project this is this<br>environmental data science project so<br>yeah if you are<br>interested and you could be interested<br>on on attending this just send us an<br>email and it's really specific for<br>environmental data science<br>So yeah thank you very much<br>wonderful thank you so much Albert that<br>was amazing I'm I'm I'm reeling from<br>some new words I've learned like gooeys<br>and and thinking about tokens in<br>different ways and data Lake and data<br>mesh we have time for questions and I'd<br>really like to open it up to the floor<br>for your comments your questions<br>um Albert's really happy to take those<br>okay<br>um you talked about responsible Ai and<br>not needing responsible AI but<br>responsible people<br>so there are some responsible people but<br>there are also some irresponsible people<br>and to some extent we're moving from an<br>infinite Information Age to a<br>misinformation age and alternative facts<br>how how do you think the future of AI<br>things yeah very good question so I<br>think that the problem with I think is<br>really a technology so and then as a<br>tool can be used in good ways and in bad<br>ways so it's going to be used in a lot<br>of bad ways but also at the same time in<br>in good ways for example you can imagine<br>cyber security many people are going to<br>use AI tools to try to<br>enter into system so at the same time I<br>think that we are going to be able to to<br>use AI to defend about this Cyber attack<br>so I think it's going to be<br>like computer science sometimes I like<br>this this idea that<br>let's say AI basically is computer<br>science on asteroids so it's really<br>really much powerful computer science<br>but it's it's it's like that and what is<br>going to to happen is that uh yeah we're<br>going to be improving How We Do Ai and<br>there's going to be a good usages and<br>bad usages so I think that for example<br>in Europe they are maybe the the<br>Pioneers on regulating Ai and and they<br>really want to starting next year they<br>really want to have clear<br>loss and uh so what they are using there<br>is that they they are thinking on<br>different types of systems the system<br>with high risk system with medium risk<br>and the systems with low risk and they<br>treat them differently because the ones<br>with high risk is the ones for example<br>that they involve people right so this<br>is our high risk so we need to be very<br>very careful and I think that the key on<br>AI is that yeah this is a very good but<br>tools but they are tools they cannot you<br>cannot go to the doctor and the doctor<br>is going to be an automated Ai No it's<br>going to be a doctor that maybe instead<br>of using books or using Google search or<br>using the internet is going to use that<br>tool to have some advice and then to<br>decide but it's always people that needs<br>to make the decisions<br>so this is the beginning so we really<br>how things are going to evolve because<br>there are so many people working on this<br>field is so exciting so every week we<br>see recent discoveries recent it's<br>really exciting so now making a<br>prediction more than three months six<br>months is really really not possible but<br>I can imagine that we'll have<br>big things coming especially for example<br>in science this is going to speed up how<br>we do research not because it's going to<br>to develop new things alone no it's<br>because it's going to help researchers<br>scientists to do research faster if it's<br>if it's improving productivity 10 times<br>this is what we are going to use to do<br>so many tasks are going to be benefited<br>in the sense that we are going to do<br>things much faster but again there is a<br>lot of risk and this is what I think we<br>really need to to be discussing this<br>because if we don't discuss this<br>a lot of people will be discussing this<br>and deciding for us so it's good that<br>everybody discusses this yeah all right<br>thank you that question other question<br>comments<br>speak to the Box<br>great thank you is that working<br>right into it like that that's working<br>okay<br>um<br>you uh you talked about the uh came up<br>and asked about its biases that it had<br>and basically talked about the fact that<br>it was very Western biased because of<br>the thing<br>um so I guess my question is is there<br>non-western if parts of the world that<br>are developing their versions of AI that<br>are biased their way<br>as well yeah just at the same time<br>because I assume that there is that's a<br>very good naive to assume that it wasn't<br>happening that's a very good point so so<br>of course there is a big example is<br>going to be China right I think China<br>are developing their own large language<br>models and of course they are based on<br>Chinese texts right so it's going to<br>have like a different view of the of the<br>world<br>so I I imagine that if you look at the<br>large language models the the the the<br>the base ones the ones that are only<br>large language models that are<br>predicting the next score they are a bit<br>dangerous in the sense that<br>yeah they are only predicting numbers<br>and and then it's really there's no<br>guidance that they can be so this is why<br>I think all of these data all this what<br>is a a way to have gold rail so we we<br>check what what are the the outputs so<br>yeah that's the thing at the beginning<br>we're thinking oh we are going to have<br>only one large language models with GPT<br>everybody's going to reach a GPT and<br>that's all but no now what we see is<br>that<br>they are going to be<br>many many large language models and some<br>people say well maybe what was going to<br>happen is that each one we are going to<br>have our personal lines large language<br>model that is going to be our personal<br>assistant so imagine that we have one<br>large language model that knows all<br>about our life in the sense all about<br>our emails all what we are doing in the<br>internet so then they're going to be<br>really good at giving good advice<br>so yeah this is this is a good point so<br>the large swingers models depends on the<br>data so yeah if we have a data that is<br>inspiring it's getting data from another<br>culture it's going to be so yeah just<br>doing the job right if it's a French<br>large language model maybe different<br>from English large language model right<br>because the the way of looking at the<br>um you said that this would be<br>beneficial towards researchers but you<br>also said that it's a black box and we<br>can't really see how the algorithm works<br>so how does that work with like peer<br>review<br>well the thing is that uh yeah so I I<br>was thinking on AI in general right<br>because uh uh so this is one one two at<br>this moment we are talking about this<br>large language models at GPT because<br>it's really it's really huge<br>but maybe in six months we're talking<br>about another technology on AI that also<br>again is using data but this is really<br>doing uh other amazing things<br>so for example there was a deep mine<br>that uh has been working a lot of on AI<br>and it's really good now on helping uh<br>how to do research on biology in terms<br>of proteins they really really speed up<br>how to discover new proteins so it's<br>really really huge so I think that this<br>is going to happen in in many many<br>aspects of science that's something that<br>maybe before require I don't know one<br>one year now it's going to be able to we<br>should be able to do that in in days so<br>I think this is going to be the the main<br>breakthrough again you mentioned this<br>explainability I think that's really the<br>core and there is a lot there's a new<br>topic that is called explainable Ai and<br>basically it's based on that so the idea<br>is every time we have an output of one<br>of these AI systems we would like to<br>know<br>why what's what's uh and uh for example<br>in in these large language models this<br>is something that there are people doing<br>research on that because still we don't<br>know and especially and that's maybe the<br>importance of having an open or closed<br>model right if we're using a closed<br>model we should not be able to to to<br>know uh what's the origin of the of the<br>of of the text but if we are using an<br>open uh maybe then yeah it should be<br>much easier<br>I think it's it's it's very important<br>that uh we should be critic on that that<br>that's also a sign right so we should be<br>very very critic and then uh<br>check that everything is done uh right<br>that there is not any point there that<br>uh we really we are doing something<br>wrong yeah<br>thanks<br>you uh specifically mentioned that there<br>was an event on August 24th and there<br>was a link at a register for it but I<br>really didn't understand what the event<br>is and what's going to go on and how<br>long it's going to go for and it could<br>expand on that a little yes so the last<br>three events so yeah so we have uh the<br>first one is the hackathon this is<br>environmental AI hackathon so the idea<br>is that it's uh during a weekend and<br>then people organize yeah we organize<br>teams and then they work on<br>Environmental<br>data science problem and then yeah it's<br>going to be a jury that is going to<br>decide what is the best uh project so<br>this is this<br>um AI hackathon is going to be all<br>around New Zealand so it's not only in<br>Hamilton so this is the one that we are<br>organizing but yeah it's going to have<br>other venues then we have the Indigent<br>data aotearoa this is an event it's more<br>like a summer school for Maori students<br>where they are going to learn<br>that the signs that are sovereignty<br>apply to to to Maori and then we have<br>the last one that is this dayao Workshop<br>so this is uh the tayao project is a big<br>data science big environmental data<br>science project we have one worship<br>every year where we show what we have<br>been working during that year and we'll<br>talk about<br>yeah what we could continue<br>uh yeah what we should uh do the next<br>year so what is important in that is<br>that it's really it's going to be a<br>workshop where we are going all all the<br>team all the people at the project will<br>be showing what we have been doing this<br>year and also it's going to be a lot of<br>discussion on yeah on<br>important things for example how to grow<br>capabilities in New Zealand or how we<br>should be able to use generative AI<br>tools like cha GPT or Dali for<br>environmental science so this is a a<br>workshop that is really really good for<br>people working on environmental science<br>or working on data science because uh it<br>could be really really good to to to<br>network to synergize and to see how we<br>the last I think<br>um could could you just elaborate on the<br>environmental impact that slide you had<br>was rather<br>um surprising and um I might be<br>sharing my ignorance here but I can't<br>work out why is why is the computer so<br>detrimental or high producer of carbon<br>dioxide or detrimental to the<br>environment compared with everything<br>else<br>and and following on from that are we<br>wasting our time you know running around<br>in electric vehicles and so on and so<br>forth you know when you look at the<br>comparison there<br>thank you yeah that's a<br>yeah that's a good<br>question so<br>what is happening is that<br>for example when we think about the<br>cloud cloud basically is computers<br>running<br>in in yeah it's it's basically we are<br>renting uh computers so when we're<br>thinking for example cha GPT or all<br>these services that are provided by<br>Cloud basically are running on computers<br>that are usually in Big Big Data Centers<br>so if<br>you have used One desktop you'll know<br>that it's it's going to hit a lot when<br>it's Computing so imagine when you have<br>thousands of computers so it's going to<br>create a huge amount of of hit so then<br>to do that you need to<br>decrease the temperature so doing that<br>requires a lot of energy<br>so this is why that's the thing that we<br>think that when we are doing a search on<br>Google or when we are doing this we are<br>not we are green we are not doing<br>anything wrong but yeah we are using<br>computers and when we are using<br>computers we are using energy and and<br>that's the that's the point so if you<br>remember uh there was a a period of time<br>where the people were worried about<br>Bitcoins right because the people had to<br>mine they were buying a lot of machines<br>they were doing that so the risk is that<br>we we finish doing something similar<br>with AI in the sense of yeah having a<br>lot of machines creating new models and<br>doing that so that's why it's very<br>important to do research and and see how<br>we can do that using the resources this<br>is increasing a lot of people are<br>working on that and imagine that if<br>instead of uh to create the GPT we we<br>needed months and using thousands of<br>gpus we can be something that<br>at the end we can run in one mobile as a<br>simple app that that's going to be<br>perfect so so I think this is something<br>that uh it should be a priority on<br>seeing how we can develop Greener AI or<br>or<br>yeah a more energy efficient<br>algorithms yeah<br>well please um join with me and<br>um uh thank uh wonderful speaker Albert<br>the vet tonight with a round of applause</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>