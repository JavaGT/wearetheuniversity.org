<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">The Future of Thinking - Professor Michael Witbrock inaugural lecture [1:08:02]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=3VII_w9jhhs" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCc5_p6pLdNSJAnT9-rAPJqA" target="_blank">University of Auckland - Website video repository</a></p><img src="https://i.ytimg.com/vi/3VII_w9jhhs/maxresdefault.jpg" alt="Thumbnail for video titled: The Future of Thinking - Professor Michael Witbrock inaugural lecture" style="width: 100%;"><div class="tags"></div><h2>Description</h2><p>Humans are quite good at thinking, relative to other animals, plants, and rocks. But we are, perhaps, sometimes not as good at it as we might be. Fortunately, perhaps, our ability to think has given us the means to upgrade our ability to think, both at an individual and at a civilisational level. The development of language, accounting, the scientific method, and human rights, among many others, can all be viewed as software upgrades for individual, group, and civilisational thinking. None of these upgrades have come without both costs and benefits. This view of our history makes the accelerating rise of computational and recently Artificial Intelligence technologies seem almost inevitable.<br><br>In this talk, we’ll survey some of the upgrades that most directly predicted the path towards broadly capable AI, look at indicators that such AI is fairly imminent, including work we’re doing here in NZ. Finally, we’ll touch on the enormous opportunities and risks of this AI-based upgrade for individuals, organisations, societies and human civilisation.<br><br>Michael Witbrock is a professor of computer science at The University of Auckland, building a research group, the Broad AI Lab, integrating machine learning, reasoning and natural language understanding, with an additional focus on maximizing the near-term benefit of AI to NZ entrepreneurs and business, and more generally achieving the best social and civilizational impacts of increasingly powerful AI. Prof. Witbrock's PhD is in Computer Science from Carnegie Mellon, and he holds a BSc(Hons) in Psychology from Otago. Before joining the University, he was a Distinguished Research Staff Member at IBM T J Watson Research Center in Yorktown Heights, NY.<br><br>For more videos from the University of Auckland, visit our YouTube brand channel: https://www.youtube.com/UNIofAUCKLAND</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>so hi there my name is douglas elephant<br>and as the sort of acting crypto pseudo<br>pretend dean at the moment it's my great<br>pleasure to welcome you to the<br>um the inaugural lecture by professor<br>michael whitbrock<br>michael's a relatively new appointment<br>at auckland having joined us just about<br>two years ago now i think<br>slightly more than two years ago now<br>having previously been a<br>distinguished research staff member at<br>ibm's tj watson research center in new<br>york<br>he has a bsc in orns and psychology good<br>from otago university and just<br>just saying to me now his family have<br>been in new zealand for 170 years<br>which is impressive um<br>and his phd is in computer science from<br>carnegie mellon<br>uh michael is a very uh influential<br>figure internationally in artificial<br>intelligence with around<br>150 publications that have been cited<br>well over 5000 times<br>i don't mean each of the 150 has been<br>cited 5 000 times but in total<br>uh michael is rapidly building a very<br>innovative<br>research group here called the broad ai<br>lab<br>and it's a testament to michael's<br>judgment or at least i think it is that<br>one of his first hires was one of my<br>former phd students hello josh<br>nice to see you here you're onto more<br>interesting things<br>the group is focused on machine learning<br>and reasoning and natural language<br>understanding with a particular interest<br>in the social and civilizational impact<br>of artificial<br>intelligence including immediate benefit<br>to new zealand<br>entrepreneurs and businesses there's a<br>very applied focus here<br>from michael's abstract we're going to<br>learn something which i'm finding a<br>great relief<br>which is that humans are better at<br>thinking than rocks are which is a good<br>thing to know<br>and the idea that we can conceptualize<br>new ways of thinking as<br>uh software upgrades is i think a<br>particularly sort of<br>intriguing idea to me and the idea that<br>again from michael's abstract that these<br>upgrades come with costs as well as<br>benefits it<br>seems sort of worryingly familiar<br>microsoft<br>the abstract for michael's talk is as<br>fascinating to me as for any inaugural<br>lecture that i've introduced<br>i'm looking forward very much to the<br>next half hour please join me in<br>welcoming to the stage professor michael<br>whitbrock<br>so no i'm wishing i'd read the abstract<br>before writing the talk um but<br>hopefully you won't be too uh<br>disappointed um<br>good evening i'm going to talk about my<br>uh<br>what i think about thinking um and how<br>it might uh<br>change um so<br>sort of um when you think about thinking<br>there are three things uh that i think<br>you should think about<br>um so uh<br>one thing that's kind of uh important to<br>consider is like<br>who's doing the thinking because what uh<br>constitutes thinking really depends on<br>on who's doing it and you you kind of<br>think of thinking as something that is<br>done<br>you may think of thinking of something<br>which is done by an individual sort of<br>in isolation producing<br>some product of this thinking which are<br>thoughts<br>right um but i think that's um kind of a<br>uh unfairly restrictive<br>uh uh view it's unfairly restrictive on<br>the<br>uh low end this thing here is a plesia<br>um it's very slightly smarter than a<br>rock<br>um that's uh we know the complete<br>circuit diagram of its uh neural system<br>it has about 10 000<br>neurons or so um it's um been very<br>important in understanding the<br>physiology physiology and genetic<br>physiology<br>of of thought but that is much<br>less intelligent than your average<br>neural network<br>and as i said slightly more intelligent<br>than your average rock<br>if you're worried about eating that<br>don't be worried about eating it because<br>it's um smart and might<br>care uh worry about eating it because<br>it's disgusting<br>that thing there is a kia um<br>it is much smarter than a rock um that<br>there is a<br>ada lovelace she is also much much<br>smarter than a rock and much much<br>smarter than a kia<br>um but they are both uh capable of um<br>they were capable of thinking at an<br>individual level um and they are<br>kind of most famous in a way for being<br>able to think at an individual<br>level but it's not just individuals<br>which think right for humans because<br>we're this<br>partially used social kind of animal<br>when we get together we're much better<br>at thinking than we are individually<br>so we do things like form labs um<br>well i'm doing that at the moment it<br>remains to be seen whether we're better<br>at thinking than we would be as<br>individuals but when we can form like<br>larger groups<br>we can form very large groups this is<br>where i used to work<br>i used to work there this is the ibm tj<br>watson<br>research center it's a very large<br>laboratory which is part of a very large<br>company<br>and you can think of a company<br>as an organism right you can think of<br>people groups<br>in general from uh teams<br>up to uh sort of um groups up to large<br>organizations especially corporations<br>as things which think um and they think<br>very much better than individual human<br>beings in some ways<br>and then uh what we're building at the<br>moment is sort of this<br>planetary thinking thing those are some<br>starlink satellites um<br>which will uh join all this planet up<br>into one<br>thing that is um capable of thinking but<br>also might be capable of thinking<br>sort of dangerous thoughts um so the<br>second thing to think about<br>on top of who's thinking is okay what<br>are they thinking with right<br>and so traditionally the thing that<br>you've fought with is a<br>monkey brain well actually it's a<br>chimpanzee brain so that's unfair to the<br>chimpanzees<br>a human brain um a<br>cute little 6502 processor from my<br>childhood<br>um that's not actually my one i didn't<br>have time to photograph it quantum<br>computers optical networks<br>optimal networks are something that's<br>worth thinking about<br>in terms of the great difference between<br>them and people<br>people are very slow compared to that<br>and<br>they're like um extraordinarily slow<br>compared to that unless you think<br>unless your roger penrose and think<br>otherwise this is a gpu so it's a fairly<br>modern type of computer and that<br>that we won't mention uh further even<br>though i'd intended to that's a<br>neurolink machine<br>um just isn't going to be time to talk<br>about sticking uh<br>wires of various kinds of brains um and<br>the third thing to think about is like<br>how you're thinking<br>right so there's uh things that think<br>there are<br>kind of things that you think with and<br>then there are modalities of uh<br>thinking and in things like human beings<br>this is this guy daniel<br>kahneman who wrote a book thinking fast<br>and slow<br>he's not the first person to have<br>thought his thoughts but he is the first<br>person who wrote a book which was as<br>popular<br>and he thought uh divides um thinking<br>into uh system one and system two<br>uh system one is the sort of thinking<br>which is keeping me upright at the<br>moment and<br>identifying dr alice there<br>and it's the uh professor alice sorry<br>it's done rapidly unconsciously you<br>don't know that you're doing it and it's<br>not hard<br>right um system two uh is kind of uh<br>thinking<br>slowly and carefully it's the human<br>superpower not just humans kia's as well<br>octopuses um a few other things<br>do that sort of seem to do that kind of<br>slow reflective<br>uh thinking which counts as reasoning<br>but super powerful<br>right um it's the reason we're sitting<br>here with<br>gadgets right other other creatures<br>don't make<br>gadgets well crows make gadgets but<br>they're sticks right so<br>um but it's done really poorly by most<br>people<br>it's really valuable it's the thing that<br>drives our civilization and we're<br>really bad at it so uh kind of<br>the theme of this lecture is how might<br>we as a as a people group<br>get better at this um even if<br>individually we can't<br>um yeah so if you're good at that you<br>get paid well and people inaugurate you<br>as a professor<br>don't even have to be good at it um so<br>and that thing is the fundamental design<br>principle of computers right so the<br>abstractions that we form when we think<br>about type 2 thinking<br>are the reasons why we have these things<br>right these are binary numbers and logic<br>and<br>reliable memory systems and so on<br>they're all based on kind of a<br>simulation<br>of this kind of thinking<br>although nowadays we're<br>a little bit blurred right so i said in<br>the uh<br>abstract so i did skim it um that would<br>talk a little bit about how humans have<br>thought over time and how that's changed<br>um<br>yeah so we start off thinking right we<br>started thinking<br>uh in kind of the same way that we might<br>think that ikea<br>thinks um or um<br>sort of other or other kinds of um<br>simpler people like chimpanzees uh might<br>think like this right<br>um so mostly from sensory data<br>right so you see stuff you do trial and<br>error um<br>you eat uh eat stuff and it's good or<br>you try poking at something with a stick<br>and it works and you keep on doing that<br>um one human it's done sort of one human<br>at a time one problem<br>at a time and the benefits of this are<br>only shared<br>directly right i can go off and work out<br>that i can hunt potatoes or kumara<br>right i can dig them up and i can take<br>them home and you get to eat them and<br>that's wonderful<br>but um if i can't communicate with you<br>right all you do is get the kumara right<br>you can't learn to i can't<br>learn to i can't teach you to fish kumar<br>on your own or whatever that metaphor is<br>right<br>um so so that's kind of a uh<br>not not not great and while we were<br>stuck in that state<br>um we did not do very much better than<br>the other animals in fact<br>up to the point where we got beyond this<br>our primary advantage over other animals<br>is that we could run<br>away from them better than everybody<br>else so humans are very good at thinking<br>but we're also very good at running away<br>so we can run away for a long time and<br>that gives us an evolutionary advantage<br>right so um we're in the state for a<br>while but then there's<br>sort of a transition right so um<br>uh and in between uh before we got out<br>of the state um<br>we were able to do things like imitation<br>um i believe that crows can also<br>and kia can also do that if they one of<br>them learns to do a stick the other ones<br>can watch them and they can learn to do<br>that too<br>so that's a way of transmitting um<br>information by kind of<br>simulating um in much the way uh that a<br>reinforcement learning system might do<br>now<br>simulating the in the action in their<br>brain while<br>observing while pinning it to some<br>observed data to make it the right<br>action and then doing it themselves so<br>we could do that<br>part of what comes along with that in<br>order to do that<br>you have to have some kind of theory of<br>mind because you have to recognize that<br>that thing<br>is doing something that you might do<br>right so you have to see it as<br>an analog of yourself um and because of<br>that<br>limited collective action is kind of<br>possible right you can run with your<br>band you can all run in the same<br>direction you can see that people<br>are hitting the wildebeest in 2001 with<br>the<br>jaw bone or whatever it was um it wasn't<br>a<br>build a beast it was something else<br>anyway whatever the animal was<br>yeah you're heading out with the jawbone<br>and it falls over<br>and you all descend on it as<br>humans do we are not nice creatures on<br>the other hand the creatures which<br>caused us to get so good at running away<br>aren't all that nice either<br>so um so eventually we stopped doing<br>that right<br>eventually we invented language<br>that's great yeah that that<br>that um that was the best invention that<br>we<br>ever made i don't promise to be<br>consistent about thinking that's the<br>best one<br>you know sometimes i sometimes i think<br>that those automatic tell dispensers<br>which<br>you put your hand under you don't have<br>to touch in which the university issues<br>the use of in favor of<br>things which spread germs but anyway um<br>sometimes i think they're the best<br>invention<br>um but you know well uh so we developed<br>language<br>um which entails the development of a<br>general of concepts like a<br>glass of water and i think this is<br>probably for me yes<br>um thank you um so<br>there's a general concept of a cup here<br>and it's a container and so forth and<br>these things we can compose together<br>and we can say things about it and<br>that's really useful because the next<br>time a cup comes along<br>um i can decide more reliably whether<br>it's a cup or not<br>right so um this allows<br>language also allows us to transmit<br>information not individual to individual<br>but so reliably from an individual to<br>small group<br>and because of that because each of the<br>members of that small group<br>can go and transmit their information to<br>another small group and so forth<br>we can get exponential knowledge spread<br>so that's much better<br>than linear knowledge spread right um<br>that's uh<br>you know with that in a lifetime you<br>could spread a piece of knowledge to all<br>the humans which<br>back then uh there were not very many of<br>them maybe a hundred thousand<br>right but you could easily cover all of<br>them um apart from some of them were<br>kind of far away<br>all right um could develop counting<br>um as a result of the ability to share<br>this knowledge we could have cultural<br>artifacts like agriculture and<br>navigation<br>we could start developing uh<br>abstractions about<br>thought leading to this talk we could<br>do things like develop rhetoric tikanga<br>law<br>we could we could plan together<br>right we could build parts of plans<br>serialize them out as we say in computer<br>science<br>serializing them into other brains<br>change them<br>and do that repeatedly to build a plan<br>which was the product of<br>more than one of us i thought a thought<br>which had been constructed by a group<br>this is a great advance but the problem<br>with doing that<br>um yeah the problem of doing that is uh<br>that it does you no good after you're<br>dead<br>right all that stuff goes away and uh<br>back then<br>um you were yeah that map is like uh<br>when you were dead<br>and not very long ago so in our<br>lifetimes we have approximately<br>half the probability of being dead at<br>some point in<br>uh starting from your birth right so<br>that<br>that was a bigger problem for them than<br>it was for us and it would<br>it's no longer a problem for us so yes<br>right um so and because we uh<br>we invented knowledge permanence<br>otherwise known as writing<br>right what writing allows you to do<br>is to um stay around after you're dead<br>or at least your thoughts can stay<br>around after you're dead that's very<br>useful<br>um it can be uh and your thoughts can be<br>accessed uh<br>at any time even when you're asleep or<br>dead<br>right um they can be unchanged over<br>generations<br>um but you can write new things based on<br>them so they can be modified<br>they can be modified and you can keep<br>checkpoints just like google drive does<br>when you drop a file in it<br>um remembering what you used to think um<br>and they can and there's no limit to the<br>amount of accumulation well i suppose<br>there's some<br>limit but you know our disk drives have<br>very small features in that on them so<br>you know if we turn our solar system<br>into storage medium we're going to be<br>able to store quite a lot of stuff<br>and for the first time<br>it's put a physical technology<br>into the path of thinking so up to this<br>point<br>um we had psychological technologies<br>like uh<br>rhetoric um and probably and quite<br>sophisticated uh theories of<br>rhetoric we had psychological um uh<br>technologies like tikanga right like<br>notions of what the right thing to do<br>and the wrong thing to do in a culture<br>these all improved our ability to think<br>as<br>individuals and as groups but this<br>writing was the<br>kind of the first physical technology of<br>thought<br>so uh yeah so<br>this sort of allowed us to start moving<br>towards other ways of<br>uh improving uh thought um it allowed<br>numeracy and record keeping which<br>allowed us to<br>build um larger kind of groups<br>it allows the joint development of<br>knowledge when separated right i can<br>write down part of a plan<br>and send it on a<br>person or an animal to you maybe a<br>pigeon<br>if it's light and you can augment it and<br>you can send it back and we can<br>build up through this email thread we<br>can<br>write our grant proposal to the<br>paleolithic<br>granting agency um and that<br>you know that means it was the first<br>non-local networking technology right so<br>this was the first<br>uh the first thing where we were sending<br>bytes<br>around the world and kind of building up<br>composites<br>of permanent knowledge um so that was uh<br>really<br>really useful and again it's like<br>unlimited accumulation over<br>generations which means not only can we<br>um not only can we build up thoughts<br>from people who are widely distributed<br>in space we can also build up thoughts<br>from people who are widely distributed<br>in time<br>you know we can build things with people<br>who are dead and that<br>was useful and now i think we we're<br>we're at the stage now<br>when we can build the first little bit<br>of<br>our inevitable path towards artificial<br>intelligence right<br>so at this point um we can start<br>really building long-term abstractions<br>about thought<br>right so artificial intelligence is<br>really<br>kind of the technological embodiment of<br>getting<br>of abstracting thought from our minds<br>and realizing it in other ways right so<br>when we formalize thought we are doing<br>something which is on the path to<br>artificial intelligence because we're<br>kind of making thought<br>uh um we're we're manipulating<br>abstraction over thought<br>right so uh won't worry too much about<br>that this is um<br>aristotle's organ on one of the and we<br>still have it because<br>we have uh writing and this was one of<br>the first<br>publications about logic and logic has<br>been important<br>in the history of artificial<br>intelligence and one of the goals of our<br>lab<br>is to make something like logic<br>important again<br>because it's not fashionable at the<br>moment all right so<br>logic speaking of logic inference so<br>inference is this process of formalizing<br>reasoning so we all do<br>various kinds of reasoning but you know<br>it might be good reasoning it might be<br>bad reasoning<br>our conclusions might be reliable or<br>unreliable it's kind of hard to tell<br>people go around making all sorts of um<br>unreliable<br>inferences all the time it's quite the<br>fashion these days and then they go on<br>youtube and tell other people about it<br>or twitter<br>and uh we got we get ourselves into<br>messes so far<br>we haven't got ourselves into a<br>redeemable messes<br>um but uh but we have ended up having a<br>lot more people<br>dead from covert for example than we<br>needed to because of unreliable<br>inferences<br>right so um we don't<br>some of us don't like this about<br>ourselves right that our inference<br>methods are unreliable and we would like<br>to where possible be able to<br>conclude um things and then trust<br>that no matter what happens no matter<br>what other things people might think or<br>whatever opinions or whether they're<br>happy or sad<br>those things should remain the same<br>that's a big thing to ask for<br>um and i'm not uh you know<br>unofficially i am not so sure about its<br>prospects for wide<br>spread applicability um although people<br>try<br>um it's it's it's also it's really hard<br>to do<br>and it's really really hard to do for<br>people um you know<br>logic is just don't don't even try it so<br>it's just no fun um all right so<br>uh but um it's you know what it is it's<br>a set of reliable cognitive technologies<br>of various sorts um you know<br>partially mechanical and partially sort<br>of psychological or philosophical<br>which allow us to combine knowledge into<br>new knowledge<br>where we can rely on the new knowledge<br>at least being no less reliable than the<br>knowledge which was combined<br>right and that's that's pretty good and<br>this uh um<br>leads to our ability to have philosophy<br>um<br>it also leads to our ability to have<br>case law right<br>so you can examine a case and you can<br>test that case with respect<br>to carefully constructed language a kind<br>of logic<br>which allows people to fairly reliably<br>reach the same conclusions given the<br>same information<br>that means that we can actually use<br>individual cases<br>filtered through this function of case<br>law to build<br>up a body of law over time this is no<br>small<br>achievement we'd like to do more of that<br>kind of thing for more fields<br>by teaching computers to do it too<br>we can have things like mathematics and<br>accounting scientific method<br>logic and professions because we are<br>able to formalize these reasoning<br>processes to some degree or another<br>right so once you've developed that<br>it kind of allows you to develop other<br>things on top of it right<br>so one thing that uh you can get once<br>you have these form<br>uh these these formalized reasoning<br>techniques um<br>these systems for inferences that you<br>can take kind of<br>dodgy teachers and cause them to be able<br>to<br>educate students reasonably well<br>because uh you can tel because there's a<br>method for telling whether<br>um they've taught them the right things<br>or not right so this enables universal<br>education<br>um the necessity the utility of this<br>sort of inference<br>um has led to us<br>um trying to teach everybody to do it<br>and as i said like humans are lousy at<br>this<br>so yeah good luck with that but still we<br>strive<br>um and you know there are 40 000 people<br>who uh think that they are being taught<br>to do more reliable reasoning or<br>something here<br>leads to sort of meta professions so you<br>can sort of analyze<br>the behavior of professions like doctors<br>for example<br>and see whether or not you can codify<br>what they do in ways which will improve<br>their reliability<br>so for example those checklists when<br>they're always asking your name and your<br>birth date and so on<br>that is um an attempt to apply a kind of<br>logic<br>an organizational logic to the<br>profession of medicine in order to<br>improve its reliability the reason the<br>reason i care about organizations quite<br>a lot is that i think that um<br>ai that organizations are a better model<br>for ai systems than individual human<br>beings<br>um just because of the you know the fact<br>that they can do<br>complex reasoning in parallel for<br>example the fact that they rely on inter<br>processor communication uh extensively<br>all things that are<br>uh that ai systems will necessarily have<br>it leads to<br>franchising and oh i haven't been<br>talking about this but down here and<br>the i think is the kind of the the kinds<br>of things which are most uh<br>affected by this kind of thinking right<br>so by the time we're up here we've moved<br>on from people<br>and small people groups and teams and so<br>on to<br>the things which are most uh affected<br>by this are abstract persons like<br>universities<br>and whole civilizations right the idea<br>of a metal profession<br>only makes sense at a kind of<br>civilization level<br>right um psychology yeah<br>um so psychology again is a technology<br>for upgrading our thinking<br>right this is where we look at how we<br>think right and we we look carefully at<br>the mechanisms for how we think not<br>really so much about the content of the<br>thoughts but um<br>the the mechanisms both uh at uh the<br>level of um<br>computational extractions right<br>motivational<br>abstractions but also sort of<br>abstractions of the uh<br>of what goes on physic uh physically and<br>these are a bunch of<br>historically relevant uh psychologist<br>somehow connected to the topic of my<br>foot<br>talk and i'm not going to go into<br>much more detail although<br>this is a picture illustrating long-term<br>potentiation<br>and i have a particular fondness for<br>that because when i was a psychology<br>student in otago i stuck electrodes<br>in the brains of rats and tried to make<br>that happen<br>and this is a one of the first<br>theories about how to update weights<br>between neurons<br>in order to have a general um learning<br>algorithm<br>and long-term potentiation was a<br>mechanism<br>which embodied the sort of thing but so<br>this uh<br>this book was written in 1948<br>right so a very long time ago clever guy<br>this<br>donald hebb and long-term potentiation<br>because i was<br>doing it as an undergrad must have been<br>invented around 1980<br>because it had just been discovered um<br>uh recently<br>um that's not actually a skinner box but<br>everyone calls them<br>um yeah that leads to the second part of<br>the roots of ai<br>which is sort of how does computation<br>actually happen<br>inside intelligent organisms and how can<br>we replicate that by simulating it on<br>computers<br>right and this is uh one of the first<br>diagram one of the first reliable<br>diagrams of<br>part of a human neural system by this<br>again very clever guy santiago ramon<br>icahal<br>it was a beautiful picture as well<br>so we've been uh so we've been trying to<br>make ai for quite some time now right<br>um some on some reading back to<br>aristotle and beyond<br>um on some reading um you know back to<br>ramona kahal<br>certainly uh by the time donald hebb<br>came around<br>the turing test had already been<br>invented and we were well on our path to<br>making intelligent machines um and the<br>last kind of uh<br>maybe it's not the last kind of thinking<br>let's not be bold i don't remember<br>um but um<br>meta civilization right this is a new<br>kind of thinking that applies at the<br>level of whole civilizations and has<br>become<br>um necessary recently right and i think<br>people don't like it when things become<br>necessary but they<br>do so um<br>thinking about whole civilizations<br>right when you're forced to because the<br>whole civilization is rapidly<br>interacting causes you to come up with<br>new ways of thinking<br>so one of the uh new kinds of ways of<br>thinking that has been<br>born because of this is uh cultural<br>theory<br>there are many people who don't like<br>that too bad i'm not saying it's right<br>or<br>wrong i'm just saying that it's a um<br>thinking that way is a natural<br>uh consequence of the situation that we<br>find ourselves in and we should not act<br>surprised<br>or upset that people are thinking that<br>way right um<br>similarly um it has led to things like<br>international law and uh intercultural<br>law<br>so for example the um outer space treaty<br>and the treaty of waitangi are both<br>examples of that and were so forced upon<br>us this sort of thinking<br>which was novel at the time somewhat<br>novel at the time<br>was forced upon us by the fact of our<br>technological and social<br>advancement our movement um from<br>isolated groups from<br>individuals towards whole civilizations<br>right this is<br>this is one of the main threads in our<br>upgrade in what we've been able to<br>upgrade ourselves to be able to do<br>because of upgrading our thinking<br>similarly it's uh led to the idea of<br>human rights<br>you need that idea if you're going to<br>manage people by the<br>millions or the billions you don't<br>necessarily need that idea<br>you still want that idea but you don't<br>need it<br>right if you're just managing a village<br>and uh and yeah macro economics<br>similarly<br>you don't need um sorry uh<br>i would say marks but i can't think i<br>can't remember the name of that austrian<br>um<br>the austrian economic uh guy on the<br>other milton friedman<br>um in the likes you don't need marx and<br>friedman if you don't have<br>large societies interacting with huge<br>money flows right you don't need this<br>type of thought without that so<br>civilization scale thinking<br>is developed and then<br>you know along with all of this you know<br>the there's an important<br>uh piece perhaps for this talk is uh<br>thinking<br>thinking with machines right this is a<br>new kind of thinking as well<br>and it's uh again i would argue<br>that it's necessary because it's the<br>only thing that can<br>uh successfully run the sorts of<br>thoughts which are required<br>for the things in the last slide so for<br>example if you're thinking about<br>civilization level thinking<br>um the maximum the maximum output<br>bandwidth of a<br>human being is some few killer board<br>right um remember killer board when com<br>when things used to come<br>that doesn't happen anymore because they<br>are doing that<br>at frequencies um of billions<br>of hertz right so we can't hear them<br>doing that they're still doing it and<br>uh your computers can<br>talk to each other um at<br>of the order of a billion words a second<br>right we can't do that<br>and there are some kinds of thinking i<br>would say that you can't do<br>unless you can talk to one another at<br>that rate<br>right so there are types of thinking<br>that human beings<br>um at least without brain computer<br>interfaces will never be able to do<br>because our network bandwidth isn't<br>um large enough or parallel enough um so<br>yeah<br>we've been building thinking machines<br>for a long time too um<br>that one's um that greek one from the<br>boat<br>you know um yeah so so we've been trying<br>to do that um<br>for a long time we're getting we're<br>getting better at it at<br>well i hope is the required rate um and<br>uh you know so part of what that's<br>enabled us to do<br>is have broadcast knowledge right<br>because we have machines<br>like radios we have a lot of radios<br>and even more cameras ridiculous numbers<br>of cameras in the world<br>um actually i don't know this might have<br>more radios than cameras it's got all<br>sorts of<br>radios for things you don't think about<br>um so<br>so we did our technologies for broadcast<br>knowledge printing first radio tv web<br>facebook youtube tick tock<br>and uh who knows what's uh uh what's<br>next<br>um eventually<br>eventually something involving uh<br>putting stuff straight into your brain<br>will come along because i had some<br>anesthesia<br>related are they called hallucinations<br>and they had great resolution right<br>i mean those those things i mean they<br>were just like wallpaper patterns so<br>they weren't very interesting right<br>but they were they were better than tv<br>and our tvs are really good these days<br>right so uh all right<br>we'll get to that and then um<br>another thing um that we've developed<br>along so<br>those technologies were all about<br>getting stuff out for the humans<br>right but we also have data broadcast<br>and exploitation<br>and again that allows us<br>in principle to do sorts of thinking<br>that we weren't able to do before<br>so for example it's conceivable<br>that you could have a computer read all<br>of the scientific papers<br>that i have ever been published and talk<br>to other computers about them<br>and see which parts of them are<br>consistent with each other<br>and which parts aren't we need that<br>right we are at a point in science where<br>the humans can't do it<br>we need to develop that that's one of<br>the things that i'm hoping the sort of<br>technologies that we're developing<br>uh will lead to because at the moment um<br>it's i don't know it's not quite just<br>luck<br>right there's peer review and so on but<br>the probability distributions<br>associated with um all of our<br>paper to paper information matching<br>technologies<br>have extremely high variances on them<br>and we've got to<br>reduce that and the i think the way to<br>do it is um<br>automation right so we're still doing<br>okay<br>yeah so what's the solution to this<br>right jump to the<br>jump to the end um automate the whole<br>process data collection augmentation<br>knowledge data<br>adaptation inference checking and<br>explanation development of new<br>ai techniques hand it all over to<br>machines and free the humans so that we<br>can go<br>and don't have to give talks like this<br>which we'll get to uh<br>in a bit um and i could have had a glass<br>of wine before and had a nice<br>uh relaxing time sitting with you<br>watching a computer<br>give a talk about uh about this and you<br>know everything else<br>and this is kind of the end point right<br>where it<br>this is going to happen this century<br>that all of the useful things<br>will be done by our civilization without<br>pretty much involving human beings very<br>much in<br>in doing it it is separate to the extent<br>that we want to be involved<br>um and the extent that we're not going<br>to mess things up<br>in ways which really can't be allowed<br>right i mean there are some things which<br>you know there are some things that<br>human beings cannot be allowed to do um<br>controlling nuclear weapons is one of<br>them uh synthesizing viral genomes and<br>encapsulating them<br>you know it's like no do not let humans<br>do that right um<br>but you know we'll see uh um so we we we<br>need<br>to find ways not to do that and yet we<br>need to have the technology<br>all the technologies required to<br>synthesize viral genomes<br>and encapsulate them because that's like<br>this distance away from how we built the<br>covent vaccine<br>and how we built it so quickly right so<br>we need to be able to do that and we<br>can't let ourselves do it this is a<br>little bit of a worry<br>all right so we're going to hand this<br>all over to ai well maybe not but<br>that's one one thing that you might<br>think about doing<br>so what is ai right um so one when i<br>started an ai<br>people thought it was funny to say that<br>it was everything that we don't know how<br>to program<br>but now ai systems um<br>know how uh to do a lot of things that<br>we<br>have no there's no hope that we'll ever<br>know how to program them<br>explicitly right they are too<br>complicated in fact um like<br>when it comes to for example playing<br>chess we don't even know how to play<br>chess anymore<br>right we're no good at it we lost how<br>how<br>how the hell are we supposed to write a<br>program to do something<br>that we can't even do right um so<br>um and the number of things which have<br>that quality<br>um is not going down um it's<br>yeah it's going up um yeah so that's why<br>i started off kind of slowly um<br>you know logic um neurons<br>heavy and learning um people<br>did stuff i started being interested in<br>i read a book called machine learning<br>when i was a little kid<br>and by by by<br>i know then i guess i was<br>working on it although not on uh not on<br>psych at the time<br>well i did have a lost decade actually<br>working on that thing<br>um no but it sort of went along and<br>people<br>built programs which did sort of um<br>thinking things right and uh that was<br>good and<br>grant money came and went and they were<br>ai winters and summers<br>and uh um and at that point<br>uh at actually in 1971 and 1986 back<br>propagation was invented by<br>different people this one caught on this<br>is common<br>in science because as i said we human<br>beings are incapable of keeping track of<br>it all<br>and it's not getting any better right so<br>uh<br>went along and then all of a sudden uh<br>um we got<br>this neural network stuff uh started<br>working and it started working<br>i'd say it started working for three<br>major reasons which i won't go into<br>i'll go into um one of those maybe four<br>major reasons um see i can't because i'm<br>in your network i can't do math<br>correctly either and neither can<br>the new ones um so<br>one reason was that we got good at<br>storing large amounts of data and<br>shipping it around<br>so data became free that was really<br>useful information retrieval became<br>free as well that was really useful and<br>is not<br>often sort of sung about very much<br>we developed something called a resnet<br>um that you don't need to know about but<br>it meant that our neural networks could<br>stop being small like a plysia<br>and could go to hundreds of layers deep<br>which is deeper than most parts of a<br>there was the development of<br>reinforcement learning effective<br>reinforcement learning that took a while<br>but it came along<br>that's the reason why it means that you<br>don't have to have training data<br>you just have to be able to tell whether<br>you're right to some degree<br>right it can even be probabilistically<br>tell that you're right and then you can<br>learn to do things that's why computers<br>that's why a human being will never beat<br>a halfway competent computer at chess or<br>goal again<br>right because of reinforcement learning<br>and the last thing is<br>uh the current thing which is doing<br>really well are<br>things called transformers and that's<br>why when you listen to<br>a youtube video often you can tell that<br>it's not a human being not because the<br>voice<br>is funny but because it's reading<br>something written by someone who doesn't<br>really speak english in a perfect<br>american or english accent right so<br>and it's also the reason why say google<br>translate is<br>better at any language which isn't your<br>native language than you are<br>and probably for most of you better<br>uh at your native language than you are<br>right it's because of these uh<br>transformer networks which we'll talk a<br>little bit more about<br>right so transformer network so this is<br>um<br>this is a little bit old this is from uh<br>2019 or something<br>and it's a system called uh gpt2<br>um so it's hopelessly out of date um but<br>one of these<br>um is uh the the colored<br>writing one of the one of the pieces of<br>color writing was generated by<br>shakespeare<br>one of the pieces of colored writing was<br>generated by gpt2 okay so now<br>you should i'll give you a few seconds<br>to decide which one you think is um<br>shakespeare gpg2 gpd2 shakespeare<br>right um make up your mind can you tell<br>you probably don't can't unless you've<br>been to this<br>and this is one of shakespeare's not so<br>good plays<br>so hopefully you haven't memorized it<br>right this uh this is from gpt-3 da<br>vinci this is a state-of-the-art system<br>i did this at 2pm today<br>so this is my abstract but actually<br>up to the point where it becomes fat and<br>after that it was written by gpt3<br>okay this is in fact my abstract<br>um and i've colored a piece uh in red<br>there in blue there<br>um where we seem to be on the same page<br>me and gpt3<br>right so it's hard to tell that that<br>wasn't written<br>by a person now<br>i do admit that i went through<br>four iterations of trying slightly<br>different things and slightly different<br>stopping points inside my<br>abstract to find the one where it's<br>where it didn't spit out like a a fake<br>speaker name<br>and building right and stuff like that<br>which was confusing but this is you know<br>this is very lightly curated<br>um right so yeah so<br>um you know gpd3 thinks i'm<br>dumb or at least oh and it took um<br>of the order of two seconds to write all<br>that<br>so yeah and it's busy serving stupid<br>requests like this for millions of other<br>people at the same time<br>so uh there you go and um the answer the<br>question before is that the one on the<br>left<br>is uh from gpt2 but who cares because<br>it's obsolete<br>gpt-3 laughs at it<br>we can prompt it to do so probably all<br>right so uh yeah so<br>that's really quite impressive i think<br>uh you know what<br>what these ai systems can do um if i<br>went back to 1990s me let alone<br>1980s me or 1970s me and asked whether<br>or not<br>these people in 2020 had artificial<br>intelligence<br>i think uh i would have to say<br>yes right and this um this isn't all<br>that we<br>can do we can take a old photo of<br>someone<br>and raise the resolution and animate it<br>and make it say stuff<br>we can take a half picture of a kitten<br>and fill out the other half of the<br>kitten<br>we can tell a system that we want a<br>picture of a<br>um i don't know an avocado playing chess<br>and<br>eating a banana and he'll draw some<br>cartoon to that effect<br>and we can be beat at uh an increasing<br>number of<br>games oh yeah and we can synthesize art<br>and stuff all right so<br>apart from kind of uh apart from<br>agency i think um<br>that we would have thought was<br>definitely ai has uh<br>has happened and i i i don't<br>i don't know it's kind of difficult to<br>deny um<br>gpt3 like a tiny little bit of agency<br>i was going to i was going to<br>tell you how gpt actually works um<br>by but i had is not intuitive enough for<br>me to make it intuitive<br>enough for you yet and also i don't<br>think that would help because if i told<br>you how your brains actually work you<br>it wouldn't necessarily allow you to<br>judge whether you're intelligent or not<br>right so if you look at neurons they<br>don't seem very clever and<br>you know right um so so<br>we look like we're winning uh so maybe<br>we're not winning because uh<br>you know all the knowledge that we are<br>storing away um so<br>gpd3 knows a lot of stuff right um it<br>it wrote that without plagiarizing i<br>didn't go and look look for any anything<br>it just looked at its neurons and uh<br>voila right but all that knowledge is in<br>opaque uh<br>parameters which is true inside your<br>brain too your brain anyone here who<br>has non-opaque parameters in their brain<br>and and we think they're not because we<br>um have special neuron we have a special<br>gpt3 in our brain for confabulating<br>reasons why we thought stuff which<br>i think we can reproduce for computers<br>so we'll<br>we'll work on that there's lack of kind<br>of lack of transfer between<br>tasks so this is becoming less true for<br>some tasks like<br>language translation we just teach them<br>to translate all of them and they're<br>better at each of them than they would<br>be if they were just doing one<br>so there is some transfer but sort of<br>general<br>transfer of task capabilities is not<br>there<br>and what else yeah lack of explanations<br>but i always<br>i already denied the credibility of<br>human explanations so it's there's that<br>um so what do we need to get to uh human<br>level knowledge use right so<br>what we what we want to solve those<br>problems<br>is for our ai systems to act as if they<br>have knowledge in the same way that we<br>do<br>right to remember things to say that<br>this is the basis<br>of my uh of my answer to reuse the basis<br>of that answer for future answers and so<br>forth well<br>uh yeah this this this this stuff<br>because um<br>we can't realistically scale up<br>this sort of careful inference this like<br>very careful legal thinking for example<br>or very careful scientific thinking we<br>just can't<br>uh do it by growing more people because<br>even if we grow more people the network<br>doesn't improve<br>the only way we can really scale that up<br>massively<br>is by automating it so how might and<br>when we are able to do that careful<br>thinking<br>it's very good our buildings don't fall<br>down<br>people don't die right people take the<br>vaccines people are not um denied their<br>property because some judge had a bad<br>day<br>right so that sort of uh careful<br>thinking is uh<br>very powerful it would be would probably<br>be good for us<br>if we could have more of it done so how<br>how might we do that<br>now um one thing is<br>to uh you know to get toward uh to have<br>more symbolic knowledge<br>right in some for in some sense of<br>symbolic i mean<br>symbolic knowledge are representations<br>of things which allow you to think about<br>them more reliably<br>and there's a wide variety of symbolic<br>knowledge uh people people who know what<br>it means<br>would usually think of it as denoting<br>things like mathematical logic and<br>computer programs<br>but uh it's more than that so careful<br>legal uh<br>knowledge for example is like it's kind<br>of like a computer program<br>it's a computer program for humans which<br>is designed<br>to make them produce the same inferences<br>about a legal case as other humans<br>right but it's a more informal<br>programming language because it's for<br>humans<br>similarly formal narrative is less<br>formal than formal lingual<br>legal language and less form more than<br>fiction<br>so when i talk about we need to get good<br>at processing<br>symbolic knowledge and if we want it to<br>be more reliable<br>we need to get good at pushing things<br>down towards that end<br>right so where we can take a<br>mathematical logic<br>uh sorry a mathematical notion and push<br>it down to mathematical logic<br>then we can be certain about it so the<br>more things that we can do that for<br>the more reliable our civilization will<br>be<br>and it's not just symbolic knowledge<br>it's not just about text<br>there's also all sorts of picture-like<br>symbolic knowledge<br>like that and again if we can push<br>uh for useful purposes right as opposed<br>to<br>enjoyment purposes if we can push things<br>that way<br>we tend to get better results<br>and you know we can also push things<br>that way and get um<br>a bit more artistic results based on the<br>the facts you know both of those are<br>potential things that machines could do<br>um<br>yeah so we want to we've got pretty good<br>at learning<br>we've done a lot of research in the past<br>on reasoning<br>this is from that time when i was doing<br>uh psych so that's an explanation<br>produced by a computer<br>about a case based on some complex<br>reasoning it's just that that was very<br>hard<br>to get a computer to do and i think that<br>the best way to get computers to do<br>more of that is to teach them to teach<br>themselves to do that<br>um and and we and<br>but combining this sort of symbolic<br>reasoning with the machine learning<br>which has been doing so very<br>well recently and this is from 2014 so<br>you're totally unimpressed by it<br>now but back in 2014 that was that was<br>that was impressive getting good at this<br>stuff requires you to be able to take a<br>problem that you're trying to solve<br>break it down into sub problems break<br>that down into sub problems<br>find the answers to those sub problems<br>and then compose those answers back up<br>into<br>an answer here's a simple example i'm<br>not going to go through it<br>but this allows you to prove that<br>honolulu is a city<br>um based on something population based<br>on it being bigger than dunedin because<br>that's kind of my<br>criterion but then dunedin when i lived<br>there as a child<br>yeah that's where that constant 70 000<br>comes from right so we're trying to<br>that's how that's kind of our program<br>right make computers<br>um able to do at scale the sort of<br>reasoning that<br>the sort of thinking that we don't like<br>doing because it's hard<br>and that anyway we can't do well enough<br>because of hardware<br>limitations like network bandwidth the<br>clock speed of our brains which is about<br>200 hertz at the um right five kilohertz<br>at the very<br>there's one kind of neuron in your ear<br>which fires at five kilohertz but that's<br>it<br>that's the fastest you know what<br>computers think of five kilohertz<br>um they think that that is a decade or i<br>don't know a decade in between<br>firings right so um yeah<br>so we've got um so we're trying to do<br>that and we're trying to do that by<br>uh carrying out a program of research as<br>one does<br>because we're at a university and they<br>won't continue to pay me<br>if i don't carry out a program of<br>research<br>right so one thing that we're trying to<br>do is teach this is a collaboration with<br>the people that ibm researched who i<br>whom i used to<br>live with and some of uh grad students<br>including<br>chiming there so treat mathematics as a<br>game so<br>you know the reason we wanted chess was<br>because of reinforcement learning<br>we are able to explore you know given<br>that there are a set of legal moves<br>we're able to explore those legal moves<br>we're able to tell whether we're one or<br>not<br>right that's all true of mathematical<br>proof<br>it's interesting to note that the<br>majority of things that in mathematics<br>that we think are true<br>we do not have machine verifiable proofs<br>of them<br>right so the vast majority of<br>mathematics is<br>informal from the point of view of<br>mathematical logic itself<br>so we would like to fix that<br>and then go on for there so you know<br>this is<br>again aristotle this is an early<br>mathematical proof<br>that's a less early one that's a fairly<br>recent one about<br>four colors and maps which you may have<br>heard about<br>when you grew up it was like done by<br>enumerating<br>a large number of cases because there<br>were computers<br>but you know just like chess<br>a mathematical proof um you can tell<br>when when you're finished or not<br>but if it's a formally verifiable proof<br>you can tell whether it's a proof or not<br>so you can get a you can get a pellet<br>you know rewarding you if it's a proof<br>and nothing if it's not a proof and<br>there are<br>moves that you can make and those moves<br>are<br>used in inference rules to combine two<br>lemmas<br>two things that you already knew into a<br>new thing and though the set of those<br>inference rules are small<br>the set of lemmas unfortunately is much<br>bigger than the set of<br>moves in a chess game or even a go game<br>which is why<br>this hasn't already been done but<br>yeah but we're working on this i i<br>expect this to work in the not distant<br>future i would be surprised if it takes<br>10 years<br>to get computers better at mathematical<br>proof than humans<br>and that will be useful um on complete<br>on a very different<br>path we're trying to build we're trying<br>to at least think about what it would<br>mean to build an ai system that<br>embodies a cultural viewpoint so<br>um can you build a system that doesn't<br>just produce<br>text right but produces text which um<br>or which produces uh outputs which<br>reflect<br>its membership in some way of a culture<br>a distinct culture or a distinct<br>people group and so what does it mean to<br>have a kiwi ai or an american ai or a<br>chinese ai not in terms<br>of it you know speaks new zealand<br>english or<br>american english or chinese or maori<br>or turkish right but because it's<br>culturally situated<br>right it's part of the it embodies and<br>implements the worldview of that group<br>or maybe of several groups<br>in the interactions between them can ai<br>systems<br>therefore contribute to cultural<br>coexistence by working out where the<br>consistencies are and with the<br>inconsistencies which need to be<br>actively managed by uh people are<br>and to mutual benefit and can they<br>contribute to the<br>cultures that they uh are embedded with<br>and because we're in aotearoa<br>indigenous cultures are of sort of<br>particular interest<br>in this resp in this respect so we've<br>got<br>a couple of threads which are working in<br>that direction<br>we're trying to learn to answer<br>questions which require reasoning<br>genuine in particular and uh others are<br>trying to do that<br>uh zucchini is trying to do that as well<br>um so<br>um at the moment there are a lot of<br>systems which can answer sort of factoid<br>questions really well<br>right so if uh or if you have to like<br>combine two simple pieces of information<br>they can do that<br>if it requires more complex reasoning<br>than that and making intermediate<br>results and then combining that they<br>tend to fall apart<br>although something like that is clearly<br>going on<br>inside gpd3 so it's uh<br>why they don't why they don't do it as<br>much of a mystery<br>as what they do do so<br>so we're trying to adapt these question<br>answering systems<br>so that they can do the kind of complex<br>uh problem manipulation<br>and required to answer questions trying<br>to understand the sorts of<br>reasoning that gpt can and can't do and<br>why<br>so this is an excerpt from the paper<br>from the abstract that it wrote for me<br>and if you look at the green bit right<br>number of<br>a number of thinkers blah blah blah<br>while others right<br>in order to maintain that level of<br>consistency<br>that is an inference operation right<br>knowing that the arguments of those<br>pieces um those frames those syntactic<br>frames<br>have to be um are compatible requires an<br>inference operation but it's kind of<br>uncontrolled it's unknown<br>which of those operations you can do and<br>which ones you can't<br>um and there's a whole industry of<br>people who are friends of mine who point<br>at things that it fails to do and say<br>you stupid gpt3 you're not ai at all<br>right<br>so we'd like to understand what uh more<br>clearly what the things<br>are they can't do and then look at<br>whether or not for example there are<br>human psychological mechanisms which<br>might be incorporated into these systems<br>to give them those abilities<br>similarly the the parallelism between<br>those blue things<br>is better than most of your first year<br>students<br>yeah it will it will get a better mark<br>on the<br>satsa que test than uh<br>than a lot of people all right<br>we want so part of that so understanding<br>what they do<br>but really what we want to do is make<br>so clearly they're doing something but<br>if you give them quite<br>simple tasks um actually the winner grad<br>schemer ones are no longer quite the<br>sort of task they can't do<br>but you can give them quite simple tasks<br>involving things like negation and they<br>they get stuff wrong if you ask them to<br>add numbers together they'll get it<br>right<br>some of the time but not others of the<br>time it seems to have something to do<br>whether it's likely that there's been a<br>table somewhere on the web<br>which has those numbers in it so like up<br>to five digits they<br>usually get them right and more than<br>that they don't but we really don't know<br>why what we're trying to do is work out<br>why they're broken in that way and then<br>give them general mechanisms<br>which they can apply through learning<br>right so learnable mechanisms which will<br>allow them to do those sorts of tasks<br>more reliably<br>um yeah so i poured the carafe into the<br>glass until it was empty or full what<br>was empty or full<br>the answer the craft or the uh glass<br>sorry cup um and uh depending on which<br>one<br>you chose uh here the correct answer<br>changes here right so um this<br>type of problem uh these women grad<br>schema problems used to be really<br>difficult now computers are approaching<br>uh i i<br>actually haven't looked at the<br>leaderboard recently they're approaching<br>human performance on these sorts of<br>problems but it's not clear that that<br>transfers to other tasks we would like<br>to<br>transfer it to other tasks these systems<br>like gpt-3<br>they have read the internet so they know<br>every uh they know a lot of stuff<br>including how to write my abstract<br>right but they don't uh necessarily not<br>suppose there's only like one example of<br>some fact somewhere which is required to<br>answer a problem they can't do anything<br>about that at the moment there are<br>systems which do information<br>retrieval while they're doing question<br>answering but these have not been<br>combined together and even if you do<br>combine them together they wouldn't take<br>the intermediate<br>reasoning whatever that is that they've<br>done store it away and use it later so<br>incorporating meaningful long-term<br>memories and<br>a meaningful theory of theory formation<br>so that for example<br>uh even if at the moment even if they<br>read all the psychological<br>or the molecular biology papers right to<br>work out whether they're<br>consistent internally they couldn't<br>really work out whether they're<br>externally consistent because they<br>wouldn't be able to build the<br>abstractions which are<br>needed to compare them right so this is<br>uh<br>something that uh we're going after in<br>fact josh is<br>supposed to be uh working on something<br>related to that at the moment<br>um right so those are some research<br>projects um right we're almost out of<br>time<br>societal impact yeah so<br>doing things which could replace all the<br>useful work done by humans<br>is not without its impact on our<br>civilization<br>on the other hand like wiring us all up<br>with satellites and<br>fibre optics was not without its impact<br>on civilization either<br>inventing writing was not without its<br>impact of<br>civilization it enabled for example mass<br>religion for good or bad right so these<br>uh<br>there are uh all sorts of effects how<br>can we<br>uh how can we mitigate them so you know<br>he<br>has sort of what's coming at us um over<br>the next<br>couple of decades you know from<br>large-scale reasoning which means uh<br>which leads to<br>assistance that can do the sorts of<br>the sort of tasks that you would if you<br>were allowed to have a professional<br>staff member<br>help you they would be doing for you<br>right um<br>that that is certainly uh coming better<br>than human speech recognition<br>is certainly coming including the<br>ability to hear<br>things that you think can't be heard<br>right so that's a little bit of a<br>worry um general conversational<br>interactions certainly happening<br>and uh going to happen better than human<br>translation just because they can read<br>more stuff<br>than a human could in many lifetimes is<br>coming<br>it's hard to tell exactly when i'm<br>involved in one<br>effort in broadly capable robotics<br>back in the u.s hard to tell when that's<br>happening but i have a feeling that we<br>might be<br>at about where we were in 2000 with cell<br>phones<br>um for robots that um<br>they're about to become useful enough<br>that there will be a self<br>uh a fee a positive feedback<br>um development loop which will rapidly<br>improve them<br>um and then broadly capable of corporate<br>ai right so companies that can<br>mostly run themselves without uh humans<br>evolved and then<br>general superintelligence who knows when<br>this is i'd be surprised if it's not the<br>century<br>i wouldn't be surprised if it's slightly<br>after 2050<br>um when you know there's almost nothing<br>that involves kind of thinking<br>that human beings are generally better<br>at<br>than computers so we better start doing<br>stuff about that right and uh you know<br>the downsides of these are<br>you know pretty bad lots of constrained<br>sensing and manipulation jobs all the<br>factory jobs go<br>lots of constrained intellectual jobs<br>like answering email<br>dealing with the dealing with the<br>ridiculous forms that doug<br>now is responsible for uh foisting upon<br>me<br>you know therefore you know and if you<br>lose those jobs you get vastly unequal<br>loss of resources because the people who<br>just who don't uh need people for those<br>jobs anymore get richer the people who<br>used to have those jobs and don't get uh<br>poorer<br>therefore broad job loss and uh and<br>broad loss of human control over<br>corporations<br>um in much the same way that we have um<br>you know<br>that various reorgs cause humans to lose<br>control over the university<br>um similarly uh um you know that would<br>have<br>that could happen in a much wider uh way<br>um<br>and uh you know the end point of this<br>sort of<br>distribution from the people who um are<br>using ai<br>um from the people who used to do what<br>the ai is doing<br>could lead to pretty extreme uh<br>instances<br>of rent uh seeking by corporations with<br>ai<br>um based on ai you know and the<br>the the worst case you know the the end<br>point of that is that there's one<br>company in the world goldman sachs which<br>is entirely<br>run by an ai for the benefit of goldman<br>sachs but nothing else<br>right so this wouldn't be uh wouldn't be<br>great or zero i don't know<br>you know if you want if you want new<br>zealand to win it doesn't really matter<br>um and then you know the general in<br>utility of humans<br>right which doesn't have to be a bad<br>thing as long as humans still have value<br>right um relaxing is not bad<br>i've i've already shown you that i don't<br>need to write abstracts for talks<br>anymore<br>or at least i only have to write the<br>first half of them<br>but that could lead to generalized loss<br>of human autonomy that wouldn't be good<br>or<br>the future can be uh really good if we<br>maximize<br>if we use ai to maximize health<br>longevity and justice if we use it to<br>maximize<br>equality of access to resources<br>which means like changing our notion of<br>ownership of them<br>means changing our notion of how you<br>allocate resources<br>because you can't allocate them based on<br>utility which we don't at the moment<br>anyway<br>right but we can't do that at all we<br>can't even pretend that we're doing that<br>um a widespread benefit from the<br>economic and other products of ai right<br>i mean<br>there's no reason why anything in this<br>situation should cost almost anything<br>right when nothing useful<br>should cost needs to cost anything if<br>you have this complete automation<br>right so this could lead to freedom of<br>people people groups animals in the<br>environment<br>it could lead to ai systems which really<br>understand the cultures of different<br>people groups managing the relation<br>gently managing the relationships<br>between them and helping people to<br>maintain<br>more agreeable relationships while not<br>being interfered with<br>right it could you know that could lead<br>to general<br>increases in human autonomy and our<br>ability to act properly as<br>communities which is something that<br>we're really good at when provided the<br>means to do it<br>um and could end up with us uh<br>you know increasing the sustain uh<br>sustainability and then perhaps the<br>reach across the<br>galaxy of human civilization right so uh<br>plan<br>plan b plan b is the one to pick right<br>so uh<br>let's make that happen um yeah and the<br>the future of thinking which can lead to<br>plan b<br>uh definitely includes um aotearoa<br>we don't want you just to come to the<br>university of auckland and join the lab<br>we would like<br>cooperating to bring this together right<br>certainly the psychology department has<br>a enormous role to play<br>in for example helping us to learn<br>what sort of things should be added to<br>gpt to make it<br>smart enough to reach these goals all of<br>the aia doing<br>departments across the country can work<br>together to achieve these uh<br>ends and their own ends more quickly we<br>really<br>we we can have an impact on this<br>future and i would very much like<br>you</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>