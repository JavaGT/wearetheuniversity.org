<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">The promises and perils of big data in healthcare [51:19]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=wOi2ppgYybU" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCPVjZXotZ5oX9jyXlFFRj2w" target="_blank">University of Otago - Ōtākou Whakaihu Waka</a></p><img src="https://i.ytimg.com/vi_webp/wOi2ppgYybU/maxresdefault.webp" alt="Thumbnail for video titled: The promises and perils of big data in healthcare" style="width: 100%;"><div class="tags"><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#big data</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#healthcare</span></div><h2>Description</h2><p>This Medical Forum is presented by Dr Angela Ballantyne, Senior Lecturer in Bioethics, University of Otago Wellington, "The promises and perils of big data in healthcare."<br>Find out more about Dr Ballantyne http://bit.ly/2xfZXq6</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>okay welcome everybody my name is<br>Lindley Anderson I'm head of department<br>of the bioethics Center and it's great<br>to see so many people here for our<br>presentation from Angela who happens to<br>be sitting up in Wellington fingers<br>crossed for technology succeeding today<br>I'm sure it will welcome Angela we're<br>very much looking forward to your<br>presentation but just to tell you a<br>little bit about Angela she's a senior<br>lecturer in bioethics at the University<br>of Otago Wellington and her research<br>interests include exploitation research<br>ethics vulnerability the effects of<br>pregnancy and reproductive technologies<br>in secondary use research with clinical<br>data now Angela's just published a book<br>that combines a number of her interests<br>in the book co-authored is pregnancy<br>vulnerability and the risk of<br>exploitation and clinical research now<br>Angela has a very illustrious sort of CV<br>in 2016 she received in New Zealand<br>mazdan faster grant in University of<br>Otago Wellington Award for Best emerging<br>researcher she's been president of the<br>big international association of<br>bioethics a big global enterprise and is<br>their ethics member of the central<br>ethics committee that's the health and<br>disability ethics committees she's<br>worked in schools of medicine primary<br>health care and philosophy in Australia<br>England and the US and as the Technical<br>Officer for genetics and ethics in the<br>World Health Organization in Geneva<br>prior to returning to New Zealand she is<br>a visiting scholar at Yale University<br>interdisciplinary Center for Bioethics<br>and I am sure I you all join with me in<br>welcoming Angela for her presentation so<br>Angela thank you very much in our hand<br>directly over to you and we do have to<br>finish it 10:00 to 2:00 so we'll have<br>time for some questions at the end so<br>thank you very much Angela okay so can<br>you hear me all right that clear enough<br>so I just start ok I'll assume you let<br>me know if you can't hear me or first of<br>all thank you so much for letting me<br>present from Wellington and I know it's<br>kind of a pain you do have to watch a<br>screen rather than a real person but I'm<br>hugely helpful for me not to have spent<br>the whole day flying to Geneva and back<br>you back so thank you for your<br>consideration in that regard<br>so as Lindley said I'm currently working<br>on a master and faster grant which is<br>looking at secondary use of clinical<br>tissue and clinical data for research<br>purposes without patient consent and I'm<br>going to be talking about one aspect of<br>that today which is the use of<br>healthcare data for research and I'll be<br>looking at the promises and the perils<br>of big data and healthcare this image<br>I've got on the first slide is an image<br>from Times Higher Education supplement<br>which represents our humanity riding<br>into the future on the back of big data<br>and logics and that for example kind of<br>captures some of these ideas about the<br>huge promises we've heard about how big<br>data can revolutionize all sorts of<br>industries including healthcare so big<br>data deserves a definition to start with<br>and so it's typically defined in<br>relation to the what's called the three<br>B's which is the volume of data the<br>variety of the Dargis are real mix of<br>different sources of data and the<br>velocity so that refers to the<br>processing speed of computers required<br>to process the data and a lot of the<br>examples I'll be talking about today are<br>big data examples but I also want to<br>make the point that a lot of what I say<br>today will apply to things that aren't<br>typically defined as big data so it may<br>be like small or medium data and<br>projects that you must example might<br>have been involved in there's a lot of<br>different ways of trying to<br>conceptualize how much data there is in<br>the world these days and the soundbite<br>that I find most compelling is the<br>statement that 90% of the data that<br>currently exists in the world was<br>generated and only<br>two years and that is continuing to<br>expand exponentially so we're generating<br>more and more data and with that comes a<br>lot of interest and how we might use<br>that data<br>the second reduce data involves taking<br>data that was collected for one purpose<br>and what I'm going to talk about today<br>is data that was collected and the<br>clinical context for clinical care and<br>reusing it recombining it repurposing it<br>sharing it linking it with other data<br>for a new purpose and one of the things<br>that's really distinctive about data in<br>Big Data and what we're seeing in the<br>data ecosystem is the fluidity of data<br>so data moving from the healthcare<br>context to research to the financial<br>sector and government and administrative<br>services and their fluidity means it can<br>be quite difficult to control so that's<br>one thing I'm going to be focusing on<br>today is given the complexity of the<br>data ecosystem the way in which it's<br>fragmented and that idea of fluidity<br>where can we try and exert control to<br>minimize the risks of big data and try<br>and maximize the benefits so here's an<br>overview of what I'm going to do and I<br>want to tell you first of all about what<br>the rules are for how you can use health<br>information for research in New Zealand<br>then I'm going to talk about what some<br>current challenges are and those are<br>largely come down to this exploding<br>demand for use of data and the sources<br>of data are expanding as well and both<br>of those mean create challenges for<br>controlling access to data and I'm going<br>to talk about three mechanisms we can<br>think about as potential tools to try<br>and control data access and those are<br>consent governance and transparency<br>models first I just want to make the<br>kind of preliminary point and define<br>some concepts so there's a difference<br>between law ethics and social license<br>and I think sometimes and debates you<br>know and big data it's one of those we<br>can get a little bit confused sometimes<br>about the difference between these three<br>so very simply and hopefully there's no<br>lawyers in the audience<br>Laura's basically what you<br>so what according to legislation are you<br>permitted to do ethics is a different<br>question and that's what should you do<br>so there's a normative investigation of<br>what the right course of action or the<br>right way to treat people or dasha<br>would be in social license the way I'm<br>using it today and as a descriptive term<br>to simply describe what the public<br>thinks it's okay to do in a certain<br>sphere so in this case in relationship<br>use of health data now those three<br>things can come apart so it might be<br>that the law permits you to do something<br>but there isn't social license for that<br>and there might be good ethical reasons<br>not to use data in that way ideally what<br>we're trying to do is align all three so<br>that we've got a legal use of data<br>that's it's a clear appropriate and<br>socially sanctioned so that's kind of<br>the that's the goal that we're working<br>towards but just be aware that sometimes<br>these three things can come apart so to<br>start with the law then and what can you<br>do with patient data without consent so<br>we start with the health information<br>privacy goal and rule 11 as concerns the<br>disclosure of health information so you<br>can disclose health information if the<br>reason for disclosure is directly<br>related to the purpose for which you've<br>got the health information so this is<br>typically thought to include sharing<br>health information with the clinical<br>team the purposes of clinical care and<br>to also allow peer review and quality<br>audit and these and the justification is<br>that the disclosure should be within the<br>expectations of the person who gave you<br>the health information so it should be<br>they should the data subject or the<br>patient should expect that this is a<br>possible use of the data and we<br>shouldn't be doing things with the data<br>that are outside patients expectations<br>there is an exception to that which is<br>that you can use health information for<br>research purposes without patient<br>consent if you get approval from a<br>research ethics committee if required<br>for that use so that takes us over to<br>the National ethics Advisory Committee<br>observational guidelines and this is the<br>guidance that if it's committees have<br>for determining if you go to<br>committee and say can I have access to<br>this patient information for research<br>these clauses here guide the efforts<br>committee in their consideration of your<br>request so there's three three criteria<br>and you have to get a YES on each of<br>those and with an a there's three<br>different options so first of all you<br>have to show that the procedures<br>required to obtain consent would either<br>cause unnecessary anxiety to patients or<br>their families prejudice the scientific<br>validity of the study or would be<br>impossible and practice to obtain for<br>example the patient's I did so you have<br>to satisfy one of those three and in the<br>next two there would be no disadvantage<br>to the participants or their relatives<br>or any collectives involved and the<br>public interest in the study outweighs<br>the public interest in privacy so that's<br>kind of we the law sets at the moment<br>the these are these guidelines and<br>effect all the research is its<br>guidelines in New Zealand are currently<br>under revision and we expect kind of a<br>document to be released by Ministry of<br>Health hopefully by the beginning of<br>next year for consultation so if this is<br>an area that you're interested in I<br>would say expect some movement in<br>relation to access to data use and make<br>sure that you are available to kind of<br>submit commentary or you know your<br>thoughts and during that consultation<br>process okay so um my view is that an<br>exception where if it's committees can<br>allow access to data we win those<br>criteria criteria or image was<br>originally used as an exception so the<br>idea was you're supposed to get consent<br>in the majority of cases but if there's<br>really overwhelming public benefit in<br>your study and you really can't get<br>consent you know I guess committee can<br>join your waiver I sit on the next<br>committee and I think from what I hear<br>from other if it's committees we're<br>seeing increasing applications to access<br>data on these grounds and that just<br>gives you an idea of the increasing<br>demand for data for a range of different<br>purposes and this creates a challenge I<br>think so what can you do with the data<br>well dad is useful too and in many of<br>you will have been involved in research<br>studies using data for these kind of<br>examples to improve health service<br>provision so to figure out<br>yeah health services are needed which<br>patients are going to benefit and to try<br>and really align your health service<br>provision with the patients that will<br>benefit most from that and they need<br>access to the services to reduce costs<br>so if you target your health services<br>more effectively and you reduce waste in<br>the system this is really the underlying<br>philosophy of the whole social<br>investment approach which has been a key<br>strategy for Bill English over the last<br>five years probably um in development of<br>the social investment agency development<br>of the IDI I'm gonna talk about in a<br>minute which is really designed to<br>provide to use public sector data to<br>provide an evidence base regarding which<br>social services work and to guide social<br>spending so this is within health and<br>more broadly across government services<br>to generate new medical knowledge so I<br>was at a conference um two weeks ago<br>where researchers were talking about<br>linking five different New Zealand<br>databases so no involvement with<br>patients no no necessity to get consumed<br>so just looking at data that was already<br>collected and they were looking at the<br>impact of HPV vaccination rates as a<br>protective factor and preventing preterm<br>birth during pregnancies so this was<br>entirely new kind of potential benefit<br>of the HPV vaccination so generating<br>real you know genuine innovative new<br>medical knowledge of existing datasets<br>so capturing their knowledge precision<br>medicine is one of the kind of off 2,000<br>potential benefits of Big Data yet to be<br>realized yet I would say the idea of<br>precision medicine is that you use<br>things like pharmacogenomics to really<br>go to identify which patients are going<br>to have adverse reactions to drugs for<br>example and again really minutely target<br>specific interventions and drugs to<br>patients who will most benefit from them<br>and in predictive health modeling so<br>that's looking at health system as a<br>whole<br>patients progression through the health<br>system over their life and really trying<br>to invest early in high-risk patients to<br>prevent health needs developing and also<br>to reduce costs so lots of demand for<br>data and lots of<br>different to be used in lots of<br>different ways so as I said one example<br>of this is the integrated data<br>infrastructure so this is a<br>world-leading data resource in New<br>Zealand that the government has<br>established and is hosted by statistics<br>New Zealand and it's a database<br>containing de-identified micro data<br>about people and households and it can<br>be used to the following sorts of<br>studies for example and this is a study<br>done by Treasury in 2015<br>looking at the data to see if they could<br>identify children there were greater<br>risk of having adverse outcomes and<br>looking at the data they identified four<br>indicators that might predict children<br>at risk and these were having a sifts<br>finding of abuse or neglect being mostly<br>supported by benefit since birth having<br>a parent with a prison or community<br>sentence and having a mother with no<br>formal qualifications then you can play<br>with the data a bit more and see for<br>example that 35 percent of children who<br>are flagged at being at risk actually<br>don't end up having any adverse outcomes<br>and so you might want to look at the<br>data and see what kind of resilience<br>factors are at play here 65 percent<br>heroic age being at risk do have one or<br>more of the poor outcomes and then you<br>can look for example at the distribution<br>of risk across New Zealand so this is<br>kind of an example of the way lots of<br>different data sets a mixed to try and<br>predict patterns predict risk and inform<br>provision of services okay so given this<br>increasing demand for data there are a<br>number of examples where this has caused<br>some controversy so I'll tell you about<br>a few of these so one is the OkCupid<br>example this is a online free dating app<br>in 2016 Danish researchers wrote an<br>algorithm to scrape the data and collect<br>70,000 user profiles packaged out of the<br>data see it and release it on the<br>internet on an Open Science framework<br>platform for social scientists to use<br>for research purposes they didn't<br>include people's actual names but did<br>include user<br>a whole range of personal information<br>now the researchers said well I mean<br>this is a free publicly accessible<br>database all we had to do to access it<br>was to create our own account and then<br>we could see in if the accounts are<br>available so we're not it's not an<br>invasion of privacy people who are using<br>the service said that it was outside<br>their expectations of what they thought<br>would happen with the data and that they<br>were really unhappy about it and in the<br>end it was such significant controversy<br>that eerie searchers pulled the data set<br>from the public wrong that's one example<br>of controversy another one closer to<br>home recently has been the Ministry of<br>Social development's policy of<br>requesting personal identifiable client<br>level data from NGOs that provide social<br>services and they get funding from the<br>government so the new model was that was<br>going to introduced was to require that<br>all this patient level data be shared<br>with MSD as a condition of future<br>funding contracts now this caused a lot<br>of concern in the NGO sector agencies<br>such as rape crisis Women's Refuge well<br>stop which is an NGO that provides<br>services to people engaged in harmful<br>sexual behaviors or really concerned<br>that a range of things may happen one<br>bit people who use their services<br>citizens use their services might be so<br>concerned about MSD having access to<br>their personal identifiable data they<br>might not access the service when they<br>really need it and that'll be a problem<br>- they might access the service but they<br>might provide false information which is<br>problematic in terms of the NGOs ability<br>to provide appropriate services for that<br>person but also max up the data anyway<br>and all three there was a concern that<br>NGOs actually might start treating some<br>some users off the box so some users who<br>weren't pitch to their data might be<br>just treated big of an access to the<br>services and without any records being<br>kept and again that's problematic for a<br>range of reasons so a need and the<br>Privacy Commissioner came out and John<br>Edwards and said that the policy was<br>excessive and disproportionate the<br>policies currently been put on hold<br>because of an<br>an image a related MSD data security<br>breach and concern not because MSD<br>backed away on kind of ideological<br>grounds from this policy so we might see<br>that resurface and the last example I<br>want to talk about was the case where<br>the National Health Service in the UK<br>shared patient data with google's<br>deepmind service which is googled<br>artificial intelligence company so this<br>happened in 2016 and they shared 1.6<br>million patient records for patient<br>records and with Google so that deepmind<br>could look through the data and develop<br>an airport stream which was designed to<br>detect acute kidney injury as in<br>hospital so that here could be given to<br>patients more quickly the full records<br>included HIV status abortion history<br>mental health history and the argument<br>for that was that the whole reason they<br>needed the artificial intelligence<br>program was because they didn't know<br>which variables to look at so they had<br>given the four patient records so that<br>the program could analyze all of that<br>and come up with the appropriate<br>algorithms this is caused a lot of<br>controversy it's been challenged on<br>legal grounds so the legal grounds that<br>the NHS used to share the data was that<br>idea that I spoke about right at the<br>beginning that it was that the patient's<br>disclosed their health information for<br>the purposes of direct patient care and<br>this was an example of providing direct<br>patient care therefore was was one of<br>the original purposes for which they got<br>the health information and that is being<br>challenged on legal grounds so John Bell<br>who's a professor at Oxford released a<br>report only a few weeks ago arguing that<br>it was a misuse of public resources so<br>saying the NHS is an amazing public<br>resource should be used for the benefit<br>of the UK population not to allow<br>private companies to profit his view is<br>that it was such a rich data CH and<br>developed these incredibly powerful<br>algorithms there<br>deepmind couldn't have developed<br>otherwise that it could lead possibly to<br>an entirely new industry and was a real<br>competitive advantage for google to have<br>access to this data<br>so because it was a lot of demand and<br>what that demand comes controversy I<br>mean so the other source of challenge is<br>just the variety of places that health<br>data is now collected and that makes it<br>difficult to control as well so we've<br>talked about clinical data data that's<br>collected for the purposes of clinical<br>care but also we have research data and<br>some of that research data can be reused<br>for future projects I think many of you<br>will be aware that when you submit<br>publications to some of the leading<br>medical journals these days they're<br>asking you to submit your primary data<br>sets in a public database for future use<br>so that's reusing research data<br>there's also patient generated data so<br>this can be home monitoring devices that<br>vets X people download on their phone<br>the one concern one challenge here is<br>that this means that the app developers<br>and the private sector are really the<br>ones that are collecting the health<br>information and that can make it harder<br>to monitor and manage as well so one<br>example here that caused controversy<br>again in the last year um was a company<br>called We Vibe um who developed a smart<br>technology vibration so this was a<br>vibration that could be remote<br>controlled and so if your partner wasn't<br>with you or you've met someone over the<br>internet that you wanted to play with<br>you could give them the code and they<br>could control the vibration as you were<br>using it but what users didn't realize<br>was the company was collecting data<br>about vibrations sitting temperature<br>duration of use and we're using this to<br>continue to develop fear services they<br>see that this was just Quality Assurance<br>which sounds a little bit similar to<br>some of the arguments we use around<br>reuse of health data um in no further<br>app development but customers sued the<br>company for misuse of data and they and<br>their company agreed to a settlement um<br>we don't know how much for in December<br>last year<br>there's also laboratory data so data<br>samples for example at tissue samples<br>that have been processed and turned into<br>data that can be used and administrative<br>data so for example farm ain't got a<br>health service utilization data so we've<br>got lots of different demand for data<br>and data have been held in lots of<br>different areas so I want to just talk<br>for a minute now about what are what are<br>the risks what are the ethical risks in<br>relation to data research I think which<br>we still tend to focus primarily on<br>individual risks and that's risks to<br>privacy confidentiality and potential<br>harms that might result to individuals<br>if there is a breach of their personal<br>health information I think we do this<br>because our research ethics paradigm<br>comes from an focus on interventional<br>research and comes for example from the<br>Cartwright inquiry report where the<br>focus is really on doing things to<br>individual patients so that's what's<br>kind of prominent in their mind so this<br>is a risk if you're using identifiable<br>data and there is a risk of privacy<br>breaches I think there's a real concern<br>there's a problem that I see which is<br>that we can tend to assume that if we're<br>not a - the data being there sufficient<br>to prevent harm and I really want to<br>challenge that today so I think there's<br>a range of harms not necessarily to<br>individuals but to collectives or<br>communities or groups and this happens<br>even when the data is not identifiable<br>whether it's anonymized the identified<br>potentially identifiable coded these<br>risks so even a few manage risks in<br>terms of individual privacy breaches you<br>still live with these risks to groups<br>and there can be in terms of<br>stigmatizing groups leading to<br>discrimination surveillance of<br>particular populations and entrenching<br>and equality so one example of this as a<br>policy slightly outside the health field<br>and a policy called predictive policing<br>so there's many states in the US for<br>example use data analytics to drive<br>predictive policing so what you're<br>trying to do there is use algorithms to<br>forecast where crimes are likely to<br>occur in advance and allocate resources<br>sounds like that um Tom Cruise movie<br>wasn't it along similar lines okay but<br>this is real um and you can use the<br>algorithms to either profile individual<br>sort of profile neighborhoods but the<br>problem is that all the data that's fed<br>into those models reflects all the<br>biases racism and discrimination that we<br>know exists in the American police force<br>and judicial system and no to a very<br>similar degree and you know in New<br>Zealand and other countries as well so<br>for example 2013 the state of New York<br>did some research around what what<br>police in America can do which are<br>called<br>stop and frisk so they can temporarily<br>stop detain and question people as<br>there's a reasonable suspicion that they<br>may be involved in a crime in 2011 for<br>example police officers are stopped<br>nearly 700,000 people in New York now<br>black and Latino males aged between 14<br>and 24 make up only 4.7 percent of the<br>population in New York but made up in<br>2013<br>forty percent of those who were stopped<br>and frisked by police 90 percent of<br>those people were released in the end so<br>they were stopped and there was no good<br>ground found for detaining them longer<br>but if you were a Latin or African<br>American youth you have far far more<br>likely to be stopped by police and<br>therefore generate a criminal record and<br>this is the data that's been feeding<br>them up into the model to try and<br>predict in advance where crimes are<br>going to occur this leads the model to<br>the InFocus police resources and<br>neighborhoods that have high numbers of<br>Latino and african-american males<br>leading to the likelihood that they're<br>more likely to be stopped in the future<br>so you sort of get this vicious cycle<br>and where if there's inequalities and<br>biases and the core data using that data<br>again and again for these kind of<br>algorithms can just perpetuate and<br>entrench their inequality you know we<br>also know for example that in terms of<br>reporting crime foreigners and migrants<br>are less likely to report crime often<br>because they have less trust of the<br>police so neighborhoods with high<br>degrees migrants might be under<br>recording crime so it's really important<br>to think about the biases in the source<br>data and how these data analytic<br>programs could potentially harm<br>collectives<br>all right so we've talked about the<br>rules um accessing health information<br>we'll talk about some of the challenges<br>and some of the risks but I just want to<br>finish by talking about three different<br>options for trying to control the data<br>ecosystem and there's a bit of a tussle<br>at the moment in the literature around<br>which would be the best option I'm going<br>to talk about consent governance and<br>transparency so the range of different<br>models of consent and the first is a<br>specific consent and that's what you'll<br>be familiar with in terms of clinical<br>care standard research ethics um the<br>world Medical Association and their<br>declaration of type a just come out and<br>reg this is end of last year reiterated<br>that for data use and by bio banking and<br>data banking you need really<br>comprehensive specific consent from data<br>subjects and patients so there's a<br>really high standard in other areas we<br>see the idea of broad consent so this is<br>for example and those of you have done<br>research might be familiar with the idea<br>of future unspecified research we're<br>increasingly seeing researchers asked<br>for blood or tissue samples to be able<br>to bank for future uses that are<br>currently unspecified that's incredibly<br>broad so it might be you know we want to<br>do anything with your tissue in the next<br>50 years<br>um so many argue that that it's<br>problematic because it doesn't amount to<br>valid consent um another option of<br>dynamic consent which is where you have<br>a web dynamic web interface we use your<br>ongoing communication with the people<br>who have heard with the data subjects<br>and this works reasonably well for<br>established data banks or bio banks<br>where patients know that they've given<br>you their information and patients can<br>kind of click on which studies they want<br>their data to be used for but it's<br>resource intensive and in the some<br>debate about opt-out models so whether<br>you allow the public to opt out of data<br>use and if they don't you go ahead and<br>use it um it's a few problems with the<br>consent option in terms of regulation<br>one is that you just can't adequately<br>anticipate future uses of data so if<br>you're relying on getting conceived at<br>the point of collection<br>and we know that technology cycles are<br>about every five years it's very likely<br>that within ten years we're gonna better<br>do stuff with data that which is just<br>inconceivable when you collected the<br>data so for me I think at that point<br>you're getting you know they can see it<br>is so incredibly broad that I think it's<br>basically meaningless um your other<br>option is otherwise to have ongoing sort<br>of dynamic content models but that seems<br>to be really difficult to roll out<br>across the population um particularly<br>for our most vulnerable members of the<br>community I also think that can seem<br>from individuals isn't sufficient so<br>even if you've got consent from every<br>data subject or every patient that<br>wouldn't necessarily meet some of the<br>concerns around teacher collective harms<br>but even though it's not sufficient<br>there's still debate out there about to<br>what degree it's necessary so governance<br>um as an alternative model to governance<br>is rather than individuals providing<br>authorization it's a representative<br>group providing authorization for data<br>use and you'll be familiar with this in<br>terms of the role that research ethics<br>committees play in terms of governing<br>research data access committees that are<br>associated with specific data sets<br>there's been some debate about whether<br>New Zealand needs something like a data<br>Ombudsman so for example Jane Fiona<br>Caldecott is the national data Guardian<br>in the UK and she came out and commented<br>publicly on the NHS deepmind<br>collaboration and as an important group<br>in New Zealand recently established<br>court to monitor donor who are the<br>Murray data sovereignty network um and<br>they have argued for they're arguing for<br>Maori data sovereignty over Murray data<br>and for something idea therefore called<br>a cultural license which is that data<br>use doesn't just need to be acceptable<br>to the general population in terms of<br>social licence it needs to be<br>appropriate to Maori and that we need to<br>think about new governance structures to<br>ensure that Maori having a say over use<br>of Maori data then the final ideas but<br>on the table is transparency<br>um so transparency isn't a type of<br>authorization and that it's not asking<br>for permission at any point um<br>but it's a really important platform in<br>my mind for facilitating public debate<br>so when you're transparent about what<br>you're doing with data it can mean<br>individual data subjects at least have<br>the option of finding out what's going<br>on with their data it can mean that<br>journalists and other agencies and civil<br>rights organizations lawyers can<br>critique data use and generate public<br>debate it means that so that and that<br>can mean that we pick up on concerning<br>specific individual examples of data use<br>also means that we can actually audit<br>the data ecosystem more effectively and<br>figure out what are the patterns in<br>terms of data use who's using health<br>information and it can support<br>accountability and that it can hold<br>researchers who are misusing data to<br>account so there's an agency called the<br>data future program partnership sorry<br>and that's a independent group in New<br>Zealand government funded and they have<br>just released ten days ago two weeks ago<br>and a judgment on social licence in New<br>Zealand and they're really pushing for<br>the idea of transparency as an important<br>platform and so this is the transparency<br>wheel it's got eight questions and<br>organizations GP practices hospitals<br>private companies should be asking<br>themselves about data use and their idea<br>is that all organisations to have a<br>publicly facing example of this on their<br>website and there should be different<br>layers of information so that<br>individuals can click on the part of the<br>wheel that they're interested in and<br>find out more information you see one of<br>the examples is can I can am I going to<br>be asked for my consent so there are two<br>future programs of view is that even if<br>you're not asking for consent sometimes<br>that's fine but you need to be<br>transparent with people about whether<br>they're going to have the option of<br>consent or not in relation to the<br>specific use<br>and they also flag their specific<br>stakeholder and participant engagement<br>as would be appropriate in a number of<br>cases so over and above this<br>transparency model and that's where the<br>data use is really novel for the<br>population and question it involves low<br>trust or vulnerable groups and or has<br>significant impact on<br>or Maori so in summary um I think we<br>need to move away from the idea that the<br>anonymization is sufficient to prevent<br>harm in relation to data use I think we<br>need to shift our focus away from harm<br>to individuals and have a much more<br>substantive debate about harms to<br>collectives or communities in relation<br>to data use and we need ongoing debate<br>about the best models for controlling<br>dirty is considering consent<br>transparency and governance and to<br>varying degrees those will be<br>appropriate in different cases and I<br>think my view is that consent I think<br>that maybe we spend too much time<br>focused on consent and where it's simply<br>not practical in many cases and robust<br>governance models in transparency models<br>and would be valuable alternatives so<br>that's all thank you very much that was<br>really interesting we've got just over<br>almost 15 minutes for questions so<br>hopefully I've got to use this little<br>thing here and hopefully the work so<br>can you hear me yeah okay good thank you<br>very much that is interesting I'm Barry<br>Taylor I'm involved in the Big Data<br>around the bitter start challenge I know<br>it's challenge can I specifically ask<br>you to comment on the IDI the way it's<br>currently set up and whether it's giving<br>enough protections and transparency of<br>the sort that you're talking about but<br>from what I've read and people I've<br>spoken to I think that the level of data<br>security of the system is good I think<br>I'd like to see additional governance<br>mechanisms in place so at the moment<br>uses of the idea I goes through a five<br>safes cheeks which is sort of safe<br>project safe people so other researchers<br>appropriately qualified safe<br>institutions and is in a question of<br>whether the data use and the public<br>benefit essentially and Liz Macpherson<br>the New Zealand statistician signs off<br>on those so it's sort of her view alone<br>as to whether the sufficient public<br>benefit and I think there's lots of<br>potential cases which is a indicator say<br>with the crime - or a lot of other uses<br>of data where we need to have a deeper<br>more substantive conversation about data<br>use and one thing that you do quite<br>often find is that and the data future<br>partnership has found this as well if<br>you ask the general public do you think<br>it's a good idea to profile families<br>identify at-risk vulnerable children the<br>general public in New Zealand is use<br>this definitely in the public interest<br>but most people won't fall into the<br>category of data subjects whose data<br>will be used if you speak to families<br>who have had engaged on the surface for<br>example you're much much more skeptical<br>so often known I think it's in the<br>public benefit so I think and as far as<br>I know you know unless his office said<br>you know if she has concerns about you<br>know other particular cultural issues in<br>relation to this question do we need to<br>consult with Maori there's no model for<br>her to go through there's no committee<br>for her to go to to get additional<br>advice I do know there's lots of agents<br>there's lots of discussion in relation<br>to government agencies at the moment<br>about establishing internal kind of data<br>ethics<br>committees to provide some kind of<br>advice good hello you hear me<br>Brian coffee I'm interested in the fact<br>that in the list of ethical issues I'm<br>actually raised the ethics in terms of<br>the people using the data need to assess<br>its validity because as since I trained<br>in mathematics and statistics for it<br>admits and I don't use data unless I<br>have a pretty damn good idea about the<br>validity and an accuracy of the data I'm<br>using and that's the way I was trained<br>so for example 15 years ago or 16 years<br>ago I managed to point out the cancer<br>registry that they had seven people with<br>prostate cancer who were women which<br>sort of was a bit of a problem last year<br>I had found that they had two people who<br>had two deaths signed for the same<br>person that this was for eautiful years<br>apart so I'm what makes me about the<br>deaths one last year's a lot of people<br>use that mortality database hekima is<br>the only one that found it and it's the<br>first thing I did to go through and you<br>do these chicks and so I'm concerned too<br>this big data gives you rubbish if a lot<br>of the data points have been validated<br>them so we need to actually a whole<br>system of validation of this that voice<br>that linking all together you getting<br>Miss people think it's great the truth<br>that's the biggest lies you can get yeah<br>um you know I think there's like an<br>incredibly important point and so I<br>talked about some of the potential<br>biases in terms of the underlying data<br>in terms of discrimination or inequality<br>in relation to the data set but you're<br>right it can just be basic errors and<br>that's a particular problem and relation<br>to use of health data quite often<br>researchers need access to identifiable<br>health data to be able to go and kind of<br>clean the data and keep the data for<br>use it well then anonymize it or get<br>into it use it for research purposes and<br>so as oppose one concern I have at the<br>moment is that some studies small number<br>of studies using health data end up<br>because they need access to identify<br>without it going through the research<br>ethics review process but at least be<br>getting some review and there's some<br>discussion about the social benefit of<br>the research I've got a paper coming out<br>in the Z on a medical journal the next<br>few weeks or so kind of raising some<br>concerns about whether research if it's<br>committees have the technical expertise<br>to be reviewing data and to be asking<br>the kind of questions you know that you<br>that you for example would have the<br>skills to ask in terms of you know what<br>data sources do you need and how you<br>accounting for biases in the data how<br>are you controlling for some of these<br>variables um and so I think that degree<br>of expertise is really important in<br>terms of reviewing the data data uses or<br>data proposals and I think it varies a<br>lot but the other difficulty is data<br>moves so fluidly an Assessor I'm sure<br>there's some researchers you know and<br>researchers that I work with here who<br>are very conscientious in kind of very<br>aware of what they need to do to get the<br>right data but um I'm sure there's other<br>cases where that doesn't happen as well<br>I mean I was talking to someone who<br>worked in the private sector and<br>involved with flybys so huge dataset and<br>we're saying that one of her major<br>challenges of actually retaining her<br>data analysts and has you know his staff<br>was that the clients they're working<br>with keep asking stupid questions and a<br>lot of the work they doing with the<br>clients are saying what you want you<br>can't we can't get you good answers for<br>what you want to know with the data that<br>we've got right you need to be asking<br>different questions but so often because<br>it's a service driven industry they're<br>required to do what the client asked for<br>even if they if data scientists think<br>it's a stupid use of the data or an<br>inappropriate use of the data and then<br>her staff just get bored with doing<br>silly things so move off and so yeah I<br>can you catch okay I can't to us for so<br>I can't yeah my concern is at the level<br>of software and so with things like<br>health records so something like health<br>one so that involves the use of the<br>software system and just concerned that<br>we don't have the expertise in New<br>Zealand to manage our secure<br>infrastructure for things involving the<br>internet so that we just don't have at<br>the most basic level control over the<br>use to which the data is part and so I'm<br>concerned that the people who are doing<br>the software and all the software<br>updating and so on that they're<br>basically in the position of being able<br>to do what they want with our data in a<br>way that doesn't profit New Zealanders<br>that's my main concern with the whole<br>Big Data thing and I don't think it's<br>something that I've heard anybody else<br>raise so it's wondering what you thought<br>about that and if that's something that<br>maybe should be on the agenda for<br>something to for people to be concerned<br>about yeah I think it's a good question<br>it's a little bit outside my area of<br>expertise because I don't really I don't<br>have a personal view about this you know<br>the appropriateness of the software that<br>we're using um so a few things I well<br>that's just hum yeah so so a big review<br>that the Nuffield Council did in the UK<br>um looked at data breaches in relation<br>to health data and found that overall<br>data breaches are actually incredibly<br>rare and uniquely data breaches that<br>result in harm do you need it's not a<br>brand the people who they are running<br>the managing the software I don't know<br>what it's the software system called<br>that health one runs on I did ask at<br>some point and it's not a New Zealand<br>software it's managed and run maintained<br>by people over scenes and I'm sure that<br>they they are allowed to do internal<br>checks and all the rest of it to make<br>sure that records aren't being altered<br>by who-knows-who<br>or any alterations that I authorized<br>people or whatever so just in terms of<br>them managing their own software<br>sorts of things that they can do with<br>the data that isn't covered by New<br>Zealand law New Zealand health flora I'm<br>not even sure cuz I'm not sure if we're<br>worrying about these things for anyone<br>to look into it in terms of managing<br>secure and Trinette infrastructure yes<br>it's a different question I mean I think<br>um sort of international conference I<br>was at last year there were data experts<br>talking about the absolute complexity of<br>international data legislation and I<br>think that you're right that data is<br>hosted often offshore data moves between<br>different jurisdictions and that is<br>really complex problematic and should<br>not be going they should be getting<br>approval before it goes I mean I think<br>what my view is that suppose a few<br>things as it comes down to risks and<br>benefits right so I think there are<br>enormous benefits from using the data<br>and so I'm not kind of you know I think<br>we need to be careful not to sort of<br>throw the baby out with the bathwater<br>and so many things that we do involve<br>risks and it's a question of are the<br>risks proportional to the potential<br>benefit so that's why I come back to the<br>fact that you know even if people are<br>accessing the data if they're not doing<br>anything wrong with it if there's no<br>breach if there's no harm to patients<br>perhaps the benefit we get from those<br>services is worth it on balance the<br>other thing I would say is it comes back<br>to social license and really engaging<br>the public in a debate about what's<br>happening because the truth is that<br>eventually there are going to be data<br>breaches in a public if we don't kind of<br>bring the public along with us in terms<br>of how data is used and what the<br>benefits so there are in what governance<br>systems have been in place as one data<br>breach that can you know really damage<br>public trust<br>so I suppose those have been my comments<br>on relations there<br>okay thank you what else got any<br>questions yes see if I can do it this<br>time<br>you ready is that the issue of you<br>submit communities and data being is one<br>of the reasons I don't use the decile<br>system is because it labels groups and<br>labels a community so from my<br>professional practice I declined to use<br>the decile ratings<br>I will tend to use the Association AMA<br>k-- scale but they identify if you like<br>region or body if a group of people with<br>its close and also the other thing is I<br>think it's Chris Cunningham when he did<br>his inaugural rich lecture and a massive<br>from professorship pointed out that 18%<br>of people change their ethnicity between<br>hospital admissions etc and people seem<br>to think of somehow that's fixed way she<br>quite flexible and ever taken into<br>account new statistical analysis that's<br>produced so do you mean particular<br>viewpoint on both of those issues<br>yes the quality of the output no<br>intimately fundamentally tied to the<br>quality of the input so the data that<br>you're using and how effective that<br>matches to what you're trying to I<br>suppose tag I think how do they on a<br>high level part of the real problem with<br>big data is the is how opaque the<br>algorithms are and how you know because<br>it's statistical and because it's<br>mathematical it has this aura of truth<br>and neutrality which I think you make<br>the point that there's all sorts of<br>value-based judgments in terms of what<br>data sources you choose to use it's the<br>previous speaker mentioned in terms of<br>how valid the data is and whether you<br>keep that um but it becomes really<br>difficult for the public you know and<br>even other researchers to interrogate<br>that<br>cause the algorithms are so complex and<br>because it's kind of dressed up in this<br>image of stats and math you know which<br>is therefore true and I'm a suppose<br>might mind my point would just be that<br>the data isn't neutral and the questions<br>we choose to ask of the data I value<br>driven the data we choose to put into<br>the models as value driven with a we<br>account for biases and inequalities you<br>know comes down to questions of value<br>and we just need to keep focused on<br>there and I think you know your your<br>okay right any further questions<br>oh yes I'm good I cannot throw that far<br>nobody told me I had to do upper-body<br>strength training before I came to this<br>thing I was gonna say I've never seen<br>lonely so active animation sorry I might<br>have missed it if it was covered but the<br>definition of data there is data which<br>is not actually gathered as such but as<br>there and that's genetic data when form<br>another so guthrie tests for argument's<br>sake mess clicks and in this country<br>which in circumstances could be defined<br>as data which could be mined for<br>purposes there's a approach which is<br>ethical legislative and social that<br>covers that and so part of a challenge<br>of laboratory data is that it's covered<br>so again your new technology disrupt<br>established conceptual categories and<br>that's what makes them interesting to<br>people like me but also makes them<br>really difficult to regulate so for<br>example you write tissue samples<br>originated under the human tissue act<br>and but being a turned into data insert<br>a potentially and being a regulated<br>under the health information privacy act<br>and in those two pieces of legislation<br>repression their witness is eerily<br>designed to align and this is the<br>problem not only in New Zealand but<br>internationally as well I mean so many<br>countries are trying to rewrite their<br>data regulation at the moment and take<br>into account and<br>the relationship between human<br>biological material and data in even<br>defining stuff like personal data health<br>data sensitive data are incredibly<br>difficult to define I suppose the other<br>again like really high-level comment I'd<br>make is that um so spoke to a data<br>scientist the other day who knows all<br>this talk about how we regulate but<br>there's but lots of research shows that<br>the regulation regulatory cycle is often<br>about 15 years from when an issue was<br>first identified to win it's debated<br>regulation as implemented and a full<br>technology cycle is every five years<br>right so we legislation is going to be a<br>reasonably an effective tool for<br>responding dynamically to data ethics<br>concerns because I think models like<br>kind of transparency in governance are<br>much more fluid and their since people<br>feel a bit more comfortable with it<br>because it means you're not kind of<br>pinning down tight laws but I just AM<br>bit skeptical of pinning down those laws<br>tinnie you know when you're five years<br>behind what people are currently doing<br>with the data and so yeah I mean you're<br>right to point out that um the<br>intersection in terms of regulation of<br>okay thank you very much I see that<br>we're out of time I'd like to thank the<br>audience for your attendance and<br>participation and that session was<br>really good to see so many people and<br>engage in this topic and I finally like<br>to thank Angela ballantine very much for<br>an engaging presentation and like to<br>show you appreciation and the usual</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>