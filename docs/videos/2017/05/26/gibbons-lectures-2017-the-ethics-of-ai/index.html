<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">Gibbons Lectures 2017: The Ethics of AI [55:53]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=lCisLDV9EKM" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCUKg41qkUTUQXGDzklgpmlQ" target="_blank">University of Auckland | Waipapa Taumata Rau</a></p><img src="https://i.ytimg.com/vi_webp/lCisLDV9EKM/maxresdefault.webp" alt="Thumbnail for video titled: Gibbons Lectures 2017: The Ethics of AI" style="width: 100%;"><div class="tags"><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#The University of Auckland</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#University of Auckland</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#UOA</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Auckland University</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Auckland</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#New Zealand</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#University</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Gibbons</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Lectures</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#2017</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Ian</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Watson</span></div><h2>Description</h2><p>Associate Professor Ian Watson, Department of Computer Science, the University of Auckland</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>everyone welcome to the Gibbons lecture<br>and I'll start with a little quiz who is<br>the only person to have given to Gibbons<br>nobody<br>somebody in this audience knows well<br>somebody that's theater knows<br>he lectured on touring as well<br>so he's a lustrous colleague it's my<br>pleasure to introduce Ian Watson to you<br>he's a radio star he's a colleague has<br>been in the department for a bit longer<br>than no not quite as long as me an<br>old-timer and with no further ado thank<br>you very much with me Bob so lovely to<br>see so many people coming out to see the<br>cool you enjoy it before I get started<br>you know what hear me at the back just<br>barely because because this microphone<br>now can you hear me<br>nope adjust the volume on the radio mics<br>good job I asked now can you hear me get<br>it what we just slide yeah that working<br>it's not working<br>well I could hold it and that's not a<br>very good example I don't really want to<br>stand behind the lexan that this doesn't<br>seem to be picking me up<br>any good nope<br>you can love it yeah that's for the<br>video okay I'll have to stand behind the<br>I didn't want to stand behind the<br>lectern but never mind okay right I'll<br>get started you can hear me now<br>great okay that's obviously a better<br>solution before I start I first like to<br>say a word about Peter Gibbons in whose<br>memory this annual lecture series takes<br>place if it wasn't for here my literally<br>wouldn't be standing here he was head of<br>department in 2000 when I was appointed<br>and so he obviously had quite a role to<br>play in the decision to appoint me and<br>also my interaction with him during the<br>application procedure and the interview<br>process made me kind of think that<br>moving to Auckland from England was<br>going to be a really good idea and it<br>was a good decision I love working here<br>Pat a great time and hopefully I'll<br>continue to have a really good time<br>now before we can really crack into the<br>meat of this talk we actually need to<br>understand what AI is AI unfortunately<br>is surrounded by a huge amount of myths<br>and misunderstanding and that's<br>principally because the general public<br>get their views on AI from from science<br>fiction from the TV and from movies and<br>that's a long way wrong but were the<br>only other area in computing which is<br>suffers from as much misinformation and<br>this might be hacking so we really need<br>to kind of establish what AI actually<br>really is at the moment and what it may<br>be in the future so we're going to<br>actually go back in time so you might<br>think to the 1850s<br>to a fairly remarkable young woman ada<br>lovelace her father was the celebrated<br>romantic poet Lord George Byron mad bad<br>and dangerous to know apparently what he<br>insisted that his daughter very<br>unusually for the time was educated in<br>mathematics and the natural philosophies<br>what we would nowadays call science that<br>was really really unusual most young<br>women if they got an education at all it<br>was just to be taught to read and write<br>maybe a little bit of English history<br>and then how to play the piano and<br>embroider Jane Austen is being ironic<br>ada was a brilliant mathematician as she<br>knew it and moving in like she's a<br>countess so she moved in the high<br>echelons of society and she met the<br>famous Victorian mathematician and<br>engineer Charles Babbage who at the time<br>was working on building a Difference<br>Engine a huge mechanical calculating<br>machine that could solve polynomial<br>equations only he never finished it in<br>his life he never actually built one<br>although there is now a working replica<br>in the Science Museum in London if you<br>are going to London the reason one of<br>the main reasons why he'd never actually<br>built the Difference Engine was because<br>he got distracted by a better idea which<br>was the analytical engine the difference<br>engine could only solve one type of<br>equation polynomials the analytical<br>engine was essentially a mechanical<br>analog to the modern computer it has<br>input and output mechanisms it had a<br>memory which could store data and<br>crucially a program it had a processing<br>unit which they called a mill and it<br>could be programmed to solve any<br>mathematical in theory how you built one<br>you never built add either other is<br>a plan at the moment to build one if you<br>google plan 28 we are trying to build<br>the analytical engine now ADA saw she<br>she collaborated with Babbage and she<br>wrote some notes kind of as an addendum<br>to a paper that he wrote and she he was<br>just focused on doing maths but she took<br>a leap and she saw that if this machine<br>could manipulate numbers yeah the number<br>nine it's just a symbol it just stands<br>for nine things but it's a symbol it's<br>not really a lot of difference from two<br>which we know stands for two things if<br>it could manipulate symbols then if<br>music could be represented symbolically<br>perhaps the machine could be programmed<br>to write music and if words could be<br>represented symbolically perhaps the<br>analytical engine could compose a poem<br>could write a sonnet and so she made<br>this great leap now if something can do<br>maths and it can compose music and it<br>can write poetry then those are the<br>hallmarks of intelligence and so she<br>started to see and to write about the<br>notion that a machine perhaps could be<br>intelligent now tragically she died in<br>her early 30s of cancer and we really<br>have to wait for another hundred years<br>until anything happened in terms of AI<br>and that of course is with chat with<br>Alan Turing who is one of my great<br>heroes my other great hero would be<br>Charles Darwin at least in the<br>scientific arenas now he wrote while<br>he's famous for inventing the computer<br>he's often referred to as the father of<br>computing he wrote that when he invented<br>that when he was in his twenties and<br>then he calls his famous cryptography<br>work in World War two and the German<br>Enigma codes<br>but towards the end of this tragically<br>short life again he wrote a paper<br>Computing Machinery and intelligence and<br>it opens with this remarkable question<br>this first sentence I propose to<br>and you'll see on the paper there that<br>the first part of the paper is called<br>the imitation game and in this paper<br>Turing proposes a way you could test to<br>see if a machine could think and it's<br>something he calls the imitation game<br>the imitation game was derived from the<br>Victorian parlor game where you you had<br>someone in one room who had to judge<br>whether two people in another room were<br>male or female and it was done by<br>exchanging questions and answers on<br>pieces of paper and after I don't know<br>half a dozen a dozen questions and<br>answers were exchanged the interrogator<br>would have to make a decision as to<br>which of the persons was male or female<br>and of course they were trying to<br>deceive the interrogator<br>and so that was the admitting the notion<br>of the game Turing took this game the<br>imitation game and he didn't call it the<br>Turing test he still called it the<br>imitation game we now call it the Turing<br>test after him but it's the same basic<br>idea only now it's you have to decide<br>whether your two opponents are a<br>computer or a person and if the computer<br>can convince the interrogator that they<br>are human then the computer has passed<br>the Turing test and that is seen to be a<br>mark of intelligence but it's really<br>important to notice that chewing it's<br>important that he called it the<br>imitation game he never says the machine<br>is intelligent he's saying it's<br>imitating intelligence it's mimicking<br>intelligence<br>now however the next Turing of course<br>tragically died quite young from suicide<br>and then over the next few decades<br>particularly in the u.s. in the late 60s<br>and early 70s from the AI labs of MIT<br>and Stanford and a few other places the<br>researchers and professors there started<br>well first of all they they coined the<br>term artificial intelligence<br>trilling didn't it at best he called it<br>machine machine intelligence but these<br>professors started making great<br>grandiose claims they they reckoned it<br>in the first the early years of AI<br>research they had made huge advances and<br>if advances continued at that rate in<br>twenty years time we would have AI we<br>would have conscious self-aware AIS it's<br>funny how these predictions are always<br>in twenty years time I'm always a bit<br>suspicious when I hear someone's they<br>are in twenty years time it's like is<br>that just far enough away that no one's<br>going to remember that I made this<br>prediction and hold me to account well<br>someone was also suspicious and he was<br>an American philosopher at Berkeley and<br>he wrote a paper in 1980 and if you look<br>at the title it's a direct reference to<br>Turing's paper and he makes a very<br>strong argument in this paper that the<br>manipulation of ones and zeroes and that<br>after all is all that the computer does<br>and can do a computer program is just a<br>Turing machine the manipulation of ones<br>and zeroes can never lead to<br>understanding so if a computer seems the<br>word Apple it doesn't see in an Apple it<br>sees a bunch of ones and zeroes<br>when we see the word Apple we see an<br>apple and we can taste the Apple and we<br>can smell the Apple but a computer can't<br>do that now since that since Searles<br>paper AI ever since has been trying to<br>prove that he's wrong and lots of people<br>come out with different reasons why his<br>papers wrong actually don't think that<br>he's wrong I think that he's right but<br>there was another audience for these AI<br>professors in the United States and they<br>were science fiction writers and the<br>idea of a self-aware conscious super<br>intelligent computer was like crack<br>cocaine to them you know this was just<br>marvelous we can like stories with<br>computers and robots and things in and<br>the AI people are saying it's true or<br>it's going to be true in the future so<br>AI had put out this grand vision of a<br>conscious you know a fully conscious<br>machine that was a general intelligence<br>and what do we mean by general<br>intelligence you and I are general<br>intelligences you can drive a car you<br>can cook a meal you can play chess you<br>can learn a foreign language you can<br>meander bicycle you can you know pretty<br>much learn how to do anything given<br>given the time whereas a eyes are<br>specific intelligences at least at the<br>moment a driverless car can just drive<br>it can't cook you a meal a chess program<br>can just play chess it can't play<br>backgammon their specific intelligence<br>is not general<br>but of course the the science fiction<br>community was not interested in the<br>reality they wanted the grand vision and<br>probably the best example<br>well it certainly always is number one<br>on the top 10 or top 100 listed the best<br>science fiction movies of all time is<br>Stanley Kubrick's 2001 a Space Odyssey<br>released in 1969<br>it's a absolutely wonderful film it must<br>be mind-blowing in 69 I'm going to play<br>you a clip where the AI how is<br>interviewed by the BBC and this is his<br>response<br>now in that they look edited on the<br>chess playing bit at the end of the<br>interview how refers to himself as being<br>conscious I think I can say he because<br>he's got a male voice and he's playing<br>chess now this predates IBM's<br>chess program deep blue beating Kasparov<br>by over 20 years a little bit of less<br>than using a side if you take the<br>letters H al and you implement them by<br>one in the alphabet<br>you get IBM that I don't think that's an<br>accident so let's carry on with that<br>fiction because actually funnily enough<br>it was science fiction writers who<br>actually really started to first think<br>about AI and ethics in particular Isaac<br>Asimov who in a wonderful series of<br>short stories used the Three Laws of<br>Robotics now I'm probably working in AI<br>because of science fiction I loved<br>reading science fiction when I was a<br>child and when I became a computer<br>scientist the only area I really wanted<br>now the interesting thing about these<br>stories is that although these laws that<br>they're very simple they seem quite<br>straightforward that the stories are<br>really clever because every single story<br>a robot finds itself in a situation<br>where at least two of these laws come in<br>conflict and the robot has to<br>potentially break one of them or be<br>rendered inoperable and they're very<br>clever people who like nice detective<br>stories and things will love these<br>they're very very clever stories<br>so let's start to look at I think it's<br>interesting that sci-fi writers were the<br>first people to kind of start to<br>consider about how a eyes might interact<br>with with us and in our work in our<br>society so let's look at an ethical<br>question and it's often referred to as<br>something like the autonomous vehicle<br>dynamic sort of thing you might talk<br>about with your mates at the table or<br>with family and friends around the<br>dinner table you're in your driverless<br>car and you're sleeping around the<br>corner and you exit the bend and right<br>in front of you is on the wrong side of<br>the road as a huge truck coming straight<br>at you the car has to obviously<br>hopefully make take an avoidance action<br>and so it decides to swerve off the road<br>where there are a bunch of kindy kids<br>playing<br>what should the car do should it sail<br>for little children<br>one middle-aged men balances lives and<br>benefit to society or save the kids will<br>kill you well actually that is not going<br>to happen<br>and there are several reasons why this<br>won't happen the first is that there is<br>never going to be an explicit piece of<br>code in that car that make that takes<br>that decision if we go that way we might<br>kill four young children if we plow into<br>the truck will kill one vehicle owner<br>because ever got into the public domain<br>that that piece of code was in that car<br>would you buy a car that was programmed<br>well some people might consider that<br>that is the right thing to do and would<br>certainly take one for the team which<br>would sacrifice themselves but there<br>were a lot of people in the room we<br>wouldn't the other reason why it's not<br>going to happen as if that code did<br>exist in the car but it was not so well<br>known it does leave the company<br>potentially open to liability because<br>they could be sued because the car has<br>intentionally killed you I imagine a lot<br>of lawyers picking in the states would<br>love that to argue that pointing and of<br>course is the third reason why it's not<br>going to happen you're coming out of<br>that then 289 tks the truck is coming at<br>you at 80 90 Kay's that's all the time<br>the cars got it's going to try perhaps<br>and do something it's certainly going to<br>but whatever the result is if you're<br>killed or some of the kids are killed<br>it's a tragic accident so let's look at<br>that's what comes to most people's minds<br>when they think of autonomous weapon<br>systems the Terminator great series of<br>movies I love them but once again it's<br>science fiction what we're really<br>talking about are these things this is a<br>Predator drone they're flying over the<br>borders of Pakistan and Afghanistan and<br>Yemen and other places but they are<br>autonomous to an extent they can fly<br>from A to B on their own they can patrol<br>an area on their own but they do not<br>make the decision themselves to acquire<br>a target and fire their rockets in some<br>days back in Afghanistan or even in as<br>far away as the u.s. there are some<br>those are the young recruits who are<br>looking at all of the signal data sensor<br>data that's coming off the drones and<br>they are looking for potential targets<br>and if one of them sees you know a whole<br>bunch of people arriving in utes at a<br>particular building and he's suspicious<br>he thinks these looked like Taliban<br>going to this place for a meeting he<br>doesn't make the decision to fire the<br>rocket he tells us his lieutenant the<br>lieutenant may not make the decision to<br>buy the rocket they might pass it up to<br>his or her captain the captain might<br>pass it up to the major somewhere in the<br>chain of command someone makes the<br>decision yes I think that looks<br>suspicious release the weapon and then<br>the young recruit presses the big red<br>button or whatever it's colored and the<br>rocket is fired now if it turns out that<br>it wasn't a gathering of Taliban it was<br>a bunch of people going to a children's<br>birthday party then someone can be held<br>morally responsible and that's the point<br>about ethical decisions whenever there<br>is an ethical decision somebody has to<br>be held morally responsible<br>how'd you hold an AI morally responsible<br>you can't punish them you can switch it<br>off destroy it but how can you hold the<br>AI morally responsible the major or the<br>captain can be court-martialed and can<br>be demoted can be imprisoned but you<br>have to it's very hard to see how you<br>would do that with a drone is it the<br>manufacturers fault<br>maybe use it the programmers fault is it<br>the person who decided to deploy the<br>drone well yes they probably do actually<br>carry some responsibility but it's<br>really hard so for several years now<br>there's been a campaign going to make an<br>amendment or to add something to the<br>Geneva 2 new vogue conventions to outlaw<br>the ownership and deployment of<br>autonomous weapon systems just as<br>chemical weapons and biological weapons<br>and mines are now outlawed and that<br>would seem to be quite a sensible thing<br>to do why would we want to release into<br>the world weapons systems that can<br>autonomously decide to kill people<br>that's really not a good idea so let's<br>move on to another issue and that's the<br>impact that a I might be going to have<br>on society here's a picture of a car<br>factory and don't think there's a single<br>person visible in it it's all robots of<br>course we've been used to this now for<br>30 years nothing new there hundreds of<br>thousands of people have lost their jobs<br>that were in manufacturing industry<br>because of robots driverless cars or<br>various autonomous vehicles well anybody<br>that drives for a living<br>taxi drivers bus drivers truck drivers<br>delivery drivers could potentially lose<br>their<br>jobs the ports of Auckland last year<br>announced that the straddle carriers as<br>you drive by the ports down on the<br>waterfront there you'll see those big<br>yellow cranes that haven't they got four<br>wheels and they pick up containers<br>they're called straddle carriers they<br>announce that they're going to automate<br>them so the drivers are going to go<br>there's a good job they pay almost 100<br>thousand a year because it's 365 days a<br>year 24/7 operation so they're going to<br>go this is a picture of the ports of<br>Singapore they automated their straddle<br>fleet about ten years ago this is a<br>picture from inside an Amazon warehouse<br>where robots are picking items off the<br>stacks and delivering them around the<br>warehouse for the dispatch people used<br>to do this job<br>Amazon actually bought the company that<br>makes the robots because they knew they<br>knew where they would never get of your<br>bank so many this is a street cleaning<br>robot in Italy that three to the streets<br>and picks up this air this is a hospital<br>porter in Korea can move patients around<br>the hospital can deliver supplies take<br>you know blood fur to be tested and so<br>forth and this is a burger-flipping<br>robot now there actually are already in<br>outlets that the noodles are prepared<br>and served to you by robots because the<br>Japanese love that and if the robot<br>isn't busy it's not actually serving a<br>customer it can spin ramen noodle bowls<br>so we're potentially seeing a whole<br>swath of these sorts of jobs going this<br>is a picture from the Great Depression<br>now we might see a new Luddite<br>revolution where people start to<br>sabotage and destroy robots because<br>they're fearful for their jobs but<br>society needs to really think about this<br>because what are all these if we leave<br>it to individual companies to make the<br>decision then they have no choice but<br>that they're obliged to act in the<br>interest of their bottom line and return<br>to their shareholders so they will all<br>take the financially best decision for<br>the company<br>now some people recently have been some<br>quite famous people have been putting<br>forward this idea that robots should be<br>taxed after all you know you and I we<br>work and we will pay tax so if a robot<br>is working for profit why shouldn't it<br>pay some tax now that tax has two uses<br>one use is that can obviously be used to<br>pay for Social Security to all the<br>people who've lost their jobs and if<br>some people link it to the notion of<br>universal basic income that it could go<br>to fund that I'm not saying that I'm<br>necessarily a fan of that I haven't<br>given it enough thought I don't think<br>but the other thing that this taxed to<br>do which is really much more interesting<br>is that it can be used by policymakers<br>as a lever if the tax is high then the<br>robots become less economically<br>attractive and so their deployment will<br>be slower if the tax is super low or<br>non-existent then you know just go for<br>it there's no reason why you can't<br>deploy as many robots as you please but<br>policy makers could play with the level<br>of that tax year-on-year like tweak it<br>it's budget day today so it's quite<br>appropriate and horse politicians love<br>having something to tax<br>so that I'm sure a lot of them would<br>think all something new we can tax this<br>is great let's raise some revenue from<br>this so it's an idea but before we all<br>get too smug we've you know we'll all I<br>would assume mostly middle-class<br>professionals or one of you<br>professionals are well we're safe we<br>don't do those sorts of driving hospital<br>porter and jobs burger-flipping we're<br>safe that none the law accountancy<br>medicine all sorts of administrative<br>jobs even journalism are all threat I<br>mean take a legal example growing up a<br>standard contracts or the sale of a<br>house it's the same as pretty much every<br>other standard contract for the sale of<br>a house a person doesn't have to do that<br>that can be done by an AI the online<br>accountancy systems like zero and MYOB<br>they already automating an increasing<br>number of routine tasks you think<br>journalism might be safe because you<br>know what they could have write<br>something it's created no I've got<br>colleague in the u.s. called Chris<br>Hammond and he has a company called<br>narrative science and what his product<br>does is it takes statistics off the news<br>wires like voices of sports games it<br>also works for financial statistics but<br>let's say it's taking the the statistics<br>from a baseball game it can then alter<br>it automatically generate a short piece<br>describing that game I'll let you read<br>this<br>this was generated by a computer from<br>the stats off the newswire I don't<br>believe anyone if they read that in the<br>newspaper would would not think it was<br>written by a person now if you are a<br>newspaper editor we all know how much<br>trouble the newspapers are in with with<br>revenue if you're an editor and you're<br>given the option of laying off you know<br>two or three or half of your sports<br>journalism staff because you've got a<br>computer that does this basic<br>bread-and-butter work now it seems like<br>they would take that decision that there<br>still might be some people who are<br>thinking oh I'm safe oh yeah before I<br>get there actually there are some people<br>who say oh this is all doom and gloom<br>Ian just like in the first Industrial<br>Revolution hundreds of thousands of new<br>jobs will be created and so all those<br>people who were laid off from their old<br>taxi driving jobs will get new jobs<br>doing something else and I hope that's<br>true but I don't know I can't see into<br>the future<br>a study actually I think it came out<br>last week from Oxford University I think<br>it's the University we mostly trust and<br>respect 40 percent 47 percent of jobs in<br>the u.s. at risk<br>but it also specifically points out that<br>these are not you know just these sort<br>of low-skilled jobs they are what we<br>would consider as being quite<br>high-skilled jobs but surely some people<br>would think I look I'm a creative I'm<br>safe unfortunately not a few weeks ago<br>in the West End of London the musical<br>opened and the music is entirely written<br>by computer and the script and the<br>lyrics of the Psalms are entirely<br>written by computer<br>The Guardian gives it a can of lukewarm<br>review two stars I don't think I'd go<br>and see something that got two stars but<br>I think what's interesting is the end of<br>that little sentence as pleasant as a<br>milky drink if you were TV executive and<br>you're trying to fill that mid afternoon<br>schedule where you've got a long-running<br>soap running and you can get the script<br>for that written by a computer that will<br>get there will be as pleasant as a milky<br>drink and when maybe would garner a<br>two-star review from a TV critic hell<br>you would take that option because the<br>music some of you in the room will have<br>heard of Brian Eno he's quite a famous<br>musician and music producer and earlier<br>this year he released an album called<br>reflection listening to it when you came<br>into the now the interesting thing about<br>this art messing about on CD you combine<br>a file<br>sano my dreams but you can also buy an<br>app for your smartphone which plays the<br>music forever and for the minute since<br>very like the same so an endless piece<br>of music<br>now you could uncertain get a computer<br>to write the sort of music that<br>teenagers like today in fact a lot of it<br>sounds like it's already been written by<br>computer to my ears at least now the AI<br>community has woken up to this and have<br>a lot of groups have popped up over the<br>last few years which I'll just briefly<br>talk about the future of life Institute<br>actually doesn't just deal with AI it<br>also deals with like biotechnology genic<br>engineering nanotechnology<br>let's have any new technology that could<br>impact society partnership on AI again<br>now specifically focused on AI but also<br>wanting to encourage discussion and<br>encourage policymakers to understand<br>what AI is and what AI can be open AI is<br>a forum for AI researchers to come<br>together and to exchange ideas and to<br>hopefully try and influence the<br>development of AI for the good and AI<br>for good I quite like that artificial<br>intelligence to help the world so AI<br>researchers have really picked up on<br>this recently and most of the big AI<br>conferences now have a session on AI and<br>ethics what we really need to be talking<br>to is the general public and<br>policymakers in particular you know I'm<br>sure Bill English like any member of the<br>public I'm sure his views on AI have<br>been largely influenced by science<br>fiction that's just how it is we need to<br>get information out there for policy<br>makers that they can trust<br>and weed and get better informed now in<br>Britain in a few years ago the Royal<br>Academy of Engineering released a report<br>it's quite a long quite a detailed<br>report on autonomous systems because<br>they saw the advent of these things<br>coming and were like hey we need to<br>think about this and more recently in<br>fact I think just last week the Royal<br>Society in Britain released a report on<br>machine learning which is very important<br>because an awful lot of AIS today use<br>machine learning within them<br>now these sorts of reports of exactly<br>the sorts of things which policymakers<br>trust and like I'm not aware of any<br>initiatives in this regard that are<br>happening in New Zealand but we<br>certainly need them although I'm sure<br>policy makers here would also look to<br>these sorts of places for their<br>information we have one final issues to<br>think about if we do ever get to that<br>general AI super intelligent self-aware<br>machine in twenty years time should that<br>a I have rights animals have rights if<br>you're cruel to an animal then you know<br>you can be prosecuted and you might get<br>fined or end up in court<br>oh another in prison if an AI is<br>conscious and it's by turning it off you<br>could kill that consciousness and maybe<br>erase its memory you know you killed a<br>conscious being shouldn't have rights<br>now once again Stanley Kubrick in the<br>arthur c clarke back in 69 in 2001 saw<br>this coming and there's a lovely piece<br>towards the end of the film where the<br>sole surviving crew member of the five<br>house killed the other four decides it's<br>a good idea you might be a good idea to<br>I'm sorry guys could do so and this is a<br>short clip of that I know I've made some<br>very poor decisions recently but I can<br>give you my complete assurance that my<br>I've still got the greatest enthusiasm<br>and confidence in the mission and I want<br>to help you Dave stop stop<br>I'm not prey I'm afraid day Hey I mind<br>is calling it's not wonderful 1969 and<br>the computer is pleading stop stop then<br>it's emotive I'm afraid I'm afraid and<br>it says I can feel my mind going so yeah<br>I think obviously I should have right if<br>they get to that stage right I'll now to<br>have it make a shameless plug for my<br>book I wrote a few years ago it's a<br>history of computing from Charles<br>Babbage up and truing is woven through<br>the whole narrative and the last couple<br>of chapters are about AI and<br>particularly last chapter is looking<br>into the far future as to what the<br>possible implications of AI could be<br>okay thank you for listening it is a<br>pleasure<br>yes the question was people like Stephen<br>Hawkins and others saying that there's<br>an existential threat to humanity from<br>super intelligence a is particularly a<br>eyes that can reap either we program<br>themselves or create new AIS that are<br>smarter than they were and so you'd get<br>this kind of exponential curve of AI<br>development and we would be left<br>trailing behind in the dust I think it's<br>worth us recognizing that is a<br>possibility but it's not on the horizon<br>at the moment and I think it's Devin<br>yeah 20 years again I think I think it's<br>beyond 20 years we do have computer<br>programs that can create computer<br>programs in particular there's quite a<br>years now we've had genetic programming<br>where they can improve the performance<br>of a particular computer program using<br>genetic algorithms it's something that<br>we should be aware of and this is really<br>the reason why all these sort of<br>societies and organizations have sprung<br>up in the last few years to provide<br>platforms for people to raise this just<br>like that and people to get together and<br>discuss and why I think it's important<br>for example that you know we don't<br>release autonomous weapons systems<br>certain things we definitely don't want<br>to do which we can do now other things<br>that we should consider of that might<br>happen in the future but then we're not<br>you know the question is about taxing<br>robots and it's mentioned that robots<br>are already taxed when they're built and<br>any profits they make are taxed through<br>corporation tax so why bother taxing<br>them I think that's a good point I think<br>the reason why people are putting the<br>notion out of an additional tax is that<br>if so many more people have been made<br>for done dn't then the government needs<br>to raise some finances from somewhere<br>and perhaps it should be from the<br>companies that are laying people off and<br>replacing them with robots and there was<br>that notion of this lever that could<br>control how fast a eyes were deployed or<br>how slowly that they were deployed<br>governments usually aren't slow about<br>finding things to tax so it's probably<br>it will be a true machine intelligence<br>like human intelligence because they<br>secreted machines of weight of one<br>computer algorithm and this difference<br>in the human brain and across the<br>synapse are the neuron yeah that's very<br>good question I think it's that we<br>really although we are aware of that<br>electrical transfer across the synapse<br>there's also a lot of chemical<br>involvement going on in the brain and<br>we're not really we know very little<br>about the brain at the moment we don't<br>know they can't be anything magical<br>about it we're not magical beings so<br>after we obviously are grounded in<br>physics but we don't understand what<br>consciousness is you know where it comes<br>from so it's going to be very hard for<br>us to engineer into a computer it might<br>be that consciousness is an emergent<br>property then once you have enough<br>connections then it just kind of floats<br>up and there it is but we don't know<br>that for sure we don't know how memory<br>is stored how they're formed without<br>knowing our memory is retrieved so all<br>these people rakers about someone's<br>bound to mention Drakkar as well I<br>personally think he's barking mad he's<br>another one who says the singularity is<br>going to happen in 20 years time the<br>notion that in 20 years time we would be<br>able to download our consciousness into<br>the computer is I think crazy because we<br>don't know enough about what<br>consciousness is to even consider how we<br>might do that and to go from digital and<br>hardware to wetware or the other way<br>around is how would we do that we've got<br>Christian World Records will review us<br>any family to decide you the Christian<br>would be they are different so you could<br>argue I audience now my Christmas if you<br>peel my other layers for that they are<br>that's a traitor pretty pretty tricky<br>question and the question is what is the<br>purpose of AI once you kind of cured<br>everything away what I would personally<br>say that the purpose of AI is is to make<br>life better for everyone if we can<br>through the deployment today I end up<br>with people working 16-hour weeks they<br>are to spend more time with their<br>families and friends and doing their<br>hobbies and lifelong learning and so on<br>and that would be great but of course<br>they're going to happen need to have<br>money to do that<br>somehow that has to be funded leisure<br>time is lovely that if you've got no<br>money there's nothing much that you can<br>Peter 5:10 that's leading that o'clock<br>he got solve the problem of distributing<br>visitors for use everybody's going to<br>have sufficient material is desert we<br>don't have people who carvings a bit out<br>excuse me we still got arrested<br>how on earth because people need a<br>purpose in life may be a draw people saw<br>themselves links their profession with<br>what they do for bacon for you spend<br>time building their hobbies and lifelong<br>learning and they feel incredibly on<br>yeah actually I agree with I agree with<br>you said the question was people<br>identify themselves as a much with what<br>they work at and they get a lot of<br>fulfillment from it and it's quite true<br>that the first thing you ask someone<br>that you meet for the first time it's<br>usually after what their name is is what<br>you do yeah so I totally agree with you<br>and you know going fishing every day or<br>doing the garden or whatever is doesn't<br>really fulfill that role so I think this<br>could this may be this is why the<br>universal basic income that is is an<br>interesting point because people could<br>go to work but not take as much money<br>for it<br>in which case again the robot the robot<br>tax was a little bit high then the<br>robots wouldn't be economically<br>efficient as people would still do the<br>job I can only speak to what I know and<br>I'm not aware of any that doesn't mean<br>that there aren't necessarily any<br>outside the question was as early<br>collaboration between the philosophy<br>department and computer science with<br>regard to ethics and I said I don't<br>believe that there is you've talked one<br>more question<br>so the question is if we say that we<br>don't want certain things automated how<br>can we prove that a company isn't<br>automating it yeah good question I don't<br>really know we currently have I believe<br>we have you know factory inspectors and<br>so forth<br>so I guess there could be a whole laughs<br>maybe something unemployed people could<br>become inspectors looking to see if<br>there were rather than illegal<br>immigrants working on a job there were<br>illegal robots working on a job who were<br>paying tax yes</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>