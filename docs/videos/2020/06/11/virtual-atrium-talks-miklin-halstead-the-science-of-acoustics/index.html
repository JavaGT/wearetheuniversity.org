<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>We Are The University</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="color: #fff;font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/videos">Videos</a></li><li><a href="/authors">Authors</a></li></ul></nav></header><main><h2 style="text-align: center;">Virtual Atrium Talks: Miklin Halstead—The science of acoustics [27:55]</h2><p style="text-align: center;"><a href="https://www.youtube.com/watch?v=j8StUhG7oYM" target="_blank">Watch on Youtube</a></p><p style="text-align: center;"><a href="https://www.youtube.com/channel/UCBWjJVwRap6ocot6rs1Gg-g" target="_blank">Te Herenga Waka—Victoria University of Wellington</a></p><img src="https://i.ytimg.com/vi/j8StUhG7oYM/maxresdefault.jpg" alt="Thumbnail for video titled: Virtual Atrium Talks: Miklin Halstead—The science of acoustics" style="width: 100%;"><div class="tags"><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Victoria University of Wellington</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#VUW</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Vic Uni</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Victoria University</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Miklin Halstead</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Acoustic science</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Wellington School of Architecture</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Wellington Faculty of Architecture and Design Innovation</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#VR</span><span style="background: #0003; border-radius: 0.3em; padding: 0.3em; display: inline-block; margin: 0.2em; font-size: 0.8em">#Virtual Reality</span></div><h2>Description</h2><p>The science of acoustics is relatively mature – we can predict the loudness of a ventilation system or the sound attenuation of a building element or the reverberant response of a space, with very good accuracy. However, our ability to communicate these qualities has largely been limited to text and numbers and “trust us, this is worth it”. The ability to demonstrate what a fan, or a wall or a space would sound like is seemingly simple, but in practice is confounded by many factors.<br><br>Marshall Day Acoustics have built a listening space which incorporates VR hardware to coordinate visual presentation with high-quality spatial sound reproduction. Our early efforts indicate that this system overcomes many of the hurdles of acceptance by listeners, and has proven useful in the design process.<br><br>Miklin Halstead from Marshall Day Acoustics Wellington presents their work to date, discuss the ongoing challenges of VR acoustic presentation, as well as discussing some of the other research and development areas Marshall Day Acoustics is presently undertaking.<br><br>The Wellington Faculty of Architecture and Design Innovation’s Virtual Atrium Talks are a series of seminars where staff, PhD students, and external design and built environment practitioners present their current research and seek feedback from the community.</p><h2>Transcript</h2><p style="opacity: 0.9; font-size: 0.8em">Transcripts may be automatically generated and may not be 100% accurate.</p><p>and that actually does have an acoustic<br>um parallel in looking at how good the<br>the direct sound propagation is so it's<br>a<br>it's a semi-acoustic tool and we're also<br>using<br>uh grasshopper to sort of look at stage<br>acoustics and how reflectors can help<br>performers hear each other uh there's a<br>there's a project that i'm really keen<br>on<br>talking about sometime in the future<br>which is um<br>the acoustic requirements of tireo and i<br>think we we got a uh proposal a while<br>back asking<br>um to demonstrate our commitment to<br>the the multicultural aspects of new<br>zealand<br>um do we have respect for the treaty and<br>and uh understanding of taiwan and<br>fennel<br>and we sort of thought well yeah we can<br>tick all the boxes and say we do all<br>that sort of thing but the truth is<br>there hasn't been a lot of research into<br>the requirements<br>for te reo in new zealand and that's a<br>bit of a silly thing to have<br>gone missing so one of the things we're<br>starting to delve into and we're<br>interested in some<br>some folks registration of interest is<br>is finding out<br>first linguistically what's required to<br>say that we're communicating<br>te reo efficiently and secondly what are<br>the cultural expectations of<br>architecture<br>um in terms of supporting speech or<br>music<br>um and and you know what's historically<br>how<br>buildings contributed to sound and going<br>forward what<br>as designers should we be doing uh<br>as designers in new zealand to build<br>buildings for that purpose<br>we've also got a few things that i'm<br>personally interested in room mode<br>mapping so looking at how<br>if you took a virtual reality system<br>into a room<br>and waved your microphone around<br>attached to the end of a virtual reality<br>pointer<br>could you actually map the the sound<br>pressure level of a standing wave in a<br>room<br>and be able to see it in virtual reality<br>uh tool for figuring out where to put<br>absorption and<br>where to where to uh to treat a room or<br>how to orient not that speakers<br>and finally the thing we're going to<br>talk about today which is our listening<br>room<br>so the listening room project came out<br>of this problem we have of how to<br>communicate<br>acoustics so folks in architecture and<br>folks in<br>areas have sort of cracked this they can<br>take photographs they can do renderings<br>there's been a fair amount of work in<br>how to present a photograph of<br>a landscape properly to give the right<br>visual<br>impression but that's something that is<br>lagging in acoustics<br>our our current method of communicating<br>to our clients<br>is by saying well here's here's the<br>table that says how much insulation is<br>good or how much reverberation is bad<br>um here's some guidelines about how you<br>build a building and if you if you trust<br>us<br>build it like we say then your result<br>will be good and if you spend a bit more<br>money your result will be excellent and<br>if you don't spend any of that money<br>your result will be poor so<br>so we can say those words and point to<br>those guidelines<br>but it is sort of a trust us we know<br>what we're talking about situation<br>so we'd like to move beyond that and get<br>to where we can play some sounds for our<br>client and<br>say well if you spend twice as much on<br>your glazing or your your<br>absorption um this is how much acoustic<br>benefit you'll get and be able to listen<br>to a<br>case a in case b and compare the costs<br>and benefits<br>so how do you do that well one way is<br>you can take them someplace where it's<br>successfully been implemented and say if<br>you if you go into this concert hall<br>this is a hall that has a reverberation<br>time of 1.8 seconds and has a clarity of<br>plus four decibels and you can sit<br>somebody down and have them<br>have the experience so that's that's a<br>nice way to do it but it doesn't<br>lend itself to a quick comparison of a<br>versus b<br>so you can you can do some simple<br>oralizations you can play a recording<br>you can play<br>recording a versus recording b and ask<br>people what do you think is that worth<br>another thirty thousand dollars<br>and we've done that quite a bit we've<br>brought in um recordings of noise levels<br>say of a wind turbine<br>operating in the community and we said<br>if we increase that by three decibels<br>this is what it sounds like or if we<br>make it 40 decibels<br>in absolute sense this is what it sounds<br>like um<br>that's i'll talk about why but that runs<br>into quite a few<br>problems in in our experience doesn't<br>really allow people to make good<br>decisions<br>so you can you can you can do better<br>than<br>those simple simulations and the sorts<br>of things that you need to think about<br>when you're presenting an oral<br>simulation there's some basic physical<br>limitations how quiet is the space that<br>you're<br>presenting that in because if if you've<br>got more noise coming from your air<br>conditioning system in the room<br>then the air conditioning system you're<br>trying to compare in your simulation you<br>simply won't be able to hear<br>the simulation because it'll be swamped<br>by the same token if you're trying to<br>compare the reverberance<br>of two treatments say i was<br>demonstrating uh demonstrating a<br>recording studio control room<br>and wanted to make a case for a 0.2<br>second reverb time instead of a 0.5<br>second reverb time which might cost<br>three times as much to implement but if<br>i play that in the client's office<br>it's probably about a 0.7 second reverb<br>time there's no way to really<br>hear that sort of thing properly put on<br>headphones but that's got its own set of<br>problems which we'll kind of<br>dive into in a moment and then there's<br>the more airy fairy fluffy stuff<br>about context so what we found is<br>even if you can accurately play back say<br>a level of 40 decibels<br>for a wind farm say what we found is<br>that 40 decibels sounds really different<br>if you're sitting in an indoor<br>environment that it does if you're<br>sitting in an<br>outdoor environment even if the ambient<br>sound level is the same<br>the expectations of people is is very<br>different and the way that they perceive<br>those sound levels is different based on<br>their their subjective expectations<br>by the same token the amount of activity<br>going on or whether they see the wind<br>blowing the leaves or whether people are<br>walking past the corridor<br>um all those sorts of things have a a<br>low level subjective<br>impact on the way that people perceive<br>noise levels and noise character<br>and and so this all kind of lends to<br>this question of is it possible<br>to have suspension of disbelief while<br>somebody's listening to a simulation<br>is it is it possible that they sit in<br>there and they're listening<br>in a purely subjective way rather than<br>trying to say well i can hear the<br>objective difference<br>um is that is that a a difference that i<br>can<br>qualify and and where the<br>where we get into this virtual reality<br>stuff putting<br>a headset on people which talk about the<br>moment is all about that suspension of<br>disbelief<br>now my my own opinion about vr<br>before we started doing this was it's a<br>nice little toy<br>um love to have one but probably a bit<br>of a waste of money<br>we can do all these simulations without<br>all that stuff the first time i sat down<br>and listened i was<br>absolutely stunned with how quickly i<br>started listening to the important stuff<br>that i was being asked to listen to<br>so a lot of this is is about you know<br>the technical bits of getting the<br>noise and the reference right but a lot<br>of it is about simply getting<br>the person's brain into the right<br>position to make some decisions<br>so this is this is the auckland martial<br>days listening room we've<br>we've just built our room but don't have<br>gear in it yet but this is roughly the<br>sort of thing that i'm talking about so<br>it's a<br>a single seated position you don't get<br>to walk around but you're<br>you're seated in the middle of the room<br>surrounded by an array of loudspeakers<br>and you've got some controls in front of<br>you that can move you from seat to seat<br>or change the situation you're being<br>presented<br>you've got the usual vr headset and<br>your ears are open so you're listening<br>to a sound field that's being presented<br>by<br>these loudspeakers if you move your head<br>of course the sound field is actually<br>recreated so you<br>the the acoustics change just because<br>you're moving ahead in the actual sound<br>field<br>but the vr has the responsibility of<br>changing<br>what you see through the goggles<br>the situation we've got in auckland is<br>12 loudspeakers we've got<br>three on the top and three on the bottom<br>in triangles and<br>six around the listeners head um that's<br>that's really chosen out of you know<br>sort of convenience and the size of the<br>sphere we had in that space and we'll<br>probably do something similar in our<br>room we have a little bit more head<br>space so we might<br>be able to put a few more loudspeakers<br>in the sphere above<br>and maybe one or two in in the in the<br>median plane<br>the kind of thing you'd see might look<br>like this this is a standard simulation<br>we've got of a<br>of a living space we've got a<br>seat that of course you'd be seeing this<br>from that green seat if you receive it<br>in the in the<br>simulation we've got a heat pump off to<br>the right we've got a stereo in front<br>we've got a door behind which might be a<br>neighbor we've got a window behind<br>which might be some buses and traffic<br>and of course the walls could also be<br>presented as noise makers<br>or we could go into this kind of thing<br>if we wanted to present concert halls so<br>this is a<br>space built up in rotorua and did a<br>bunch of simulation<br>uh before building the space<br>but the physical place we built this is<br>in our wellington office here<br>we had a uh storeroom that we<br>scanned all of our documents threw<br>everything away and made room built<br>the the double stud wall shown with the<br>pink insulation in it<br>um so it's about a four meter by three<br>meter by three meter high<br>room um we've<br>got the sound level from uh intrusive<br>ventilation sounds and traffic noise<br>down to about nc17<br>if we switch off the ventilation and for<br>another 5 db we can we can<br>provide some fresh air with the switch<br>on the wall illustrated below<br>um the the uh the picture the switch<br>also goes to show the depth of<br>the absorptive stuff we stuck in the<br>walls which is 150 mils of ortex quiet<br>space<br>and on the ceiling we've got a suspended<br>ceiling on a 300 ml cavity<br>with uh sort of black ceiling tiles that<br>you'd find in a cinema<br>the reverb time we've got down to is<br>shown by the pink line um<br>the untreated room is shown in blue so<br>about about sort of a two and a half<br>second reverb time<br>then progressively one and two and three<br>layers of treatment got us down to that<br>bottom line of about<br>0.15 seconds reverberation<br>so in terms of being able to simulate<br>things we can we can simulate quiet<br>things and we can simulate<br>fairly dead things and compare them with<br>other things<br>so um kind of run a bit short on time<br>here but we'll talk<br>quickly about the the nuts and bolts so<br>basically what we're doing is<br>we're preparing ambisonic audio and that<br>means<br>we're considering um spatial sound that<br>comes in<br>loudness and direction direction it's<br>encoded as a four channel<br>signal and then goes through a decoder<br>that we can decode into<br>our array of five cloud speakers or<br>twelve loudspeakers or in fact<br>into a pair of headphones um<br>we can go out in the field and use an<br>ambisonic tetra mic<br>and we can actually record sound that is<br>in this ambisonic format that we can<br>then pump into our system or we can do<br>convolution where we measure an impulse<br>response and then take some other<br>anechoic audio convolve it with our room<br>impulse response and<br>produce the convolution which is as if<br>that audio were played in the room<br>and in terms of the concert hall it<br>might be more uh complicated than those<br>four reflections we saw previously would<br>have lots of reflections<br>which all contribute to um the total<br>reverberated sound<br>but of course we do this in that<br>ambisonic way where we have four<br>different channels that contribute to<br>the<br>the the sound field in space<br>we can capture that response by<br>measuring with our iris tool<br>which measures using a tetra mic we can<br>go into a concert hall<br>and measure the response of a of a swept<br>sine wave coming out of loudspeaker<br>to produce that impulse response that we<br>can then convolve with music<br>so a situation might look like this<br>here's the loudspeaker in that space we<br>saw<br>put the microphone up in the seat sweep<br>design waves and you get an impulse<br>response<br>you can then use in our listening room<br>or we can use a tool like odion or<br>in the case of what you folks have you<br>have cat acoustics basically take<br>virtual sources shown as the red things<br>and determine the impulse response the<br>blue things would hear<br>um you could have multiple sources<br>coming into a single receiver this is<br>the case of an orchestra um and then we<br>put it through<br>our software now we're using a piece of<br>software called max<br>which is a essentially a visual<br>programming language for audio<br>manipulation<br>and we're using that to do the various<br>things like filter out the transmission<br>loss through walls<br>or the reverberants in the rooms and<br>take our our<br>uh sort of source situation and get it<br>to our<br>our listening space<br>run that result through a decoder to get<br>to our loudspeakers or our headphones<br>um and that decoder we're using is<br>harpix x which is um<br>in this case showing sort of a 5.1 um<br>response but it in in the case of our<br>room it's either a a 12 channel<br>result or a two-channel result if we're<br>so um you know the typical sort of thing<br>we'd do is we'd say here's here's uh<br>the difference between six mil glazing<br>and 12 ml glazing coming through that<br>window and you can<br>push your buttons in front of you<br>switches between the different<br>impulse responses that include the<br>transmission losses of glass<br>and the traffic noise changes<br>accordingly or you can you can see what<br>would happen if i had a<br>a solid core door versus a lightweight<br>door<br>so this is the kind of situation we<br>would simulate in that case you can see<br>we've got lots of sources representing<br>the different<br>parts of the wall or the window<br>representing the door<br>sources for the heat pump and sources<br>for our stereo in front of us<br>now that this i could speak for another<br>long time about how we how we're<br>thinking about our ambient<br>sound uh one of the things we've<br>discovered is that<br>when you walk into the room you take you<br>take sort of<br>take stock of the space you're sitting<br>down in and<br>the loudness of the simulation seems to<br>depend on the subjective loudness seems<br>to depend on<br>how much sound we present to the<br>listener before they even start the<br>simulation<br>so i'm talking here about stuff that<br>we're doing in the future which is<br>figuring out<br>um all these subjective things about<br>context about<br>the ambient environment and i think it's<br>possible to say<br>that we could get this wrong if we<br>didn't do that stuff right<br>people have sat down and said um that<br>sounds like a really noisy air<br>conditioning system when in fact<br>that was the quiet one we were going to<br>present you coming into our nc 17<br>environment<br>and then being presented with an nc 30<br>air conditioner<br>sounds loud even though it's the nc40 we<br>the visual stuff i'm not going to have<br>much time to talk about we can take<br>pictures with us<br>with a uh spherical camera or we can use<br>the various<br>tools to render stuff and we go into a<br>unity gaming engine<br>which gives us these sorts of views um<br>we've got communication between unity<br>and max<br>and between our controls so unity is<br>telling our<br>max how to rotate the head because it<br>can sense our rv<br>headset our audio system is telling<br>unity when the user's pressed a button<br>that is meant to change the scene that<br>they're listening to<br>and that's that's kind of i could talk<br>about the nuts and bolts for another<br>hour but<br>i'm going to leave it there just with<br>those concepts and give us some time for<br>thank you yes we have roughly 10 minutes<br>i'll open up and i'm sorry<br>ironically um given it's a<br>a talk on sound i forgot to press the<br>i have a question yes sure<br>regarding the simulation using um<br>a virtual model or taking the<br>photography the 360 to show<br>is there any difference what is the<br>difference in the process<br>of the simulation uh well with a photo<br>you you get a fairly static image and if<br>you rotate your head you can see<br>different parts of that<br>um it's it's quite a bit poorer in terms<br>of the resolution<br>um i guess i guess uh<br>but it is what you have to do if you're<br>if you're say you've taken a recording<br>of a train going past and you want to<br>present that loudness you know it's<br>the the difficulty involved in coming up<br>with a um<br>with a rendering probably means it's not<br>worth doing most of the cost of this<br>comes down to the visual rendering<br>actually<br>um the audio part is something we do day<br>in day out it's part of a normal process<br>so<br>so for us yeah the spherical photos i<br>guess are a<br>money saver if the client doesn't want<br>to go to that effort<br>and of course if you if you want to<br>translate if you want to move somebody<br>from seat to seat you've got to do this<br>as a<br>well i guess you could do it with a lot<br>of photos but you've got to um<br>it's a lot easier to be able to put the<br>um make the rendering from the<br>the location that you're oralizing with<br>your your audience<br>acoustics yeah that was exactly my<br>question<br>is that in the listening room the person<br>has to you know they can<br>they're static they can turn and look<br>around but they can't actually move<br>through it<br>yeah in fact we we seat people just to<br>make sure they don't get hurt and don't<br>get tired<br>but most of the time you know if we're<br>doing a concert hall it's the seated<br>position we're concerned about<br>or sitting in your lounge listening to<br>your neighbor's stereo or something like<br>that<br>so there's not much to be gained by<br>actually moving through a space<br>and it would be lovely to do and and one<br>of the things we'd like to do in fact is<br>is to have this work in real time so<br>that you can not only um<br>move about space but also be able to<br>play your trumpet and hear how the<br>the the concert hall would respond um so<br>we're doing some work on how to do that<br>um it's actually fairly complicated<br>because all this stuff<br>kind of has to be pre-processed to make<br>it fast enough to work in vr<br>so adding the layer of being able to<br>talk into it or play a trumpet into it<br>is<br>going to take several more probably<br>another dimension of computational<br>difficulty<br>um but by the same token if we wanted to<br>have a a walk through<br>where the acoustics change as you move<br>position that means we got to somehow be<br>able to<br>morph from one impulse response to<br>another as the as the<br>listener moves it's just that one of my<br>master students is down we're scanning<br>uh the cmec building<br>office so that we've got a scan<br>walk-through version for other work that<br>we're doing<br>but um we should talk offline perhaps if<br>you need to<br>do a 3d scan of a space you know we've<br>got that capability within this building<br>that's brilliant yeah<br>that's that's the thing that we're<br>missing and we have talked about how do<br>we contract this<br>yeah it'll be lovely i i should add one<br>one of the intriguing things<br>so when i was teaching second year uh<br>and students weren't asking questions i<br>would sit down with nalesh and try to<br>figure out how<br>the cat acoustic so we have like odie<br>and the ability to<br>reproduce what a room would sound like<br>you give it the acoustics<br>in terms of the shape of the room and<br>the material finishes<br>and you could pick different parts of<br>the room to stand in to listen to a<br>sound source<br>cat acoustic comes with an ability to<br>write a script from 3d studio max which<br>says these are the positions<br>then to actually calculate the impulse<br>responses in each of those positions<br>so that you could actually get what it<br>would sound like as you walk through a<br>space<br>which all seemed very intriguing until<br>we tried to match the two together and<br>we could never quite<br>find time i never had time outside of<br>the class to do it but it was like<br>between questions well this is something<br>we can do that is related to<br>the software that the students are using<br>at the moment<br>it's a very non-trivial thing to do to<br>to move through a space<br>yeah it's it's quite complicated well it<br>was down to you actually had to<br>have some kind of impulse response that<br>was<br>morphed from one position to the next at<br>30 frames a second for animation time or<br>whatever would seem seemed to be<br>appropriate it was like<br>getting the maths of all that right was<br>intriguing<br>time is a second then that that<br>reverberation is is moving while you're<br>trying to morph through it<br>yes yes exactly so but what i<br>am intrigued by is that you have the<br>ability to<br>put someone in an apartment to allow<br>them to move from place to place within<br>the apartment<br>and listen to what it would sound like<br>with<br>a building code compliant wall between<br>them and the neighbor<br>or something rather better um and that<br>to me is really one of the really<br>intriguing<br>aspects of this it's not just about what<br>it sounds like in the room but what it<br>sounds like<br>between this room and another room um<br>yeah<br>yeah and that's meat potato what<br>marshall day does so that's that's why<br>we<br>exactly straight there's a question<br>just just on that part i was wondering<br>um<br>i'm sure you have but it might actually<br>be a dumb question<br>now though think about it more but how<br>do you actually know that what's<br>happening<br>in the virtual environment is what will<br>actually happen in the<br>physical real environment i presume that<br>there's been some physical<br>measurements and tie-ups or something<br>like that<br>yeah that's a really good question and<br>one of the things we want to use this<br>for is for presentations in environment<br>court<br>and so we're thinking about how do we<br>how do we demonstrate that we got it<br>right<br>so we don't spend the whole time arguing<br>with other consultants about<br>martial days trying to pull the wool<br>over your eyes simple answer and one of<br>the reasons that the loudspeaker versus<br>the headphone<br>system is so good is because you just<br>put a sound level meter in the listening<br>place and you measure it<br>so from a from a pure loudness point of<br>view it's easy to<br>to calibrate that um that the more<br>um the the more fluffy things like<br>like the localization is is more<br>difficult to achieve we although we do<br>have our iris tool which is a<br>multi-directional measurement device we<br>can stick in that listening space<br>and demonstrate that when we say a<br>reflection is coming from over there<br>um in fact that comes into the<br>microphone in the proper way<br>so um i'm not really that's probably not<br>quite the answer to the question and<br>certainly from<br>validating the visuals that's outside<br>probably any of our<br>experience and you guys would have a lot<br>better handle on that<br>um we're not really trying to push the<br>barrel that we can<br>sorry if i get other calls coming in<br>we're not we're not trying to suggest<br>that<br>we can present the visuals properly i<br>guess is what i'm trying to say we're<br>using that as a tool to<br>suspend disbelief so people can listen<br>to our oral simulations properly<br>and within at least the context of<br>loudness we can just put a meter there<br>all right and that and sorry<br>freaking yes i was just i was just going<br>to add that<br>i get the impression that there's a<br>quantum step up when you put<br>visuals and you know sound together that<br>the the two actually somehow mingle with<br>one another and mix<br>the other one up that and you're saying<br>about the<br>the pre preconditioning of noise before<br>you come into a space<br>so maybe maybe at our opera theaters we<br>should give them really bad opera<br>as they come up you know and then they<br>yeah<br>yeah i think there's a lot to that and<br>it's something that we haven't quite<br>cracked and we're still<br>working on that yeah there'd be a lot of<br>basic research<br>to do with how how you know the saltine<br>cracker effect sort of works on the<br>ability to um<br>disconnect yourself from a previous<br>environment and consider<br>everyone yeah in the area of<br>the the visual and acoustic i do<br>remember we had a<br>fourth year student it must be nearly 20<br>years ago<br>who looked at this kind of oralization<br>but it was with headphones<br>and visualization and his<br>task was to compare two rooms<br>visually and orally and he got an<br>acoustician<br>and a lighting expert to<br>review the results and the<br>lighting expert trusted the acoustic<br>representation<br>and the acoustic expert trusted the<br>lighting<br>representation but not their own<br>so they knew too much yeah and that's<br>that's where we're at<br>um there's a guy called denzel cabrera<br>in<br>in australia who's doing some work in<br>this and he's one of the<br>papers he wrote was about going into<br>different concert halls into different<br>seats<br>and he'd measure dummy head recordings<br>of the audio and take photographs of the<br>stage from those seats<br>and then he'd mix them up and see if<br>people could um properly put them<br>together<br>right and i think to to a course degree<br>they could they their expectations<br>guided them to understand what<br>the sound should match up with the<br>visual wow but i'm not sure exactly how<br>well they could do that that is<br>interesting<br>do we have any because i can carry on<br>this conversation forever it's a really<br>fascinating area but<br>i found that really interesting that<br>there's a certain tyrell<br>environment acoustic environment well we<br>don't know<br>whether there is or not but we've always<br>assumed that's not we've always just<br>gone to our<br>our swiss or american design tables to<br>to bang out what you do in a<br>in a a fairy kai is that the right thing<br>to do that's that's what i want to find<br>out<br>i guess that was the question i wanted<br>to finish on because<br>earlier this year micklin approached me<br>and said you know there's this<br>speech transmission index sti that is<br>based on<br>a certain amount of consonants in a uh<br>in language and the clarity of speech<br>given<br>the volume that you're speaking at and<br>the background noise<br>uh in the space uh and<br>as he said at the beginning he's being<br>challenged to say<br>is that actually true of all languages<br>there seems to be some hint that perhaps<br>there is a chinese equivalent<br>of sta which picks up all of the<br>inflections better<br>but we don't know we haven't looked and<br>marshall day are very keen<br>like clean in particular but uh<br>colleague in auckland as well<br>uh and actually probably funding<br>a piece of research in this area we<br>approached people from the linguistics<br>department and becky put me onto someone<br>in maori studies<br>who i've talked to and then lockdown<br>happened<br>and so not a lot has happened in the<br>last two months<br>but i saw this as an opportunity to<br>spread the net wider and say you know<br>anyone who's interested or might be<br>interested in this field<br>uh let's talk<br>to micklin and actually get something<br>happening uh<br>the i've i think two weeks ago when we<br>were setting this up i also<br>remembered to write to the linguistics<br>people and say<br>by the way now that we're coming out of<br>lockdown perhaps we should get back<br>together again<br>i haven't heard back from them yet but<br>it's time for another reminder but i<br>if you are interested or know someone<br>who might be interested<br>then there's a phd in that at least when<br>we've got the linguistic side sorted out<br>well i'm thinking of professor thai<br>black at te awa nuyarangi up in<br>uh he would he would be down this like a<br>rabbit down up<br>okay excellent<br>right well an offline conversation<br>sounds like a really excellent start for<br>that<br>uh so anyway can i thank<br>macklin for an excellent presentation uh<br>and<br>a really challenging future but yes</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>