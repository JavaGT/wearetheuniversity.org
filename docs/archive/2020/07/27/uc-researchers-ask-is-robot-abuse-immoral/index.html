<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>UC Researchers Ask: Is Robot Abuse Immoral? – WATU</title><link rel="stylesheet" href="/styles.css"></head><body><header><h1 style="font-family: 'Arial Black', Gadget, sans-serif;font-style: italic;font-weight: 900;text-transform: uppercase;">We Are The University    </h1><nav><ul><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li><li><a href="/blog">Blog</a></li><li><a href="/archive">Archive</a></li><li><a href="/authors">Authors</a></li><li><a href="/games">Games</a></li><li><a href="/reading-groups">Reading Groups</a></li></ul></nav></header><main><h2>UC Researchers Ask: Is Robot Abuse Immoral?</h2><p> <a href="https://www.scoop.co.nz/stories/SC2007/S00050/uc-researchers-ask-is-robot-abuse-immoral.htm">Original post</a></p><h3><span>university-of-canterbury</span></h3><p>Mon Jul 27 2020 12:00:00 GMT+1200 (New Zealand Standard Time)</p><p><h1>UC Researchers Ask: Is Robot Abuse Immoral?</h1>
<p><strong>Monday, 27 July 2020, 2:24 pm</strong><br><strong>Press Release: <a href="https://info.scoop.co.nz/University_of_Canterbury">University of Canterbury</a></strong></p>
<p>In a new study, University of Canterbury (UC) researchers have found that participants considered abusive behaviour towards a robot just as immoral as abusive behaviour towards a human.</p>
<p>The paper titled ‘The morality of abusing a robot’, by Associate Professor Christoph Bartneck and PhD student Merel Keijsers of the Human Interface Technology Lab New Zealand | Hangarau Tangata, Tangata Hangarau (HIT Lab NZ) in UC’s College of Engineering, was recently published in the <em>Paladyn, Journal of Behavioural Robotics</em>.</p>
<p>“It’s not uncommon for humans to exhibit abusive behaviour towards robots in real life,” Associate Professor Bartneck says. “Our research looks at how abusive behaviour towards a human is perceived in comparison with identical behaviour towards a robot.”</p>
<p>Participants were shown 16 video clips that depicted different levels of violence and abuse towards a human and a Boston Dynamics Atlas robot. The robot in the video was computer-generated imagery (CGI), its motions created by a human actor. As a result, there were two versions of a video with identical abusive behaviours – one where the victim was a human and one where it was a robot.</p>
<p>Advertisement - scroll to continue reading</p>
<p>“We found that participants saw bullying of humans and robots as equally unacceptable, which is interesting because a robot doesn’t have feelings and can’t experience pain – it doesn’t even understand the concept of abuse.</p>
<p>“It doesn’t make sense from a logical point of view,” says Associate Professor Bartneck. “It’s very interesting in the sense that if we treat robots as if they are humans, we consider it immoral to mistreat them.”</p>
<p>However, the findings were different when participants were shown footage of a human fighting back in response to being bullied in comparison to a robot fighting back in the same situation. Humans were seen as less immoral compared with robots when fighting back.</p>
<p>“As soon as the victim fought back in response to the abuse, there was a big difference. A human fighting back in that situation was considered as more acceptable, but a robot fighting back in the same situation was not considered as acceptable behaviour,” Keijsers says.</p>
<p>“We did further analysis to explain this difference and found that the participants interpreted the robot’s response as a lot more aggressive or abusive than the human’s response – they felt there was a higher intent to harm.”</p>
<p>One explanation for this, the researchers suggest, is that when a robot fights back or resists, there is a change in power.</p>
<p>“Robots are very much meant to work and serve, so they may be viewed as sub-ordinate, but when a robot is not obedient or gets aggressive it’s viewed as inappropriate,” Keijsers says.</p>
<p>She points out that another explanation for this could be due to robots being portrayed in media as a potential threat – especially in those blockbuster movies where robots ‘rise up’ against their masters or enslave humanity.</p>
<p>“Right now we don’t have a lot of robots in society but that’s set to change. It’s only a matter of time. This research lays the foundations for a society in which we can have robots around – we have to figure out how we will interact with them,” says Keijsers.</p>
<p><strong>The HIT Lab NZ</strong> is a multi-disciplinary research laboratory at UC that focuses on how people interact with technology. There are currently several openings available for postgraduate studies in the area of human-robot Interaction that focus on the ethics of human-robot relationships and AI. Students interested in postgraduate studies at the HIT Lab NZ should contact <a href="mailto:info@hitlabnz.org">info@hitlabnz.org</a></p>
<p><strong>Christoph Bartneck</strong> is an associate professor and director of postgraduate studies at the HIT Lab NZ at the University of Canterbury. He has a background in Industrial Design and Human-Computer Interaction, and his projects and studies have been published in leading journals, newspapers, and conferences. His interests lie in the fields of human-robot interaction, science and technology studies, and visual design. More specifically, he focuses on the effect of anthropomorphism on human-robot interaction. He has worked for several international organisations including the Technology Centre of Hanover (Germany), LEGO (Denmark), Eagle River Interactive (USA), Philips Research (Netherlands), ATR (Japan), and The Eindhoven University of Technology (Netherlands).</p>
<p><strong>Merel Keijsers</strong> is completing her PhD at the HIT Lab NZ, University of Canterbury. From the Netherlands, she has a research Master’s degree in Statistics, and in Social and Health Psychology from Utrecht University. In her PhD, she studied what conscious and subconscious psychological processes drive people to abuse and bully robots. Having a background in social psychology, she is mainly interested in the similarities and differences in how people deal with robots versus other humans. Merel has accepted a position as an assistant professor at John Cabot University in Rome, Italy which she will start in 2021.</p>
<p><em>The researchers would like to acknowledge Corridor Digital who made the stimuli available for this research.</em></p>
<p><a href="http://www.scoop.co.nz/about/terms.html">© Scoop Media</a>  </p>
<p>Advertisement - scroll to continue reading</p>
<p>a.supporter:hover {background:#EC4438!important;} @media screen and (max-width: 480px) { #byline-block div.byline-block {padding-right:16px;}}</p>
<h3>Using Scoop for work?</h3>
<p>Scoop is free for personal use, but you’ll need a licence for work use. This is part of our Ethical Paywall and how we fund Scoop. Join today with plans starting from less than $3 per week, plus gain access to exclusive <em>Pro</em> features.  </p>
<p><a href="https://pro.scoop.co.nz/Individual/?from=ProIn24">Join Pro Individual</a> <a href="https://pro.scoop.co.nz/using-scoop-for-work/?from=ProIn24">Find out more</a></p>
<p>Find more from <a href="https://info.scoop.co.nz/University_of_Canterbury">University of Canterbury</a> on InfoPages.</p>
</p></main><footer style="margin-top: 2rem; background: #0001; padding: 2rem; text-align: center;"><p>We Are The University</p><ul style="list-style-type: none; padding: 0; margin: 0;"><li><a href="/">Home</a></li><li><a href="/about">About</a></li><li><a href="/contact">Contact</a></li></ul></footer></body></html>